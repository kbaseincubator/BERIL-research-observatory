{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB03: Community Pathway Completeness Matrix\n",
    "\n",
    "**Project**: Community Metabolic Ecology via NMDC × Pangenome Integration  \n",
    "**Requires**: BERDL JupyterHub (Spark — `get_spark_session()` injected into kernel)  \n",
    "\n",
    "## Purpose\n",
    "\n",
    "Compute community-weighted GapMind pathway completeness scores per NMDC sample.\n",
    "\n",
    "**Formula**:  \n",
    "`completeness(sample s, pathway p) = Σᵢ [ (aᵢ / Σⱼ aⱼ_mapped) × frac_complete(taxon_i, p) ]`  \n",
    "where aᵢ is centrifuge abundance for taxon i, and the denominator normalizes over\n",
    "mapped taxa only, so weights sum to 1 per sample per pathway.\n",
    "\n",
    "## Inputs (from NB01/NB02)\n",
    "\n",
    "- `data/taxon_bridge.tsv` — centrifuge taxon → GTDB species clade_id + mapping tier\n",
    "- `data/nmdc_sample_inventory.csv` — sample × clf_file_id × met_file_id\n",
    "- `data/bridge_quality.csv` — per-file bridge coverage and QC flag\n",
    "- `nmdc_arkin.centrifuge_gold` + `nmdc_arkin.omics_files_table` — species abundances\n",
    "- `kbase_ke_pangenome.gapmind_pathways` — 305M rows (filtered to bridged clades)\n",
    "- `kbase_ke_pangenome.gtdb_species_clade` — clade_id → GTDB_species bridge\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `data/species_pathway_completeness.csv` — per-GTDB-clade × per-pathway completeness\n",
    "- `data/community_pathway_matrix.csv` — per-sample × per-pathway community-weighted completeness\n",
    "- `figures/pathway_completeness_heatmap.png` — mean completeness by pathway × ecosystem type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0x7ccb646416a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On BERDL JupyterHub — get_spark_session() is injected into the kernel; no import needed\n",
    "spark = get_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /home/cjneely/repos/BERIL-research-observatory/projects/nmdc_community_metabolic_ecology/data\n",
      "FIGURES_DIR: /home/cjneely/repos/BERIL-research-observatory/projects/nmdc_community_metabolic_ecology/figures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "FIGURES_DIR = os.path.join(PROJECT_DIR, 'figures')\n",
    "\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'FIGURES_DIR: {FIGURES_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load NB02 Outputs\n",
    "\n",
    "Load cached bridge and inventory files from NB02. These are loaded from disk (CSV/TSV),\n",
    "so they are regular pandas DataFrames (no PyArrow ChunkedArray issue) and can be safely\n",
    "passed to `spark.createDataFrame()` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge rows: 4894  |  mapping tiers:\n",
      "mapping_tier\n",
      "unmapped                 2022\n",
      "species_exact            1375\n",
      "genus_proxy_ambiguous    1352\n",
      "genus_proxy_unique        145\n",
      "\n",
      "Inventory rows: 646, unique samples: 221\n",
      "Bridge quality rows: 220\n",
      "Samples passing QC (>=30%): 220\n"
     ]
    }
   ],
   "source": [
    "# Load NB02 outputs from disk\n",
    "bridge = pd.read_csv(os.path.join(DATA_DIR, 'taxon_bridge.tsv'), sep='\\t')\n",
    "inventory = pd.read_csv(os.path.join(DATA_DIR, 'nmdc_sample_inventory.csv'))\n",
    "bridge_quality = pd.read_csv(os.path.join(DATA_DIR, 'bridge_quality.csv'))\n",
    "\n",
    "print(f'Bridge rows: {len(bridge)}  |  mapping tiers:')\n",
    "print(bridge['mapping_tier'].value_counts().to_string())\n",
    "print(f'\\nInventory rows: {len(inventory)}, unique samples: {inventory[\"sample_id\"].nunique()}')\n",
    "print(f'Bridge quality rows: {len(bridge_quality)}')\n",
    "print(f'Samples passing QC (>=30%): {bridge_quality[\"passes_bridge_qc\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap samples passing bridge QC: 220\n",
      "Sample sample_ids: ['nmdc:bsm-11-ahfq0n74', 'nmdc:bsm-11-v0hqhp22', 'nmdc:bsm-11-57ejpn32', 'nmdc:bsm-11-nx7zwq61', 'nmdc:bsm-11-h3e54f51']\n",
      "\n",
      "Unique mapped GTDB clade IDs: 1837\n"
     ]
    }
   ],
   "source": [
    "# Determine the set of overlap samples and their classifier files\n",
    "# Use samples that appear in the inventory AND pass bridge QC\n",
    "qc_pass_files = set(bridge_quality[bridge_quality['passes_bridge_qc']]['file_id'].tolist())\n",
    "\n",
    "# One clf_file per sample: take the QC-passing file (if multiple, take first)\n",
    "inventory_qc = inventory[inventory['clf_file_id'].isin(qc_pass_files)].copy()\n",
    "# Drop duplicate samples, keeping first clf_file_id\n",
    "sample_file_map = (\n",
    "    inventory_qc[['sample_id', 'clf_file_id']]\n",
    "    .drop_duplicates(subset='sample_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "overlap_sample_ids = sample_file_map['sample_id'].tolist()\n",
    "\n",
    "print(f'Overlap samples passing bridge QC: {len(overlap_sample_ids)}')\n",
    "print('Sample sample_ids:', overlap_sample_ids[:5])\n",
    "\n",
    "# Get mapped clade IDs from bridge (native Python list — safe to use in SQL IN clauses)\n",
    "mapped_bridge = bridge[bridge['mapping_tier'] != 'unmapped'].dropna(subset=['gtdb_species_clade_id'])\n",
    "mapped_clade_ids = mapped_bridge['gtdb_species_clade_id'].unique().tolist()\n",
    "print(f'\\nUnique mapped GTDB clade IDs: {len(mapped_clade_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: GapMind Species-Level Pathway Completeness\n",
    "\n",
    "Run two-stage aggregation on `gapmind_pathways` (305M rows), filtered to the\n",
    "~1,500 GTDB clades that appear in the taxon bridge.  \n",
    "**Stay in Spark until the final ~(n_clades × n_pathways) aggregation.**\n",
    "\n",
    "Pitfall: GapMind has multiple rows per genome-pathway pair — always GROUP BY\n",
    "and MAX score first (see `docs/pitfalls.md` [pangenome_pathway_geography])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped clade names for GapMind filter: 1837\n",
      "Sample: ['s__Burkholderia_cenocepacia--RS_GCF_900446215.1', 's__Streptomyces_albus--RS_GCF_000725885.1', 's__Stutzerimonas_stutzeri--RS_GCF_000219605.1', 's__Ralstonia_solanacearum--RS_GCF_002251695.1', 's__Nocardia_cyriacigeorgica--RS_GCF_000308555.1']\n",
      "\n",
      "NOTE: gapmind_pathways.clade_name = gtdb_species_clade_id format\n",
      "      (includes genome accession suffix, e.g., s__X--RS_GCF_...)\n"
     ]
    }
   ],
   "source": [
    "# gapmind_pathways.clade_name = gtdb_species_clade_id format\n",
    "# (e.g., 's__Rhizobium_phaseoli--RS_GCF_001234567.1')\n",
    "# taxon_bridge.gtdb_species_clade_id is already in this format.\n",
    "# No GTDB_species lookup needed — use mapped_clade_ids directly as clade_name filter.\n",
    "\n",
    "mapped_clade_names = mapped_clade_ids  # These match clade_name in gapmind_pathways\n",
    "print(f'Mapped clade names for GapMind filter: {len(mapped_clade_names)}')\n",
    "print('Sample:', mapped_clade_names[:5])\n",
    "print()\n",
    "print('NOTE: gapmind_pathways.clade_name = gtdb_species_clade_id format')\n",
    "print('      (includes genome accession suffix, e.g., s__X--RS_GCF_...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered 1837 clade names as Spark temp view mapped_clade_names_tmp\n"
     ]
    }
   ],
   "source": [
    "# Register mapped clade names as a Spark temp view for efficient JOIN.\n",
    "# pd.DataFrame from Python list (not from Spark.toPandas()) — safe to use with createDataFrame().\n",
    "\n",
    "clade_names_df = pd.DataFrame({'clade_name': mapped_clade_names})\n",
    "spark.createDataFrame(clade_names_df).createOrReplaceTempView('mapped_clade_names_tmp')\n",
    "print(f'Registered {len(clade_names_df)} clade names as Spark temp view mapped_clade_names_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== gapmind_pathways schema ===\n",
      "+------------------+---------+-------+\n",
      "|col_name          |data_type|comment|\n",
      "+------------------+---------+-------+\n",
      "|genome_id         |string   |NULL   |\n",
      "|pathway           |string   |NULL   |\n",
      "|clade_name        |string   |NULL   |\n",
      "|metabolic_category|string   |NULL   |\n",
      "|sequence_scope    |string   |NULL   |\n",
      "|nHi               |int      |NULL   |\n",
      "|nMed              |int      |NULL   |\n",
      "|nLo               |int      |NULL   |\n",
      "|score             |double   |NULL   |\n",
      "|score_category    |string   |NULL   |\n",
      "|score_simplified  |double   |NULL   |\n",
      "+------------------+---------+-------+\n",
      "\n",
      "\n",
      "Sample clade_name values from gapmind_pathways (confirm format):\n",
      "+-------------------------------------------------+\n",
      "|clade_name                                       |\n",
      "+-------------------------------------------------+\n",
      "|s__Snodgrassella_alvi_B--RS_GCF_002777425.1      |\n",
      "|s__Massilioclostridium_coli--RS_GCF_900095865.1  |\n",
      "|s__Marinisoma_sp000402655--GB_GCA_000402655.1    |\n",
      "|s__UBA2943_sp900321295--GB_GCA_900321295.1       |\n",
      "|s__Alloprevotella_sp022772475--GB_GCA_022772475.1|\n",
      "+-------------------------------------------------+\n",
      "\n",
      "Temp view re-registered: 1837 clade names\n",
      "\n",
      "Verify temp view JOIN (5-row sample — should return results):\n",
      "+-----------------------------------------------+----------+-----------------+------------------+\n",
      "|clade_name                                     |pathway   |score_category   |metabolic_category|\n",
      "+-----------------------------------------------+----------+-----------------+------------------+\n",
      "|s__Streptococcus_pneumoniae--RS_GCF_001457635.1|arginine  |not_present      |carbon            |\n",
      "|s__Streptococcus_pneumoniae--RS_GCF_001457635.1|arginine  |not_present      |carbon            |\n",
      "|s__Streptococcus_pneumoniae--RS_GCF_001457635.1|arginine  |steps_missing_low|carbon            |\n",
      "|s__Streptococcus_pneumoniae--RS_GCF_001457635.1|asparagine|complete         |carbon            |\n",
      "|s__Streptococcus_pneumoniae--RS_GCF_001457635.1|asparagine|not_present      |carbon            |\n",
      "+-----------------------------------------------+----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2a: Verify GapMind schema and confirm clade_name format matches mapped_clade_names.\n",
    "# Note: Use LIMIT queries only — avoid full 305M-row scans that trigger Spark Connect\n",
    "# session reconnects and silently destroy temp views.\n",
    "\n",
    "print('=== gapmind_pathways schema ===')\n",
    "spark.sql('DESCRIBE kbase_ke_pangenome.gapmind_pathways').show(20, truncate=False)\n",
    "\n",
    "# Sample actual clade_name values to confirm format\n",
    "print('\\nSample clade_name values from gapmind_pathways (confirm format):')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT clade_name\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "# Re-register temp view here (defensive: session may have reconnected during prior cells)\n",
    "spark.createDataFrame(\n",
    "    pd.DataFrame({'clade_name': mapped_clade_names})\n",
    ").createOrReplaceTempView('mapped_clade_names_tmp')\n",
    "print(f'Temp view re-registered: {len(mapped_clade_names)} clade names')\n",
    "\n",
    "# Verify the JOIN actually returns rows before committing to the full aggregation\n",
    "print('\\nVerify temp view JOIN (5-row sample — should return results):')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT g.clade_name, g.pathway, g.score_category, g.metabolic_category\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways g\n",
    "    JOIN mapped_clade_names_tmp m ON g.clade_name = m.clade_name\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GapMind rows for mapped clades: 160,351,853 (vs 305M total)\n",
      "Distinct pathways in mapped clades: 80\n"
     ]
    }
   ],
   "source": [
    "# Re-register temp view (defensive: Spark Connect session may reconnect between cells)\n",
    "spark.createDataFrame(\n",
    "    pd.DataFrame({'clade_name': mapped_clade_names})\n",
    ").createOrReplaceTempView('mapped_clade_names_tmp')\n",
    "\n",
    "# Check how many GapMind rows are in the mapped clades subset\n",
    "n_gapmind_mapped = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as n\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways g\n",
    "    JOIN mapped_clade_names_tmp m ON g.clade_name = m.clade_name\n",
    "\"\"\").collect()[0]['n']\n",
    "print(f'GapMind rows for mapped clades: {n_gapmind_mapped:,} (vs 305M total)')\n",
    "\n",
    "# Count distinct pathways in mapped subset\n",
    "n_pathways = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT pathway) as n\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways g\n",
    "    JOIN mapped_clade_names_tmp m ON g.clade_name = m.clade_name\n",
    "\"\"\").collect()[0]['n']\n",
    "print(f'Distinct pathways in mapped clades: {n_pathways}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GapMind aggregation (may take several minutes)...\n",
      "Species pathway completeness rows: 146,960\n",
      "Clades: 1837\n",
      "Pathways: 80\n",
      "Metabolic categories: ['aa', 'carbon']\n",
      "frac_complete dtype: float64\n",
      "                                                 clade_name   pathway metabolic_category  mean_best_score  frac_complete  frac_likely_complete  n_genomes\n",
      "0              s__Citrobacter_werkmanii--GB_GCA_000759755.1       leu                 aa         5.000000            1.0                   1.0         92\n",
      "1           s__Methylocella_sp003162995--GB_GCA_003162995.1       gly                 aa         5.000000            1.0                   1.0          2\n",
      "2                  s__Rickettsia_bellii--RS_GCF_000012385.1   xylitol             carbon         1.000000            0.0                   0.0          7\n",
      "3  s__Carboxydothermus_hydrogenoformans--RS_GCF_000012865.1       met                 aa         5.000000            1.0                   1.0          3\n",
      "4      s__Lactiplantibacillus_plantarum--RS_GCF_014131735.1  tyrosine             carbon         2.997268            0.0                   0.0        732\n"
     ]
    }
   ],
   "source": [
    "# Re-register temp view immediately before the expensive aggregation (belt-and-suspenders)\n",
    "spark.createDataFrame(\n",
    "    pd.DataFrame({'clade_name': mapped_clade_names})\n",
    ").createOrReplaceTempView('mapped_clade_names_tmp')\n",
    "\n",
    "# Two-stage GapMind aggregation (stay in Spark until final result):\n",
    "# Stage 1: MAX score per (clade, genome, pathway) — eliminates duplicate rows per genome-pathway pair\n",
    "# Stage 2: AVG across genomes per (clade, pathway) — species-level completeness\n",
    "#\n",
    "# Note: CAST AS DOUBLE required — Spark infers DECIMAL for AVG(INT) and for\n",
    "#       AVG(CASE WHEN ... THEN 1.0 ...) where 1.0 is a DECIMAL literal.\n",
    "#       Without the CAST, pandas receives decimal.Decimal objects that fail\n",
    "#       in downstream float arithmetic.\n",
    "\n",
    "species_completeness_spark = spark.sql(\"\"\"\n",
    "    WITH best_scores AS (\n",
    "        SELECT g.clade_name, g.genome_id, g.pathway, g.metabolic_category,\n",
    "               MAX(CASE g.score_category\n",
    "                   WHEN 'complete'             THEN 5\n",
    "                   WHEN 'likely_complete'      THEN 4\n",
    "                   WHEN 'steps_missing_low'    THEN 3\n",
    "                   WHEN 'steps_missing_medium' THEN 2\n",
    "                   WHEN 'not_present'          THEN 1\n",
    "                   ELSE 0 END) AS best_score\n",
    "        FROM kbase_ke_pangenome.gapmind_pathways g\n",
    "        JOIN mapped_clade_names_tmp m ON g.clade_name = m.clade_name\n",
    "        GROUP BY g.clade_name, g.genome_id, g.pathway, g.metabolic_category\n",
    "    )\n",
    "    SELECT\n",
    "        clade_name,\n",
    "        pathway,\n",
    "        metabolic_category,\n",
    "        CAST(AVG(best_score) AS DOUBLE)                                         AS mean_best_score,\n",
    "        CAST(AVG(CASE WHEN best_score >= 5 THEN 1.0 ELSE 0.0 END) AS DOUBLE)   AS frac_complete,\n",
    "        CAST(AVG(CASE WHEN best_score >= 4 THEN 1.0 ELSE 0.0 END) AS DOUBLE)   AS frac_likely_complete,\n",
    "        COUNT(DISTINCT genome_id)                                                AS n_genomes\n",
    "    FROM best_scores\n",
    "    GROUP BY clade_name, pathway, metabolic_category\n",
    "\"\"\")\n",
    "\n",
    "# Collect to pandas — this is the expensive Spark job (~10+ min for large clade sets)\n",
    "print('Running GapMind aggregation (may take several minutes)...')\n",
    "species_completeness = species_completeness_spark.toPandas()\n",
    "\n",
    "print(f'Species pathway completeness rows: {len(species_completeness):,}')\n",
    "print(f'Clades: {species_completeness[\"clade_name\"].nunique()}')\n",
    "print(f'Pathways: {species_completeness[\"pathway\"].nunique()}')\n",
    "print(f'Metabolic categories: {species_completeness[\"metabolic_category\"].unique().tolist()}')\n",
    "print(f'frac_complete dtype: {species_completeness[\"frac_complete\"].dtype}')\n",
    "print(species_completeness.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species pathway completeness rows: 146,960\n",
      "Unique gtdb_species_clade_id: 1837\n",
      "Pathways: 80\n",
      "                             gtdb_species_clade_id  pathway metabolic_category  mean_best_score  frac_complete  frac_likely_complete  n_genomes\n",
      "0     s__Citrobacter_werkmanii--GB_GCA_000759755.1      leu                 aa              5.0            1.0                   1.0         92\n",
      "1  s__Methylocella_sp003162995--GB_GCA_003162995.1      gly                 aa              5.0            1.0                   1.0          2\n",
      "2         s__Rickettsia_bellii--RS_GCF_000012385.1  xylitol             carbon              1.0            0.0                   0.0          7\n"
     ]
    }
   ],
   "source": [
    "# gapmind_pathways.clade_name = gtdb_species_clade_id — just rename for clarity.\n",
    "# No merge needed; the values are already the same IDs used in taxon_bridge.\n",
    "species_completeness = species_completeness.rename(\n",
    "    columns={'clade_name': 'gtdb_species_clade_id'}\n",
    ")\n",
    "\n",
    "print(f'Species pathway completeness rows: {len(species_completeness):,}')\n",
    "print(f'Unique gtdb_species_clade_id: {species_completeness[\"gtdb_species_clade_id\"].nunique()}')\n",
    "print(f'Pathways: {species_completeness[\"pathway\"].nunique()}')\n",
    "print(species_completeness.head(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/species_pathway_completeness.csv (146,960 rows)\n",
      "  Clades: 1837\n",
      "  Pathways: 80\n"
     ]
    }
   ],
   "source": [
    "# Save species-level pathway completeness\n",
    "sp_path = os.path.join(DATA_DIR, 'species_pathway_completeness.csv')\n",
    "species_completeness.to_csv(sp_path, index=False)\n",
    "print(f'Saved: data/species_pathway_completeness.csv ({len(species_completeness):,} rows)')\n",
    "print(f'  Clades: {species_completeness[\"gtdb_species_clade_id\"].nunique()}')\n",
    "print(f'  Pathways: {species_completeness[\"pathway\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Community-Weighted Pathway Completeness Per Sample\n",
    "\n",
    "For each overlap sample:\n",
    "1. Get species-rank centrifuge abundances\n",
    "2. Join taxon → `gtdb_species_clade_id` via `taxon_bridge`\n",
    "3. Join `gtdb_species_clade_id` → `frac_complete` per pathway via `species_pathway_completeness`\n",
    "4. Compute community-weighted mean, normalized by mapped abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species-rank rows for overlap samples: 126,905\n",
      "Unique classifier files: 220\n",
      "abundance dtype: float64\n",
      "                 file_id                        taxon_name  abundance\n",
      "0  nmdc:dobj-11-kbd8zm70       Staphylococcus pettenkoferi   0.000037\n",
      "1  nmdc:dobj-11-kbxytm81  Actinoalloteichus sp. AHMU CJ021   0.000028\n",
      "2  nmdc:dobj-11-kbxytm81              Variovorax sp. PMC12   0.001012\n"
     ]
    }
   ],
   "source": [
    "# Load centrifuge species-rank data for overlap samples via Spark.\n",
    "# Use omics_files_table to restrict to overlap samples (no pandas→Spark roundtrip).\n",
    "BRIDGE_TBL = 'nmdc_arkin.omics_files_table'\n",
    "\n",
    "clf_data_spark = spark.sql(f\"\"\"\n",
    "    SELECT c.file_id, c.label AS taxon_name, CAST(c.abundance AS DOUBLE) AS abundance\n",
    "    FROM nmdc_arkin.centrifuge_gold c\n",
    "    JOIN {BRIDGE_TBL} b ON c.file_id = b.file_id\n",
    "    WHERE b.sample_id IN (\n",
    "        SELECT b2.sample_id FROM {BRIDGE_TBL} b2\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.centrifuge_gold) c2 ON b2.file_id = c2.file_id\n",
    "        INTERSECT\n",
    "        SELECT b3.sample_id FROM {BRIDGE_TBL} b3\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.metabolomics_gold) m3 ON b3.file_id = m3.file_id\n",
    "    )\n",
    "    AND LOWER(c.rank) = 'species'\n",
    "    AND c.label IS NOT NULL AND c.label != ''\n",
    "    AND c.abundance > 0\n",
    "\"\"\")\n",
    "\n",
    "clf_data = clf_data_spark.toPandas()\n",
    "# Ensure abundance is float (Spark DECIMAL maps to decimal.Decimal in pandas)\n",
    "clf_data['abundance'] = clf_data['abundance'].astype(float)\n",
    "\n",
    "print(f'Species-rank rows for overlap samples: {len(clf_data):,}')\n",
    "print(f'Unique classifier files: {clf_data[\"file_id\"].nunique()}')\n",
    "print(f'abundance dtype: {clf_data[\"abundance\"].dtype}')\n",
    "print(clf_data.head(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after merging sample_id: 126,905\n",
      "Unique samples: 220\n"
     ]
    }
   ],
   "source": [
    "# Map file_id → sample_id using sample_file_map (one clf_file per sample)\n",
    "clf_data = clf_data.merge(sample_file_map.rename(columns={'clf_file_id': 'file_id'}),\n",
    "                          on='file_id', how='inner')\n",
    "print(f'Rows after merging sample_id: {len(clf_data):,}')\n",
    "print(f'Unique samples: {clf_data[\"sample_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows mapped to a GTDB clade: 112,794 / 126,905 (88.9%)\n",
      "Fraction of total abundance covered by mapped taxa: 93.5%\n",
      "\n",
      "Mapping tier breakdown:\n",
      "mapping_tier\n",
      "genus_proxy_ambiguous    57355\n",
      "species_exact            51026\n",
      "NaN                      14111\n",
      "genus_proxy_unique        4413\n"
     ]
    }
   ],
   "source": [
    "# Join centrifuge taxa with taxon_bridge to get gtdb_species_clade_id\n",
    "# Use all mapped tiers (species_exact, genus_proxy_unique, genus_proxy_ambiguous)\n",
    "bridge_mapped = bridge[bridge['mapping_tier'] != 'unmapped'][[\n",
    "    'taxon_name', 'gtdb_species_clade_id', 'mapping_tier'\n",
    "]].dropna(subset=['gtdb_species_clade_id'])\n",
    "\n",
    "# For genus_proxy_ambiguous taxa, a single Centrifuge taxon name matches multiple GTDB clades\n",
    "# (one per genome in that genus).  We take ONE representative clade per taxon_name using\n",
    "# sort + drop_duplicates, which gives deterministic alphabetical tiebreaking on\n",
    "# gtdb_species_clade_id.  This is a conservative proxy; the sensitivity to this choice is\n",
    "# bounded by the genus_proxy_ambiguous fraction of mapped abundance (~6.5% of the 93.5%\n",
    "# mapped total, since most ambiguous matches are low-abundance taxa).  An\n",
    "# abundance-weighted mean across all matching clades is a suggested future improvement\n",
    "# (see REPORT.md Limitations).\n",
    "bridge_mapped = (\n",
    "    bridge_mapped\n",
    "    .sort_values('gtdb_species_clade_id')          # deterministic alphabetical tiebreak\n",
    "    .drop_duplicates(subset='taxon_name')\n",
    ")\n",
    "\n",
    "clf_bridged = clf_data.merge(bridge_mapped, on='taxon_name', how='left')\n",
    "\n",
    "n_mapped = clf_bridged['gtdb_species_clade_id'].notna().sum()\n",
    "n_total = len(clf_bridged)\n",
    "mapped_abund_frac = (\n",
    "    clf_bridged[clf_bridged['gtdb_species_clade_id'].notna()]['abundance'].sum()\n",
    "    / clf_bridged['abundance'].sum()\n",
    ")\n",
    "\n",
    "print(f'Rows mapped to a GTDB clade: {n_mapped:,} / {n_total:,} ({n_mapped/n_total:.1%})')\n",
    "print(f'Fraction of total abundance covered by mapped taxa: {mapped_abund_frac:.1%}')\n",
    "print('\\nMapping tier breakdown:')\n",
    "print(clf_bridged['mapping_tier'].value_counts(dropna=False).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after joining with completeness: 9,023,520\n",
      "Unique samples: 220\n",
      "Unique pathways: 80\n",
      "frac_complete dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Join with species pathway completeness\n",
    "# completeness table is keyed by gtdb_species_clade_id + pathway\n",
    "\n",
    "clf_with_completeness = clf_bridged[clf_bridged['gtdb_species_clade_id'].notna()].merge(\n",
    "    species_completeness[['gtdb_species_clade_id', 'pathway', 'metabolic_category',\n",
    "                           'frac_complete', 'frac_likely_complete', 'mean_best_score']],\n",
    "    on='gtdb_species_clade_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Defensive: cast Spark AVG/DECIMAL results to float.\n",
    "# Spark treats decimal literals like 1.0 as DECIMAL (not DOUBLE), so AVG(CASE WHEN ... THEN 1.0 ...)\n",
    "# returns decimal.Decimal in pandas, which fails in float arithmetic. CAST AS DOUBLE in cell-11\n",
    "# is the primary fix; this is a safety net for cached runs.\n",
    "for col in ['frac_complete', 'frac_likely_complete', 'mean_best_score']:\n",
    "    clf_with_completeness[col] = clf_with_completeness[col].astype(float)\n",
    "\n",
    "print(f'Rows after joining with completeness: {len(clf_with_completeness):,}')\n",
    "print(f'Unique samples: {clf_with_completeness[\"sample_id\"].nunique()}')\n",
    "print(f'Unique pathways: {clf_with_completeness[\"pathway\"].nunique()}')\n",
    "print(f'frac_complete dtype: {clf_with_completeness[\"frac_complete\"].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community matrix (long): 17,600 rows\n",
      "Samples: 220\n",
      "Pathways: 80\n",
      "       community_frac_complete  community_frac_likely_complete  n_mapped_taxa  total_mapped_abund\n",
      "count             17600.000000                    17600.000000   17600.000000        17600.000000\n",
      "mean                  0.699073                        0.766397     512.700000            0.935370\n",
      "std                   0.299451                        0.274886     313.274676            0.076067\n",
      "min                   0.000000                        0.000000       1.000000            0.314354\n",
      "25%                   0.486466                        0.621078     200.750000            0.899178\n",
      "50%                   0.801259                        0.894016     597.000000            0.960668\n",
      "75%                   0.963211                        0.982537     764.000000            0.986040\n",
      "max                   1.000000                        1.000000    1303.000000            1.000000\n"
     ]
    }
   ],
   "source": [
    "# Compute community-weighted pathway completeness per sample\n",
    "#\n",
    "# For each (sample, pathway):\n",
    "#   total_mapped_abund = Σ abundance_i  (only over taxa with a completeness score for this pathway)\n",
    "#   community_completeness = Σ (abundance_i / total_mapped_abund) × frac_complete_i\n",
    "#\n",
    "# This gives a value in [0,1]: fraction of community (by mapped abundance) with a complete pathway.\n",
    "\n",
    "# Step 1: total mapped abundance per sample per pathway (denominator)\n",
    "sample_pathway_totals = (\n",
    "    clf_with_completeness\n",
    "    .groupby(['sample_id', 'pathway'])['abundance']\n",
    "    .sum()\n",
    "    .rename('total_mapped_abund')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 2: merge denominator back and compute weighted completeness\n",
    "clf_w = clf_with_completeness.merge(sample_pathway_totals, on=['sample_id', 'pathway'])\n",
    "clf_w['weight'] = clf_w['abundance'] / clf_w['total_mapped_abund']\n",
    "clf_w['weighted_frac_complete'] = clf_w['weight'] * clf_w['frac_complete']\n",
    "clf_w['weighted_frac_likely_complete'] = clf_w['weight'] * clf_w['frac_likely_complete']\n",
    "\n",
    "# Step 3: aggregate by sample × pathway\n",
    "community_matrix_long = (\n",
    "    clf_w.groupby(['sample_id', 'pathway', 'metabolic_category'])\n",
    "    .agg(\n",
    "        community_frac_complete=('weighted_frac_complete', 'sum'),\n",
    "        community_frac_likely_complete=('weighted_frac_likely_complete', 'sum'),\n",
    "        n_mapped_taxa=('taxon_name', 'nunique'),\n",
    "        total_mapped_abund=('total_mapped_abund', 'first')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f'Community matrix (long): {len(community_matrix_long):,} rows')\n",
    "print(f'Samples: {community_matrix_long[\"sample_id\"].nunique()}')\n",
    "print(f'Pathways: {community_matrix_long[\"pathway\"].nunique()}')\n",
    "print(community_matrix_long.describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community pathway matrix (wide): (220, 81)\n",
      "  Samples: 220\n",
      "  Pathways: 80\n",
      "\n",
      "Mean community completeness per pathway (top 10 most complete):\n",
      "pathway\n",
      "gln            0.993833\n",
      "gly            0.987573\n",
      "threonine      0.976052\n",
      "chorismate     0.975708\n",
      "asn            0.974520\n",
      "met            0.973307\n",
      "thr            0.961732\n",
      "lys            0.961732\n",
      "cys            0.943909\n",
      "deoxyribose    0.932832\n",
      "\n",
      "Bottom 10 (least complete):\n",
      "pathway\n",
      "glucosamine      0.430226\n",
      "citrate          0.424053\n",
      "NAG              0.418123\n",
      "myoinositol      0.409428\n",
      "ribose           0.371778\n",
      "galacturonate    0.283137\n",
      "mannitol         0.250467\n",
      "D-serine         0.218830\n",
      "xylitol          0.094513\n",
      "glucose-6-P      0.011889\n"
     ]
    }
   ],
   "source": [
    "# Pivot to wide format: samples (rows) × pathways (columns)\n",
    "community_matrix_wide = community_matrix_long.pivot_table(\n",
    "    index='sample_id',\n",
    "    columns='pathway',\n",
    "    values='community_frac_complete',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "print(f'Community pathway matrix (wide): {community_matrix_wide.shape}')\n",
    "print(f'  Samples: {len(community_matrix_wide)}')\n",
    "print(f'  Pathways: {community_matrix_wide.shape[1] - 1}')\n",
    "\n",
    "# Summary: completeness score distributions\n",
    "pathway_cols = [c for c in community_matrix_wide.columns if c != 'sample_id']\n",
    "print(f'\\nMean community completeness per pathway (top 10 most complete):')\n",
    "pathway_means = community_matrix_wide[pathway_cols].mean().sort_values(ascending=False)\n",
    "print(pathway_means.head(10).to_string())\n",
    "print(f'\\nBottom 10 (least complete):')\n",
    "print(pathway_means.tail(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ecosystem metadata: 6361 rows\n",
      "ecosystem_type distribution:\n",
      "ecosystem_type\n",
      "NaN             5659\n",
      "Soil             348\n",
      "Freshwater       325\n",
      "Unclassified      29\n"
     ]
    }
   ],
   "source": [
    "# Add ecosystem type from omics_files_table (has study_id) + study_table\n",
    "# Use study_id from omics_files_table → join to study_table → get ecosystem_category, ecosystem_type\n",
    "\n",
    "sample_study = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT b.sample_id, b.study_id\n",
    "    FROM nmdc_arkin.omics_files_table b\n",
    "    JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.centrifuge_gold) c ON b.file_id = c.file_id\n",
    "    WHERE b.sample_id IS NOT NULL AND b.study_id IS NOT NULL\n",
    "\"\"\").toPandas()\n",
    "\n",
    "study_meta = spark.sql(\"\"\"\n",
    "    SELECT study_id, ecosystem_category, ecosystem_type, ecosystem_subtype, specific_ecosystem\n",
    "    FROM nmdc_arkin.study_table\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Join sample_study → study_meta\n",
    "sample_ecosystem = sample_study.merge(study_meta, on='study_id', how='left')\n",
    "# Keep only one row per sample_id (take first study_id if multiple)\n",
    "sample_ecosystem = (\n",
    "    sample_ecosystem\n",
    "    .sort_values('study_id')\n",
    "    .drop_duplicates(subset='sample_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f'Sample ecosystem metadata: {len(sample_ecosystem)} rows')\n",
    "print('ecosystem_type distribution:')\n",
    "print(sample_ecosystem['ecosystem_type'].value_counts(dropna=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community matrix with ecosystem: (220, 86)\n",
      "ecosystem_type counts for overlap samples:\n",
      "ecosystem_type\n",
      "Soil          126\n",
      "NaN            61\n",
      "Freshwater     33\n"
     ]
    }
   ],
   "source": [
    "# Merge ecosystem metadata into community_matrix_wide\n",
    "community_matrix_wide = community_matrix_wide.merge(\n",
    "    sample_ecosystem[['sample_id', 'study_id', 'ecosystem_category',\n",
    "                       'ecosystem_type', 'ecosystem_subtype', 'specific_ecosystem']],\n",
    "    on='sample_id', how='left'\n",
    ")\n",
    "\n",
    "print(f'Community matrix with ecosystem: {community_matrix_wide.shape}')\n",
    "print('ecosystem_type counts for overlap samples:')\n",
    "print(community_matrix_wide['ecosystem_type'].value_counts(dropna=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Heatmap — Mean Completeness by Pathway × Ecosystem Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap: 80 pathways × 3 ecosystem types\n",
      "            Freshwater      Soil   Unknown\n",
      "pathway                                   \n",
      "arg           0.704788  0.700501  0.869116\n",
      "asn           0.915418  0.985185  0.984465\n",
      "chorismate    0.971439  0.969769  0.990285\n",
      "cys           0.892817  0.955455  0.947699\n",
      "gln           0.992820  0.995030  0.991910\n"
     ]
    }
   ],
   "source": [
    "# Compute mean community completeness per pathway × ecosystem_type\n",
    "# Use long-format matrix (includes metabolic_category for ordering)\n",
    "\n",
    "# Merge ecosystem into long format\n",
    "community_long_eco = community_matrix_long.merge(\n",
    "    sample_ecosystem[['sample_id', 'ecosystem_type']],\n",
    "    on='sample_id', how='left'\n",
    ")\n",
    "community_long_eco['ecosystem_type'] = community_long_eco['ecosystem_type'].fillna('Unknown')\n",
    "\n",
    "# Mean completeness per pathway × ecosystem_type\n",
    "heatmap_data = (\n",
    "    community_long_eco\n",
    "    .groupby(['pathway', 'metabolic_category', 'ecosystem_type'])['community_frac_complete']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'community_frac_complete': 'mean_completeness'})\n",
    ")\n",
    "\n",
    "# Pivot for heatmap\n",
    "heatmap_pivot = heatmap_data.pivot_table(\n",
    "    index='pathway',\n",
    "    columns='ecosystem_type',\n",
    "    values='mean_completeness'\n",
    ")\n",
    "\n",
    "# Sort pathways by metabolic_category then by mean completeness\n",
    "pathway_category = community_long_eco[['pathway', 'metabolic_category']].drop_duplicates()\n",
    "heatmap_pivot = heatmap_pivot.join(\n",
    "    pathway_category.set_index('pathway')['metabolic_category']\n",
    ").sort_values(['metabolic_category', 'pathway']).drop(columns='metabolic_category')\n",
    "\n",
    "print(f'Heatmap: {heatmap_pivot.shape[0]} pathways × {heatmap_pivot.shape[1]} ecosystem types')\n",
    "print(heatmap_pivot.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/pathway_completeness_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# Plot heatmap: pathways (rows) × ecosystem types (columns)\n",
    "n_pathways_plot = heatmap_pivot.shape[0]\n",
    "n_ecosystems = heatmap_pivot.shape[1]\n",
    "\n",
    "fig_height = max(8, n_pathways_plot * 0.22)\n",
    "fig, ax = plt.subplots(figsize=(max(6, n_ecosystems * 1.5), fig_height))\n",
    "\n",
    "sns.heatmap(\n",
    "    heatmap_pivot,\n",
    "    ax=ax,\n",
    "    cmap='YlOrRd',\n",
    "    vmin=0, vmax=1,\n",
    "    linewidths=0.3,\n",
    "    linecolor='white',\n",
    "    annot=(n_pathways_plot <= 30),  # only annotate if <= 30 pathways\n",
    "    fmt='.2f' if n_pathways_plot <= 30 else '',\n",
    "    cbar_kws={'label': 'Mean community pathway completeness'},\n",
    ")\n",
    "\n",
    "ax.set_title('Community Pathway Completeness by Ecosystem Type', fontsize=13, pad=12)\n",
    "ax.set_xlabel('Ecosystem type', fontsize=11)\n",
    "ax.set_ylabel('Pathway', fontsize=11)\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "ax.tick_params(axis='x', labelsize=9, rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(FIGURES_DIR, 'pathway_completeness_heatmap.png')\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Saved: figures/pathway_completeness_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/community_pathway_matrix.csv\n",
      "  Shape: (220, 86)\n",
      "  Samples: 220\n",
      "  Pathway columns: 80\n",
      "Saved: data/community_pathway_matrix_long.csv (17,600 rows)\n"
     ]
    }
   ],
   "source": [
    "# Save community pathway matrix (wide format — used in NB05 statistical analysis)\n",
    "matrix_path = os.path.join(DATA_DIR, 'community_pathway_matrix.csv')\n",
    "community_matrix_wide.to_csv(matrix_path, index=False)\n",
    "print(f'Saved: data/community_pathway_matrix.csv')\n",
    "print(f'  Shape: {community_matrix_wide.shape}')\n",
    "print(f'  Samples: {community_matrix_wide[\"sample_id\"].nunique()}')\n",
    "print(f'  Pathway columns: {len(pathway_cols)}')\n",
    "\n",
    "# Save long-format community matrix (useful for NB05 joins and groupby)\n",
    "long_path = os.path.join(DATA_DIR, 'community_pathway_matrix_long.csv')\n",
    "community_matrix_long.to_csv(long_path, index=False)\n",
    "print(f'Saved: data/community_pathway_matrix_long.csv ({len(community_matrix_long):,} rows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB03 Summary ===\n",
      "Overlap samples with pathway completeness data: 220\n",
      "Pathways computed: 80\n",
      "Metabolic categories: ['carbon', 'aa']\n",
      "Amino acid (aa) pathways: 18\n",
      "\n",
      "Mean community completeness across all samples (frac_complete):\n",
      "  All pathways: 0.699\n",
      "  Amino acid (aa) pathways: 0.851\n",
      "\n",
      "Ecosystem breakdown for overlap samples:\n",
      "ecosystem_category  ecosystem_type\n",
      "Terrestrial         Soil              126\n",
      "NaN                 NaN                61\n",
      "Aquatic             Freshwater         33\n"
     ]
    }
   ],
   "source": [
    "# Summary: key statistics for NB05\n",
    "print('=== NB03 Summary ===')\n",
    "print(f'Overlap samples with pathway completeness data: {community_matrix_wide[\"sample_id\"].nunique()}')\n",
    "print(f'Pathways computed: {len(pathway_cols)}')\n",
    "print(f'Metabolic categories: {community_long_eco[\"metabolic_category\"].unique().tolist()}')\n",
    "\n",
    "# metabolic_category values in gapmind_pathways are 'aa' and 'carbon' (not 'amino_acid')\n",
    "aa_mask = community_long_eco['metabolic_category'] == 'aa'\n",
    "n_aa_pathways = community_long_eco.loc[aa_mask, 'pathway'].nunique() if aa_mask.sum() > 0 else 0\n",
    "print(f'Amino acid (aa) pathways: {n_aa_pathways}')\n",
    "print()\n",
    "print('Mean community completeness across all samples (frac_complete):')\n",
    "print(f'  All pathways: {community_matrix_long[\"community_frac_complete\"].mean():.3f}')\n",
    "if aa_mask.sum() > 0:\n",
    "    print(f'  Amino acid (aa) pathways: '\n",
    "          f'{community_long_eco.loc[aa_mask, \"community_frac_complete\"].mean():.3f}')\n",
    "print()\n",
    "print('Ecosystem breakdown for overlap samples:')\n",
    "print(community_matrix_wide[['ecosystem_category', 'ecosystem_type']]\n",
    "      .value_counts(dropna=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Decisions for NB04\n",
    "\n",
    "| Question | Finding |\n",
    "|---|---|\n",
    "| Samples in community matrix | 220 |\n",
    "| Pathways computed | 80 (18 aa, 62 carbon) |\n",
    "| Amino acid pathways | 18 |\n",
    "| Mean community completeness (all pathways) | 0.699 |\n",
    "| Mean community completeness (AA pathways) | 0.851 |\n",
    "| Ecosystem types represented | Soil: 126, Freshwater: 33, Unknown: 61 |\n",
    "| Metabolic categories in GapMind | `'aa'` and `'carbon'` (not `'amino_acid'`) |\n",
    "\n",
    "**Decision for NB04**:  \n",
    "Proceed to metabolomics processing using `data/community_pathway_matrix.csv`.  \n",
    "Join with `metabolomics_gold` on `met_file_id` from `nmdc_sample_inventory.csv`.  \n",
    "Target amino acid compounds from `metabolomics_gold` for the Black Queen test (H1).  \n",
    "Use `frac_complete` (GapMind score ≥ 5, i.e., only genomes scored \"complete\") as the  \n",
    "primary metric; `frac_likely_complete` (score ≥ 4) is also computed for sensitivity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
