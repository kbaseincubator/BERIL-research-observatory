{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB01: NMDC Schema Exploration and Sample Inventory\n",
    "\n",
    "**Project**: Community Metabolic Ecology via NMDC × Pangenome Integration  \n",
    "**Requires**: BERDL JupyterHub (Spark — `get_spark_session()` injected into kernel)  \n",
    "\n",
    "## Purpose\n",
    "\n",
    "Gate notebook for the project. Before writing NB02–NB05, we must verify:\n",
    "\n",
    "1. Column names in `nmdc_arkin.study_table`, `taxonomy_features`, and `metabolomics_gold`  \n",
    "   (not fully documented in schema docs)\n",
    "2. Whether `sample_id` values are prefixed with `study_id` (Query 1 depends on this)\n",
    "3. Whether `taxonomy_features` provides relative abundances or raw read counts\n",
    "4. Whether `metabolomics_gold` carries KEGG/ChEBI compound IDs in its own columns\n",
    "5. Which taxonomy classifier (kraken_gold, centrifuge_gold, gottcha_gold, taxonomy_features)  \n",
    "   provides the most species-level resolution\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `data/nmdc_sample_inventory.csv` — samples with paired taxonomy + metabolomics\n",
    "- `data/nmdc_taxonomy_coverage.csv` — per-sample taxonomy stats per classifier\n",
    "- `data/nmdc_metabolomics_coverage.csv` — per-sample compound counts and annotation rates\n",
    "- `figures/nmdc_sample_coverage.png` — ecosystem type distribution and sample overlap\n",
    "\n",
    "## Key Decisions to Make\n",
    "\n",
    "- Which taxonomy classifier to use in NB02?\n",
    "- Is normalization needed before computing community-weighted completeness (NB03)?\n",
    "- How to map metabolomics compounds to amino acid identity (Plan A: KEGG IDs; Plan B: name matching)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On BERDL JupyterHub — get_spark_session() is injected into the kernel; no import needed\n",
    "spark = get_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn  # pip install matplotlib-venn if needed\n",
    "\n",
    "# Paths (relative to project root — adjust if running from a different cwd)\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "FIGURES_DIR = os.path.join(PROJECT_DIR, 'figures')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'FIGURES_DIR: {FIGURES_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Schema Verification\n",
    "\n",
    "Verify column names before building any dependent queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1a: study_table — confirm study_id, ecosystem_category, ecosystem_type\n",
    "print('=== nmdc_arkin.study_table schema ===')\n",
    "spark.sql('DESCRIBE nmdc_arkin.study_table').show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b: taxonomy_features — confirm sample_id column, taxon/abundance columns\n",
    "print('=== nmdc_arkin.taxonomy_features schema ===')\n",
    "spark.sql('DESCRIBE nmdc_arkin.taxonomy_features').show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1c: metabolomics_gold — look for KEGG/ChEBI compound ID columns\n",
    "print('=== nmdc_arkin.metabolomics_gold schema ===')\n",
    "spark.sql('DESCRIBE nmdc_arkin.metabolomics_gold').show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1d: Inspect raw sample_id and study_id values to check prefix format\n",
    "# This determines whether LIKE CONCAT(study_id, '%') join works\n",
    "print('=== Sample study_table values ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.study_table\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "print('\\n=== Sample taxonomy_features sample_id values ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT sample_id\n",
    "    FROM nmdc_arkin.taxonomy_features\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "print('\\n=== Sample metabolomics_gold sample_id values ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    LIMIT 3\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1e: Check taxonomy classifiers for available rank columns\n",
    "for tbl in ['kraken_gold', 'centrifuge_gold', 'gottcha_gold']:\n",
    "    try:\n",
    "        print(f'\\n=== nmdc_arkin.{tbl} schema ===')\n",
    "        spark.sql(f'DESCRIBE nmdc_arkin.{tbl}').show(30, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR describing {tbl}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Study and Sample Inventory\n",
    "\n",
    "How many studies exist? What ecosystems are covered? How many samples have paired taxonomy + metabolomics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All studies with row count\n",
    "study_df = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.study_table\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Total studies: {len(study_df)}')\n",
    "print(study_df.columns.tolist())\n",
    "study_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples with taxonomy profiles\n",
    "n_tax_samples = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT sample_id) as n\n",
    "    FROM nmdc_arkin.taxonomy_features\n",
    "\"\"\").collect()[0]['n']\n",
    "\n",
    "# Count samples with metabolomics data\n",
    "n_met_samples = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT sample_id) as n\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "\"\"\").collect()[0]['n']\n",
    "\n",
    "print(f'Samples with taxonomy profiles:  {n_tax_samples}')\n",
    "print(f'Samples with metabolomics data:  {n_met_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples with BOTH taxonomy AND metabolomics\n",
    "overlap_df = spark.sql(\"\"\"\n",
    "    SELECT tf.sample_id\n",
    "    FROM nmdc_arkin.taxonomy_features tf\n",
    "    JOIN nmdc_arkin.metabolomics_gold mg ON tf.sample_id = mg.sample_id\n",
    "    GROUP BY tf.sample_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Samples with BOTH taxonomy AND metabolomics: {len(overlap_df)}')\n",
    "overlap_samples = set(overlap_df['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to join samples to study metadata\n",
    "# NOTE: The join key between samples and studies is unknown until schema is verified above.\n",
    "# Update STUDY_ID_COL and SAMPLE_STUDY_COL based on Part 1 findings.\n",
    "# Placeholder: inspect sample_id prefix manually to determine join strategy.\n",
    "\n",
    "# Show a few overlap sample IDs alongside study IDs to check prefix patterns\n",
    "print('Overlap sample_id examples:')\n",
    "print(overlap_df['sample_id'].head(15).tolist())\n",
    "print('\\nStudy ID examples (from study_table):')\n",
    "# Use whatever column was found in Part 1 step 1d\n",
    "print(study_df.iloc[:5, 0].tolist() if len(study_df) > 0 else '(no studies found)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abiotic features for overlap samples\n",
    "abiotic_df = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.abiotic_features\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Total abiotic_features samples: {len(abiotic_df)}')\n",
    "abiotic_overlap = abiotic_df[abiotic_df['sample_id'].isin(overlap_samples)]\n",
    "print(f'Abiotic features for overlap samples: {len(abiotic_overlap)}')\n",
    "print(abiotic_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Taxonomy Classifier Comparison\n",
    "\n",
    "Which classifier (kraken_gold, centrifuge_gold, gottcha_gold, taxonomy_features) provides the most species-level resolution in overlap samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess species-level resolution per classifier for overlap samples\n",
    "# Columns vary by classifier — update RANK_COL and TAXON_COL after Part 1 schema review\n",
    "\n",
    "def assess_classifier(table_name, sample_col='sample_id', rank_col=None, taxon_col=None):\n",
    "    \"\"\"\n",
    "    Returns per-sample stats: n_unique_taxa, fraction_with_species_rank.\n",
    "    rank_col: column containing taxonomic rank label (e.g., 'rank' or 'taxon_rank')\n",
    "    taxon_col: column containing taxon name\n",
    "    Update based on DESCRIBE output from Part 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = spark.sql(f'SELECT * FROM nmdc_arkin.{table_name} LIMIT 5')\n",
    "        print(f'\\n--- {table_name} sample rows ---')\n",
    "        df.show(truncate=False)\n",
    "        cols = df.columns\n",
    "        print(f'Columns: {cols}')\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR accessing {table_name}: {e}')\n",
    "\n",
    "for tbl in ['kraken_gold', 'centrifuge_gold', 'gottcha_gold', 'taxonomy_features']:\n",
    "    assess_classifier(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inspecting columns above, fill in the correct rank/taxon column names.\n",
    "# This cell is a placeholder — complete after Part 1 + Part 3 assessment above.\n",
    "#\n",
    "# Example (update column names to match actual schema):\n",
    "#\n",
    "# RANK_COL = 'rank'        # e.g., 'species', 'genus', 'family'\n",
    "# TAXON_COL = 'taxon_name' # taxon name string\n",
    "# ABUND_COL = 'abundance'  # relative abundance or read count\n",
    "#\n",
    "# species_frac = spark.sql(f\"\"\"\n",
    "#     SELECT\n",
    "#         COUNT(CASE WHEN LOWER({RANK_COL}) = 'species' THEN 1 END) as n_species_rows,\n",
    "#         COUNT(*) as n_total_rows,\n",
    "#         COUNT(CASE WHEN LOWER({RANK_COL}) = 'species' THEN 1 END) / COUNT(*) as species_frac\n",
    "#     FROM nmdc_arkin.kraken_gold\n",
    "# \"\"\").toPandas()\n",
    "# display(species_frac)\n",
    "\n",
    "print('TODO: Fill in RANK_COL, TAXON_COL, ABUND_COL based on schema review above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Metabolomics Coverage\n",
    "\n",
    "What fraction of measured compounds carry KEGG/ChEBI compound IDs (needed for amino acid matching in NB04)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-sample compound counts and annotation rates\n",
    "# Update column names based on metabolomics_gold DESCRIBE output (Part 1 step 1c)\n",
    "\n",
    "met_sample_stats = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        sample_id,\n",
    "        COUNT(*) as n_compounds_total\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    GROUP BY sample_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Samples with metabolomics: {len(met_sample_stats)}')\n",
    "print(f'Compounds per sample — median: {met_sample_stats[\"n_compounds_total\"].median():.0f}, '\n",
    "      f'max: {met_sample_stats[\"n_compounds_total\"].max()}')\n",
    "met_sample_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for KEGG/ChEBI annotation columns in metabolomics_gold\n",
    "# After seeing the schema in Part 1, identify candidate columns for compound annotation.\n",
    "# This cell searches for columns whose names suggest compound IDs.\n",
    "\n",
    "met_cols = spark.sql('DESCRIBE nmdc_arkin.metabolomics_gold').toPandas()\n",
    "candidate_id_cols = met_cols[\n",
    "    met_cols['col_name'].str.lower().str.contains(\n",
    "        'kegg|chebi|compound|id|inchi|smiles|name|annotation', na=False\n",
    "    )\n",
    "]\n",
    "print('Candidate compound ID columns:')\n",
    "print(candidate_id_cols[['col_name', 'data_type']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation rate: fraction of metabolomics rows with a non-null compound ID\n",
    "# Update COMPOUND_ID_COL to the actual column name found above.\n",
    "#\n",
    "# COMPOUND_ID_COL = 'kegg_id'  # UPDATE THIS\n",
    "#\n",
    "# annotation_rate = spark.sql(f\"\"\"\n",
    "#     SELECT\n",
    "#         COUNT(CASE WHEN {COMPOUND_ID_COL} IS NOT NULL AND {COMPOUND_ID_COL} != '' THEN 1 END) as n_annotated,\n",
    "#         COUNT(*) as n_total,\n",
    "#         COUNT(CASE WHEN {COMPOUND_ID_COL} IS NOT NULL AND {COMPOUND_ID_COL} != '' THEN 1 END)\n",
    "#             / COUNT(*) as annotation_rate\n",
    "#     FROM nmdc_arkin.metabolomics_gold\n",
    "# \"\"\").toPandas()\n",
    "# print(annotation_rate)\n",
    "\n",
    "# For now, inspect a sample of rows to see what annotation looks like\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n",
    "print('TODO: Set COMPOUND_ID_COL after reviewing column names above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for amino acid compound names via string matching (Plan B fallback)\n",
    "AMINO_ACIDS = [\n",
    "    'alanine', 'arginine', 'asparagine', 'aspartate', 'aspartic acid',\n",
    "    'cysteine', 'glutamate', 'glutamic acid', 'glutamine', 'glycine',\n",
    "    'histidine', 'isoleucine', 'leucine', 'lysine', 'methionine',\n",
    "    'phenylalanine', 'proline', 'serine', 'threonine', 'tryptophan',\n",
    "    'tyrosine', 'valine'\n",
    "]\n",
    "\n",
    "# Try to find a compound name column and check for amino acid hits\n",
    "# Update NAME_COL based on schema review\n",
    "# NAME_COL = 'compound_name'  # UPDATE THIS\n",
    "#\n",
    "# aa_pattern = '|'.join(AMINO_ACIDS)\n",
    "# aa_hits = spark.sql(f\"\"\"\n",
    "#     SELECT {NAME_COL}, COUNT(DISTINCT sample_id) as n_samples\n",
    "#     FROM nmdc_arkin.metabolomics_gold\n",
    "#     WHERE LOWER({NAME_COL}) RLIKE '{aa_pattern}'\n",
    "#     GROUP BY {NAME_COL}\n",
    "#     ORDER BY n_samples DESC\n",
    "# \"\"\").toPandas()\n",
    "# print(f'Amino acid compound hits: {len(aa_hits)}')\n",
    "# display(aa_hits.head(20))\n",
    "print(f'Amino acids to search for: {AMINO_ACIDS}')\n",
    "print('TODO: Set NAME_COL after reviewing metabolomics_gold columns above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Save Outputs and Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample inventory\n",
    "inventory = pd.DataFrame({'sample_id': list(overlap_samples)})\n",
    "inventory['has_taxonomy'] = True\n",
    "inventory['has_metabolomics'] = True\n",
    "\n",
    "# Merge abiotic features (ecosystem type) for overlap samples\n",
    "if len(abiotic_overlap) > 0:\n",
    "    inventory = inventory.merge(abiotic_overlap[['sample_id'] + \n",
    "        [c for c in abiotic_overlap.columns if c != 'sample_id']], \n",
    "        on='sample_id', how='left')\n",
    "\n",
    "inventory.to_csv(os.path.join(DATA_DIR, 'nmdc_sample_inventory.csv'), index=False)\n",
    "print(f'Saved: data/nmdc_sample_inventory.csv ({len(inventory)} rows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metabolomics coverage stats\n",
    "met_overlap = met_sample_stats[met_sample_stats['sample_id'].isin(overlap_samples)].copy()\n",
    "met_overlap.to_csv(os.path.join(DATA_DIR, 'nmdc_metabolomics_coverage.csv'), index=False)\n",
    "print(f'Saved: data/nmdc_metabolomics_coverage.csv ({len(met_overlap)} rows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Sample counts by data type and ecosystem type\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('NMDC Sample Coverage', fontsize=14)\n",
    "\n",
    "# Panel 1: Venn-style bar chart (simple counts)\n",
    "ax = axes[0]\n",
    "counts = {\n",
    "    'Taxonomy only': n_tax_samples - len(overlap_samples),\n",
    "    'Metabolomics only': n_met_samples - len(overlap_samples),\n",
    "    'Both (overlap)': len(overlap_samples)\n",
    "}\n",
    "bars = ax.bar(list(counts.keys()), list(counts.values()), \n",
    "              color=['#4C9BE8', '#E88C4C', '#6EC46E'], edgecolor='white')\n",
    "ax.set_ylabel('Number of samples')\n",
    "ax.set_title('Sample data availability')\n",
    "for bar, val in zip(bars, counts.values()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "            str(val), ha='center', va='bottom', fontsize=10)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Panel 2: Metabolomics compound count distribution for overlap samples\n",
    "ax2 = axes[1]\n",
    "if len(met_overlap) > 0:\n",
    "    ax2.hist(met_overlap['n_compounds_total'], bins=30, color='#6EC46E', edgecolor='white')\n",
    "    ax2.set_xlabel('Compounds per sample')\n",
    "    ax2.set_ylabel('Number of samples')\n",
    "    ax2.set_title('Metabolomics compound counts\\n(overlap samples)')\n",
    "    ax2.axvline(met_overlap['n_compounds_total'].median(), color='black',\n",
    "                linestyle='--', label=f'Median: {met_overlap[\"n_compounds_total\"].median():.0f}')\n",
    "    ax2.legend()\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No overlap samples found', ha='center', va='center',\n",
    "             transform=ax2.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(FIGURES_DIR, 'nmdc_sample_coverage.png')\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Saved: figures/nmdc_sample_coverage.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Decisions for NB02\n",
    "\n",
    "Fill in after running all cells:\n",
    "\n",
    "| Question | Finding |\n",
    "|---|---|\n",
    "| Samples with taxonomy | ??? |\n",
    "| Samples with metabolomics | ??? |\n",
    "| Overlap (both) | ??? |\n",
    "| Best taxonomy classifier | ??? (kraken / centrifuge / gottcha / taxonomy_features) |\n",
    "| Taxonomy resolution | ??? (genus-level only / species-level available) |\n",
    "| Taxonomy values = relative abundance? | ??? (yes / no — normalization needed) |\n",
    "| Metabolomics compound IDs available? | ??? (KEGG IDs in column ___ / name matching only) |\n",
    "| Amino acid metabolites found? | ??? compounds matching AA names |\n",
    "| Study → sample ID join strategy | ??? (prefix match / explicit study_id column / other) |\n",
    "\n",
    "**Decision for NB02**: Use `___` classifier. Bridge at `___` level. Expected bridge coverage: ???%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
