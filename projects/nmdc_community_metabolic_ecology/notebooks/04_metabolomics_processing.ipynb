{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB04: Metabolomics Processing\n",
    "\n",
    "**Project**: Community Metabolic Ecology via NMDC × Pangenome Integration  \n",
    "**Requires**: BERDL JupyterHub (Spark — `get_spark_session()` injected into kernel)\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Extract and process NMDC metabolomics data for the 220 overlap samples.\n",
    "Map detected compounds to amino acid categories matching GapMind `'aa'` pathways.\n",
    "Merge metabolomics + community pathway completeness + abiotic features into\n",
    "a single analysis-ready matrix for NB05.\n",
    "\n",
    "**Key decisions carried in from NB03**:\n",
    "- 220 overlap samples (centrifuge + metabolomics, passing bridge QC)\n",
    "- 18 GapMind amino acid pathways: `arg asn chorismate cys gln gly his ile leu lys met phe pro ser thr trp tyr val`\n",
    "- Each sample has 1–4 met files (avg 2.9); HILICZ_POS and C18_POS/NEG fractions\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- `data/nmdc_sample_inventory.csv` — sample × clf_file × met_file mapping\n",
    "- `data/bridge_quality.csv` — per-file bridge QC flags\n",
    "- `data/community_pathway_matrix.csv` — NB03 output (220 samples × 80 pathways)\n",
    "- `nmdc_arkin.metabolomics_gold` — 3.1M rows of measured metabolite features\n",
    "- `nmdc_arkin.abiotic_features` — environmental measurements (pH, temp, etc.)\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `data/metabolomics_matrix.csv` — per-sample × per-compound normalized intensities\n",
    "- `data/amino_acid_metabolites.csv` — subset: amino acid compounds with pathway mapping\n",
    "- `data/analysis_ready_matrix.csv` — merged: pathway completeness + metabolomics + abiotic\n",
    "- `figures/metabolomics_distribution.png` — compound abundance distributions by ecosystem type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On BERDL JupyterHub — get_spark_session() is injected into the kernel; no import needed\n",
    "spark = get_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "DATA_DIR    = os.path.join(PROJECT_DIR, 'data')\n",
    "FIGURES_DIR = os.path.join(PROJECT_DIR, 'figures')\n",
    "BRIDGE_TBL  = 'nmdc_arkin.omics_files_table'\n",
    "\n",
    "print(f'DATA_DIR:    {DATA_DIR}')\n",
    "print(f'FIGURES_DIR: {FIGURES_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load NB02/NB03 Outputs and Identify Met Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory     = pd.read_csv(os.path.join(DATA_DIR, 'nmdc_sample_inventory.csv'))\n",
    "bridge_quality = pd.read_csv(os.path.join(DATA_DIR, 'bridge_quality.csv'))\n",
    "community_matrix = pd.read_csv(os.path.join(DATA_DIR, 'community_pathway_matrix.csv'))\n",
    "\n",
    "# Overlap samples = those whose clf_file passes bridge QC\n",
    "qc_pass_files   = set(bridge_quality[bridge_quality['passes_bridge_qc']]['file_id'])\n",
    "overlap_samples = set(\n",
    "    inventory[inventory['clf_file_id'].isin(qc_pass_files)]['sample_id']\n",
    ")\n",
    "print(f'Overlap samples: {len(overlap_samples)}')\n",
    "print(f'Community matrix samples: {community_matrix[\"sample_id\"].nunique()}')\n",
    "\n",
    "# Met file IDs for overlap samples (may be multiple per sample)\n",
    "overlap_inv = inventory[inventory['sample_id'].isin(overlap_samples)].copy()\n",
    "overlap_met_file_ids = overlap_inv['met_file_id'].unique().tolist()\n",
    "print(f'\\nUnique met_file_ids for overlap samples: {len(overlap_met_file_ids)}')\n",
    "print(f'Met files per sample: avg={len(overlap_met_file_ids)/len(overlap_samples):.1f}')\n",
    "\n",
    "# Ionization mode / column breakdown from file names\n",
    "fnames = overlap_inv['met_file_name']\n",
    "print(f'\\nFile name patterns:')\n",
    "print(f'  HILICZ: {fnames.str.contains(\"HILICZ\", na=False).sum()}')\n",
    "print(f'  C18:    {fnames.str.contains(\"C18\", na=False).sum()}')\n",
    "print(f'  POS:    {fnames.str.contains(\"_POS_\", na=False).sum()}')\n",
    "print(f'  NEG:    {fnames.str.contains(\"_NEG_\", na=False).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Explore `metabolomics_gold` Schema\n",
    "\n",
    "Determine column names before building the extraction query.\n",
    "Key unknowns: compound name column, intensity/abundance column, any KEGG ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== metabolomics_gold schema ===')\n",
    "spark.sql('DESCRIBE nmdc_arkin.metabolomics_gold').show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 5 rows to understand data layout\n",
    "# Use LIMIT — metabolomics_gold has 3.1M rows\n",
    "print('=== Sample rows from metabolomics_gold ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the file_id format for metabolomics_gold (expect nmdc:dobj-12-* prefix)\n",
    "print('=== file_id format in metabolomics_gold ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT file_id, COUNT(*) as n\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    GROUP BY file_id\n",
    "    ORDER BY n DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "# Check total rows for overlap met_file_ids\n",
    "# Build a small validation using one sample met_file_id\n",
    "sample_met_id = overlap_met_file_ids[0]\n",
    "print(f'\\nRow count for one sample met file ({sample_met_id}):')\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) as n\n",
    "    FROM nmdc_arkin.metabolomics_gold\n",
    "    WHERE file_id = '{sample_met_id}'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Extract Metabolomics Data for Overlap Samples\n",
    "\n",
    "Use the INTERSECT subquery pattern to filter to overlap samples\n",
    "(avoids pandas→Spark roundtrip / ChunkedArray issues).\n",
    "\n",
    "**Column names below use placeholders** — update after schema inspection in Part 2:\n",
    "- `COMPOUND_COL`: the compound name column  \n",
    "- `INTENSITY_COL`: the abundance/intensity column  \n",
    "- Add `KEGG_COL` if a KEGG compound ID column exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Set column names based on schema inspection above ──────────────────────\n",
    "# Update these after running Part 2.\n",
    "# Common NMDC metabolomics_gold column names (verify from DESCRIBE output):\n",
    "#   compound name: 'compound_name', 'metabolite_name', 'feature_name', 'name'\n",
    "#   intensity:     'abundance', 'intensity', 'peak_area', 'normalized_abundance'\n",
    "#   KEGG ID:       'kegg_id', 'compound_id', 'annotation_id' (may not exist)\n",
    "# ---------------------------------------------------------------------------\n",
    "COMPOUND_COL  = 'compound_name'     # UPDATE if different\n",
    "INTENSITY_COL = 'abundance'         # UPDATE if different\n",
    "KEGG_COL      = None                # Set to column name if KEGG IDs exist\n",
    "\n",
    "print(f'Using compound column:  {COMPOUND_COL}')\n",
    "print(f'Using intensity column: {INTENSITY_COL}')\n",
    "print(f'KEGG ID column:         {KEGG_COL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SELECT clause (include KEGG_COL only if it exists)\n",
    "kegg_select = f', m.{KEGG_COL} AS kegg_id' if KEGG_COL else ''\n",
    "\n",
    "# Extract metabolomics data for overlap samples via Spark.\n",
    "# Filter: INTERSECT of samples with centrifuge + metabolomics files\n",
    "# Cast intensity to DOUBLE to avoid decimal.Decimal arithmetic errors\n",
    "met_spark = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        b.sample_id,\n",
    "        m.file_id,\n",
    "        m.{COMPOUND_COL} AS compound_name,\n",
    "        CAST(m.{INTENSITY_COL} AS DOUBLE) AS intensity\n",
    "        {kegg_select}\n",
    "    FROM nmdc_arkin.metabolomics_gold m\n",
    "    JOIN {BRIDGE_TBL} b ON m.file_id = b.file_id\n",
    "    WHERE b.sample_id IN (\n",
    "        SELECT b2.sample_id FROM {BRIDGE_TBL} b2\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.centrifuge_gold) c2\n",
    "          ON b2.file_id = c2.file_id\n",
    "        INTERSECT\n",
    "        SELECT b3.sample_id FROM {BRIDGE_TBL} b3\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.metabolomics_gold) m3\n",
    "          ON b3.file_id = m3.file_id\n",
    "    )\n",
    "    AND m.{COMPOUND_COL} IS NOT NULL\n",
    "    AND m.{COMPOUND_COL} != ''\n",
    "    AND m.{INTENSITY_COL} IS NOT NULL\n",
    "    AND CAST(m.{INTENSITY_COL} AS DOUBLE) > 0\n",
    "\"\"\")\n",
    "\n",
    "print('Collecting metabolomics data (may take a few minutes)...')\n",
    "met_raw = met_spark.toPandas()\n",
    "met_raw['intensity'] = met_raw['intensity'].astype(float)  # defensive cast\n",
    "\n",
    "print(f'\\nMetabolomics rows: {len(met_raw):,}')\n",
    "print(f'Unique samples:   {met_raw[\"sample_id\"].nunique()}')\n",
    "print(f'Unique files:     {met_raw[\"file_id\"].nunique()}')\n",
    "print(f'Unique compounds: {met_raw[\"compound_name\"].nunique():,}')\n",
    "print(f'Intensity range:  [{met_raw[\"intensity\"].min():.2e}, {met_raw[\"intensity\"].max():.2e}]')\n",
    "print(met_raw.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map file_id → ionization mode / column type from met_file_name\n",
    "file_meta = overlap_inv[['met_file_id', 'met_file_name', 'sample_id']].rename(\n",
    "    columns={'met_file_id': 'file_id'}\n",
    ").drop_duplicates()\n",
    "file_meta['ionization'] = np.where(\n",
    "    file_meta['met_file_name'].str.contains('_POS_', na=False), 'POS',\n",
    "    np.where(file_meta['met_file_name'].str.contains('_NEG_', na=False), 'NEG', 'unknown')\n",
    ")\n",
    "file_meta['lc_column'] = np.where(\n",
    "    file_meta['met_file_name'].str.contains('HILICZ', na=False), 'HILICZ',\n",
    "    np.where(file_meta['met_file_name'].str.contains('C18', na=False), 'C18', 'unknown')\n",
    ")\n",
    "\n",
    "met_raw = met_raw.merge(file_meta[['file_id', 'ionization', 'lc_column']],\n",
    "                        on='file_id', how='left')\n",
    "print('Ionization mode breakdown:')\n",
    "print(met_raw['ionization'].value_counts().to_string())\n",
    "print('\\nLC column breakdown:')\n",
    "print(met_raw['lc_column'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Compound Annotation and Amino Acid Mapping\n",
    "\n",
    "Map detected compounds to GapMind amino acid pathways via case-insensitive\n",
    "substring matching on compound names.\n",
    "\n",
    "If `KEGG_COL` was found in Part 2, also attempt KEGG-based matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping: GapMind aa pathway → compound name fragments (case-insensitive substring match)\n",
    "# chorismate is the aromatic aa precursor; include shikimic acid as metabolomics proxy\n",
    "AA_PATHWAY_TO_PATTERNS = {\n",
    "    'arg':       ['arginine'],\n",
    "    'asn':       ['asparagine'],\n",
    "    'chorismate': ['chorismate', 'chorismic acid', 'shikimic acid', 'shikimate'],\n",
    "    'cys':       ['cysteine'],\n",
    "    'gln':       ['glutamine'],\n",
    "    'gly':       ['glycine'],\n",
    "    'his':       ['histidine'],\n",
    "    'ile':       ['isoleucine'],\n",
    "    'leu':       ['leucine'],\n",
    "    'lys':       ['lysine'],\n",
    "    'met':       ['methionine'],\n",
    "    'phe':       ['phenylalanine'],\n",
    "    'pro':       ['proline'],\n",
    "    'ser':       ['serine'],\n",
    "    'thr':       ['threonine'],\n",
    "    'trp':       ['tryptophan'],\n",
    "    'tyr':       ['tyrosine'],\n",
    "    'val':       ['valine'],\n",
    "}\n",
    "\n",
    "# Build a compound → pathway mapping by substring match\n",
    "all_compounds = met_raw['compound_name'].dropna().unique()\n",
    "compound_lower = pd.Series(all_compounds).str.lower()\n",
    "\n",
    "compound_pathway_map = {}  # compound_name → aa_pathway\n",
    "for pathway, patterns in AA_PATHWAY_TO_PATTERNS.items():\n",
    "    for compound in all_compounds:\n",
    "        cl = compound.lower()\n",
    "        if any(p in cl for p in patterns):\n",
    "            # Avoid mapping glutamine to glutamic acid and vice versa\n",
    "            if pathway == 'gln' and 'glutamic' in cl:\n",
    "                continue\n",
    "            compound_pathway_map[compound] = pathway\n",
    "\n",
    "print(f'Total unique compounds in data: {len(all_compounds):,}')\n",
    "print(f'Compounds mapped to aa pathways: {len(compound_pathway_map)}')\n",
    "print()\n",
    "# Show matches per pathway\n",
    "pathway_match_counts = pd.Series(compound_pathway_map).value_counts().sort_index()\n",
    "print('Compounds matched per aa pathway:')\n",
    "print(pathway_match_counts.to_string())\n",
    "\n",
    "# Pathways with no matches\n",
    "missing = [p for p in AA_PATHWAY_TO_PATTERNS if p not in pathway_match_counts.index]\n",
    "if missing:\n",
    "    print(f'\\naa pathways with NO compound match: {missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show matched compound names for verification\n",
    "matched_df = pd.DataFrame(\n",
    "    list(compound_pathway_map.items()), columns=['compound_name', 'aa_pathway']\n",
    ").sort_values('aa_pathway')\n",
    "\n",
    "print('Matched amino acid compounds:')\n",
    "print(matched_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Normalization and Per-Sample Aggregation\n",
    "\n",
    "Strategy:\n",
    "1. Log1p-transform intensity values (standard for LC-MS data; handles dynamic range)\n",
    "2. For each (sample, compound): take **max** across all met files\n",
    "   (same compound detected in HILICZ_POS, C18_POS, C18_NEG — take strongest signal)\n",
    "3. Pivot to sample × compound matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log1p transform\n",
    "met_raw['log_intensity'] = np.log1p(met_raw['intensity'])\n",
    "\n",
    "# Aggregate per (sample_id, compound_name): take max log_intensity across files\n",
    "met_agg = (\n",
    "    met_raw.groupby(['sample_id', 'compound_name'])['log_intensity']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'log_intensity': 'log_intensity_max'})\n",
    ")\n",
    "\n",
    "print(f'After aggregation (max per sample-compound): {len(met_agg):,} rows')\n",
    "print(f'Unique samples:   {met_agg[\"sample_id\"].nunique()}')\n",
    "print(f'Unique compounds: {met_agg[\"compound_name\"].nunique():,}')\n",
    "print(f'\\nlog_intensity distribution:')\n",
    "print(met_agg['log_intensity_max'].describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to compounds detected in at least 10% of samples (min prevalence filter)\n",
    "# This removes rare contaminants and reduces sparsity in the matrix\n",
    "MIN_PREVALENCE = 0.10\n",
    "n_samples_total = met_agg['sample_id'].nunique()\n",
    "compound_prevalence = (\n",
    "    met_agg.groupby('compound_name')['sample_id']\n",
    "    .nunique()\n",
    "    .rename('n_samples')\n",
    "    / n_samples_total\n",
    ")\n",
    "prevalent_compounds = compound_prevalence[compound_prevalence >= MIN_PREVALENCE].index\n",
    "\n",
    "# Always keep aa-mapped compounds regardless of prevalence\n",
    "aa_compounds = set(compound_pathway_map.keys())\n",
    "keep_compounds = set(prevalent_compounds) | aa_compounds\n",
    "\n",
    "met_filtered = met_agg[met_agg['compound_name'].isin(keep_compounds)].copy()\n",
    "\n",
    "print(f'Prevalent compounds (>={MIN_PREVALENCE:.0%} samples): {len(prevalent_compounds):,}')\n",
    "print(f'AA compounds always kept:                          {len(aa_compounds)}')\n",
    "print(f'Total compounds after filter:                      {len(keep_compounds):,}')\n",
    "print(f'Filtered rows:                                     {len(met_filtered):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to wide format: samples × compounds\n",
    "met_wide = met_filtered.pivot_table(\n",
    "    index='sample_id',\n",
    "    columns='compound_name',\n",
    "    values='log_intensity_max',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "compound_cols = [c for c in met_wide.columns if c != 'sample_id']\n",
    "print(f'Metabolomics matrix (wide): {met_wide.shape}')\n",
    "print(f'  Samples:   {len(met_wide)}')\n",
    "print(f'  Compounds: {len(compound_cols)}')\n",
    "print(f'\\nSparsity: {met_wide[compound_cols].isna().mean().mean():.1%} missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Amino Acid Metabolomics Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build amino acid metabolomics table: long format with pathway mapping\n",
    "aa_met = met_filtered[met_filtered['compound_name'].isin(aa_compounds)].copy()\n",
    "aa_met['aa_pathway'] = aa_met['compound_name'].map(compound_pathway_map)\n",
    "\n",
    "print(f'Amino acid metabolomics rows: {len(aa_met):,}')\n",
    "print(f'Samples with ≥1 AA compound: {aa_met[\"sample_id\"].nunique()}')\n",
    "print(f'AA pathways covered:         {aa_met[\"aa_pathway\"].nunique()} / 18')\n",
    "print()\n",
    "\n",
    "# Per-pathway: how many samples have a detection?\n",
    "aa_coverage = (\n",
    "    aa_met.groupby('aa_pathway')['sample_id']\n",
    "    .nunique()\n",
    "    .rename('n_samples_detected')\n",
    "    .reset_index()\n",
    "    .sort_values('n_samples_detected', ascending=False)\n",
    ")\n",
    "aa_coverage['pct'] = aa_coverage['n_samples_detected'] / n_samples_total\n",
    "print('AA pathway detection rates:')\n",
    "print(aa_coverage.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each aa_pathway × sample: aggregate across multiple compound matches\n",
    "# (e.g., 'L-Leucine' and 'leucine' both map to 'leu' — take max)\n",
    "aa_by_pathway = (\n",
    "    aa_met.groupby(['sample_id', 'aa_pathway'])['log_intensity_max']\n",
    "    .max()\n",
    "    .rename('log_intensity')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f'AA by pathway rows (sample × pathway): {len(aa_by_pathway):,}')\n",
    "print(aa_by_pathway.describe().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Abiotic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore abiotic_features schema first\n",
    "print('=== abiotic_features schema ===')\n",
    "spark.sql('DESCRIBE nmdc_arkin.abiotic_features').show(40, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample abiotic_features rows\n",
    "print('=== Sample abiotic_features rows ===')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nmdc_arkin.abiotic_features\n",
    "    LIMIT 3\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract abiotic features for overlap samples.\n",
    "# Note: all columns in abiotic_features are string-typed — CAST to DOUBLE before use.\n",
    "# Join via omics_files_table (sample_id key).\n",
    "# Use INTERSECT subquery to restrict to overlap samples.\n",
    "abiotic_spark = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        a.sample_id,\n",
    "        CAST(a.annotations_ph AS DOUBLE)                            AS ph,\n",
    "        CAST(a.annotations_temp_has_numeric_value AS DOUBLE)        AS temp_c,\n",
    "        CAST(a.annotations_depth_has_numeric_value AS DOUBLE)       AS depth_m,\n",
    "        CAST(a.annotations_tot_org_carb AS DOUBLE)                  AS tot_org_carb,\n",
    "        CAST(a.annotations_tot_nitro_content AS DOUBLE)             AS tot_nitro,\n",
    "        CAST(a.annotations_water_content AS DOUBLE)                 AS water_content\n",
    "    FROM nmdc_arkin.abiotic_features a\n",
    "    WHERE a.sample_id IN (\n",
    "        SELECT b2.sample_id FROM {BRIDGE_TBL} b2\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.centrifuge_gold) c2\n",
    "          ON b2.file_id = c2.file_id\n",
    "        INTERSECT\n",
    "        SELECT b3.sample_id FROM {BRIDGE_TBL} b3\n",
    "        JOIN (SELECT DISTINCT file_id FROM nmdc_arkin.metabolomics_gold) m3\n",
    "          ON b3.file_id = m3.file_id\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "abiotic = abiotic_spark.toPandas()\n",
    "# Defensive float cast (Spark CAST still returns Decimal in some versions)\n",
    "for col in ['ph', 'temp_c', 'depth_m', 'tot_org_carb', 'tot_nitro', 'water_content']:\n",
    "    if col in abiotic.columns:\n",
    "        abiotic[col] = pd.to_numeric(abiotic[col], errors='coerce')\n",
    "\n",
    "print(f'Abiotic features rows: {len(abiotic)}')\n",
    "print(f'Unique samples:        {abiotic[\"sample_id\"].nunique()}')\n",
    "print()\n",
    "print('Non-null rates per feature:')\n",
    "print(abiotic.notna().mean().to_string())\n",
    "print()\n",
    "print(abiotic.describe().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Merge Analysis-Ready Matrix\n",
    "\n",
    "Join: community pathway completeness (NB03) + metabolomics (wide) + abiotic features.\n",
    "Keep only samples present in both the pathway matrix and metabolomics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from community_matrix (220 samples × 86 cols)\n",
    "# Inner join with metabolomics wide matrix\n",
    "analysis_matrix = community_matrix.merge(met_wide, on='sample_id', how='inner')\n",
    "print(f'After joining pathway + metabolomics: {analysis_matrix.shape}')\n",
    "print(f'  Samples: {len(analysis_matrix)}')\n",
    "\n",
    "# Left join abiotic features\n",
    "if len(abiotic) > 0 and abiotic['sample_id'].nunique() > 0:\n",
    "    analysis_matrix = analysis_matrix.merge(\n",
    "        abiotic.drop_duplicates(subset='sample_id'),\n",
    "        on='sample_id', how='left'\n",
    "    )\n",
    "    print(f'After joining abiotic features: {analysis_matrix.shape}')\n",
    "    print(f'  Samples with abiotic data: '\n",
    "          f'{analysis_matrix[\"ph\"].notna().sum()} (pH), '\n",
    "          f'{analysis_matrix[\"temp_c\"].notna().sum()} (temp)')\n",
    "else:\n",
    "    print('No abiotic features found for overlap samples — skipping abiotic join')\n",
    "    for col in ['ph', 'temp_c', 'depth_m', 'tot_org_carb', 'tot_nitro', 'water_content']:\n",
    "        analysis_matrix[col] = np.nan\n",
    "\n",
    "print(f'\\nFinal analysis matrix shape: {analysis_matrix.shape}')\n",
    "print(f'Samples: {analysis_matrix[\"sample_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Metabolomics Distribution Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: log-intensity distributions for amino acid compounds, colored by ecosystem type\n",
    "# Merge ecosystem type into aa_by_pathway\n",
    "eco_map = community_matrix[['sample_id', 'ecosystem_type']].drop_duplicates()\n",
    "aa_plot = aa_by_pathway.merge(eco_map, on='sample_id', how='left')\n",
    "aa_plot['ecosystem_type'] = aa_plot['ecosystem_type'].fillna('Unknown')\n",
    "\n",
    "# Filter to aa_pathways with detections in at least 20 samples\n",
    "well_detected = aa_coverage[aa_coverage['n_samples_detected'] >= 20]['aa_pathway'].tolist()\n",
    "aa_plot_filtered = aa_plot[aa_plot['aa_pathway'].isin(well_detected)]\n",
    "\n",
    "n_pathways_plot = len(well_detected)\n",
    "if n_pathways_plot > 0:\n",
    "    fig, axes = plt.subplots(\n",
    "        n_pathways_plot, 1,\n",
    "        figsize=(8, max(6, n_pathways_plot * 1.5)),\n",
    "        sharex=False\n",
    "    )\n",
    "    if n_pathways_plot == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    palette = {'Soil': '#c8a96e', 'Freshwater': '#4e8fb5', 'Unknown': '#aaaaaa'}\n",
    "\n",
    "    for ax, pathway in zip(axes, sorted(well_detected)):\n",
    "        subset = aa_plot_filtered[aa_plot_filtered['aa_pathway'] == pathway]\n",
    "        for eco, grp in subset.groupby('ecosystem_type'):\n",
    "            color = palette.get(eco, '#888888')\n",
    "            ax.hist(grp['log_intensity'], bins=25, alpha=0.5,\n",
    "                    label=eco, color=color, density=True)\n",
    "        ax.set_title(f'aa pathway: {pathway}', fontsize=9)\n",
    "        ax.set_ylabel('Density', fontsize=8)\n",
    "        ax.tick_params(labelsize=7)\n",
    "        ax.legend(fontsize=7)\n",
    "\n",
    "    axes[-1].set_xlabel('log(intensity + 1)', fontsize=9)\n",
    "    plt.suptitle('Amino Acid Compound Intensities by Ecosystem Type',\n",
    "                 fontsize=11, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(FIGURES_DIR, 'metabolomics_distribution.png')\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Saved: figures/metabolomics_distribution.png')\n",
    "else:\n",
    "    print('No aa pathways with sufficient detections for plotting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 10: Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metabolomics matrix (wide: samples × compounds)\n",
    "met_path = os.path.join(DATA_DIR, 'metabolomics_matrix.csv')\n",
    "met_wide.to_csv(met_path, index=False)\n",
    "print(f'Saved: data/metabolomics_matrix.csv  ({met_wide.shape})')\n",
    "\n",
    "# Save amino acid metabolites (long: sample × pathway)\n",
    "aa_path = os.path.join(DATA_DIR, 'amino_acid_metabolites.csv')\n",
    "aa_by_pathway.to_csv(aa_path, index=False)\n",
    "print(f'Saved: data/amino_acid_metabolites.csv  ({aa_by_pathway.shape})')\n",
    "\n",
    "# Save analysis-ready matrix\n",
    "ar_path = os.path.join(DATA_DIR, 'analysis_ready_matrix.csv')\n",
    "analysis_matrix.to_csv(ar_path, index=False)\n",
    "print(f'Saved: data/analysis_ready_matrix.csv  ({analysis_matrix.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB04 Summary\n",
    "pathway_cols_cm  = [c for c in community_matrix.columns\n",
    "                    if c not in ['sample_id','study_id','ecosystem_category',\n",
    "                                 'ecosystem_type','ecosystem_subtype','specific_ecosystem']]\n",
    "compound_cols_ar = [c for c in analysis_matrix.columns\n",
    "                    if c not in ['sample_id','study_id','ecosystem_category',\n",
    "                                 'ecosystem_type','ecosystem_subtype','specific_ecosystem',\n",
    "                                 'ph','temp_c','depth_m','tot_org_carb','tot_nitro','water_content']\n",
    "                    and c not in pathway_cols_cm]\n",
    "\n",
    "print('=== NB04 Summary ===')\n",
    "print(f'Samples in analysis_ready_matrix: {analysis_matrix[\"sample_id\"].nunique()}')\n",
    "print(f'Pathway columns (from NB03):       {len(pathway_cols_cm)}')\n",
    "print(f'Compound columns (metabolomics):   {len(compound_cols_ar)}')\n",
    "print(f'Abiotic feature columns:           '\n",
    "      f'{analysis_matrix[[\"ph\",\"temp_c\",\"depth_m\"]].notna().sum().to_dict()}')\n",
    "print()\n",
    "print(f'AA pathways with metabolomics coverage:')\n",
    "print(aa_coverage.to_string(index=False))\n",
    "print()\n",
    "print('Ecosystem breakdown in analysis_ready_matrix:')\n",
    "print(analysis_matrix['ecosystem_type'].value_counts(dropna=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Decisions for NB05\n",
    "\n",
    "| Question | Finding |\n",
    "|---|---|\n",
    "| Samples in analysis_ready_matrix | ??? |\n",
    "| Metabolomics compounds (prevalent) | ??? |\n",
    "| AA pathways with metabolomics detections | ??? / 18 |\n",
    "| Samples with AA metabolomics coverage | ??? |\n",
    "| Abiotic features available | pH: ???, temp: ??? |\n",
    "| Ecosystem split | Soil: ???, Freshwater: ???, Unknown: ??? |\n",
    "\n",
    "**Decision for NB05**:  \n",
    "Proceed to statistical analysis using `data/analysis_ready_matrix.csv` +\n",
    "`data/amino_acid_metabolites.csv`.  \n",
    "For H1 (Black Queen): correlate per-sample mean AA pathway completeness  \n",
    "vs per-sample mean AA metabolite intensity.  \n",
    "For H2: UMAP/PCA of community pathway profiles, colored by ecosystem type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
