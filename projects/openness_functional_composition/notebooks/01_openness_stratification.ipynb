{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Openness Stratification\n",
    "\n",
    "**Project**: Openness vs Functional Composition\n",
    "\n",
    "**Goal**: Extract pangenome statistics, compute openness metrics, stratify species into quartiles, and select ~10 species per quartile balanced by phylum.\n",
    "\n",
    "**Data Sources**:\n",
    "- `kbase_ke_pangenome.pangenome` — Per-species pangenome stats (27K rows)\n",
    "- `kbase_ke_pangenome.gtdb_species_clade` — Taxonomy (27K rows)\n",
    "\n",
    "**Output**: `../data/species_openness_quartiles.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Pangenome Stats\n",
    "\n",
    "Get all species with >= 50 genomes (robust pangenome estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pangenome_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.gtdb_species_clade_id,\n",
    "        CAST(p.no_genomes AS INT) as no_genomes,\n",
    "        CAST(p.no_gene_clusters AS INT) as no_gene_clusters,\n",
    "        CAST(p.no_core AS INT) as no_core,\n",
    "        CAST(p.no_aux_genome AS INT) as no_aux_genome,\n",
    "        CAST(p.no_singleton_gene_clusters AS INT) as no_singleton,\n",
    "        sc.GTDB_taxonomy,\n",
    "        sc.GTDB_species\n",
    "    FROM kbase_ke_pangenome.pangenome p\n",
    "    JOIN kbase_ke_pangenome.gtdb_species_clade sc\n",
    "        ON p.gtdb_species_clade_id = sc.gtdb_species_clade_id\n",
    "    WHERE CAST(p.no_genomes AS INT) >= 50\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Species with >= 50 genomes: {pangenome_df.count():,}\")\n",
    "pangenome_df.show(5, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Openness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Compute openness metrics\n",
    "openness_df = pangenome_df.withColumn(\n",
    "    'core_fraction', F.col('no_core') / F.col('no_gene_clusters')\n",
    ").withColumn(\n",
    "    'singleton_fraction', F.col('no_singleton') / F.col('no_gene_clusters')\n",
    ").withColumn(\n",
    "    'accessory_fraction', F.col('no_aux_genome') / F.col('no_gene_clusters')\n",
    ").withColumn(\n",
    "    'openness', 1 - (F.col('no_core') / F.col('no_gene_clusters'))\n",
    ").withColumn(\n",
    "    'phylum', F.split(F.col('GTDB_taxonomy'), ';').getItem(1)\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "openness_pdf = openness_df.toPandas()\n",
    "print(f\"Species count: {len(openness_pdf)}\")\n",
    "print(f\"\\nOpenness distribution:\")\n",
    "print(openness_pdf['openness'].describe())\n",
    "print(f\"\\nPhylum distribution:\")\n",
    "print(openness_pdf['phylum'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stratify into Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assign quartiles by openness\n",
    "openness_pdf['openness_quartile'] = pd.qcut(\n",
    "    openness_pdf['openness'], q=4, labels=['Q1_closed', 'Q2', 'Q3', 'Q4_open']\n",
    ")\n",
    "\n",
    "print(\"Species per quartile:\")\n",
    "print(openness_pdf['openness_quartile'].value_counts().sort_index())\n",
    "print(\"\\nOpenness range per quartile:\")\n",
    "print(openness_pdf.groupby('openness_quartile')['openness'].agg(['min', 'max', 'median']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phylum distribution per quartile\n",
    "print(\"Phylum distribution by quartile:\")\n",
    "print(pd.crosstab(openness_pdf['openness_quartile'], openness_pdf['phylum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Target Species\n",
    "\n",
    "Select ~10 species per quartile, balanced by phylum where possible.\n",
    "Prefer species with more genomes (better pangenome estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top species per quartile, balancing phylum representation\n",
    "target_species = []\n",
    "\n",
    "for q in ['Q1_closed', 'Q2', 'Q3', 'Q4_open']:\n",
    "    q_df = openness_pdf[openness_pdf['openness_quartile'] == q].copy()\n",
    "    \n",
    "    # Get top phyla in this quartile\n",
    "    top_phyla = q_df['phylum'].value_counts().head(5).index.tolist()\n",
    "    \n",
    "    selected = []\n",
    "    # Take 2 species per top phylum (up to 10 total)\n",
    "    for phylum in top_phyla:\n",
    "        phylum_species = q_df[q_df['phylum'] == phylum].nlargest(2, 'no_genomes')\n",
    "        selected.append(phylum_species)\n",
    "        if sum(len(s) for s in selected) >= 10:\n",
    "            break\n",
    "    \n",
    "    q_selected = pd.concat(selected).head(10)\n",
    "    target_species.append(q_selected)\n",
    "    print(f\"\\n{q}: {len(q_selected)} species\")\n",
    "    print(q_selected[['GTDB_species', 'phylum', 'no_genomes', 'openness']].to_string(index=False))\n",
    "\n",
    "target_df = pd.concat(target_species)\n",
    "print(f\"\\nTotal target species: {len(target_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all species with openness metrics\n",
    "openness_pdf.to_csv('../data/all_species_openness.csv', index=False)\n",
    "print(f\"Saved {len(openness_pdf)} species to ../data/all_species_openness.csv\")\n",
    "\n",
    "# Save target species for notebook 02\n",
    "target_df.to_csv('../data/species_openness_quartiles.csv', index=False)\n",
    "print(f\"Saved {len(target_df)} target species to ../data/species_openness_quartiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "Record after running:\n",
    "- How many species have >= 50 genomes? ___\n",
    "- What is the openness range? ___\n",
    "- Are quartiles phylogenetically balanced? ___\n",
    "- Any concerns about species selection? ___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
