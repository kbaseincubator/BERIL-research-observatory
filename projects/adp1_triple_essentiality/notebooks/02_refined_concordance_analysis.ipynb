{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refined Concordance Analysis\n",
    "\n",
    "Comparing essentiality predictions from FBA, RB-TnSeq, and proteomics against KO experimental truth.\n",
    "\n",
    "This notebook:\n",
    "1. Loads essentiality vectors from notebook 01\n",
    "2. Computes concordance metrics (confusion matrices, Cohen's kappa, F1 scores)\n",
    "3. Performs ROC curve analysis for continuous predictors\n",
    "4. Characterizes discordant genes\n",
    "5. Generates comprehensive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, cohen_kappa_score, roc_curve, auc\n",
    ")\n",
    "from scipy.stats import pearsonr, spearmanr, mannwhitneyu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "ev = pd.read_csv('../data/essentiality_vectors.csv')\n",
    "print(f'Loaded {len(ev):,} genes')\n",
    "ev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FBA Concordance Analysis\n",
    "\n",
    "### Set 1: Rich Media (FBA vs KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for genes with both FBA and KO data (rich media)\n",
    "fba_ko_rich = ev[ev['fba_rich_essential'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "\n",
    "y_true = fba_ko_rich['ko_rich_essential'].astype(int)\n",
    "y_pred = fba_ko_rich['fba_rich_essential'].astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "print(f\"FBA Rich Media vs KO (n={len(fba_ko_rich):,} genes)\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"\\nRecall (Sensitivity): {recall:.3f}\")\n",
    "print(f\"Precision (PPV): {precision:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set 2: Minimal Media (FBA vs KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for genes with both FBA and KO data (minimal media)\n",
    "fba_ko_min = ev[ev['fba_min_essential'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "\n",
    "y_true = fba_ko_min['ko_min_essential'].astype(int)\n",
    "y_pred = fba_ko_min['fba_min_essential'].astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "print(f\"FBA Minimal Media vs KO (n={len(fba_ko_min):,} genes)\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"\\nRecall (Sensitivity): {recall:.3f}\")\n",
    "print(f\"Precision (PPV): {precision:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TnSeq Concordance Analysis (Multiple Thresholds)\n",
    "\n",
    "Test 5 thresholds for essentiality_fraction and compute concordance with KO rich media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for genes with both TnSeq and KO data (rich media)\n",
    "tnseq_ko_rich = ev[ev['essentiality_fraction'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "\n",
    "thresholds = [0.01, 0.025, 0.05, 0.10, 0.20]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    tnseq_ko_rich['tnseq_binary'] = (tnseq_ko_rich['essentiality_fraction'] >= threshold).astype(int)\n",
    "    \n",
    "    y_true = tnseq_ko_rich['ko_rich_essential'].astype(int)\n",
    "    y_pred = tnseq_ko_rich['tnseq_binary']\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'n': len(tnseq_ko_rich),\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'kappa': kappa,\n",
    "        'cm': cm\n",
    "    })\n",
    "\n",
    "# Create summary dataframe\n",
    "tnseq_summary = pd.DataFrame(results)\n",
    "print(\"\\nTnSeq Threshold Analysis (Rich Media vs KO)\")\n",
    "print(tnseq_summary[['threshold', 'n', 'recall', 'precision', 'f1', 'kappa']].to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "tnseq_summary[['threshold', 'n', 'recall', 'precision', 'f1', 'kappa']].to_csv(\n",
    "    '../data/tnseq_threshold_comparison.csv', index=False\n",
    ")\n",
    "print(\"\\nSaved to: ../data/tnseq_threshold_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Proteomics Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for genes with both proteomics and KO data (minimal media)\n",
    "prot_ko = ev[ev['proteomics_avg_log2'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "\n",
    "# Separate essential and dispensable\n",
    "essential = prot_ko[prot_ko['ko_min_essential'] == 1]['proteomics_avg_log2']\n",
    "dispensable = prot_ko[prot_ko['ko_min_essential'] == 0]['proteomics_avg_log2']\n",
    "\n",
    "# Compute statistics\n",
    "pearson_r, pearson_p = pearsonr(prot_ko['ko_min_essential'], prot_ko['proteomics_avg_log2'])\n",
    "spearman_r, spearman_p = spearmanr(prot_ko['ko_min_essential'], prot_ko['proteomics_avg_log2'])\n",
    "mw_stat, mw_p = mannwhitneyu(essential, dispensable, alternative='greater')\n",
    "\n",
    "print(f\"Proteomics vs Essentiality (Minimal Media, n={len(prot_ko):,} genes)\")\n",
    "print(f\"\\nEssential genes (n={len(essential):,}):\")\n",
    "print(f\"  Mean log2: {essential.mean():.2f} ± {essential.std():.2f}\")\n",
    "print(f\"\\nDispensable genes (n={len(dispensable):,}):\")\n",
    "print(f\"  Mean log2: {dispensable.mean():.2f} ± {dispensable.std():.2f}\")\n",
    "print(f\"\\nDifference: {essential.mean() - dispensable.mean():.2f} log2 units\")\n",
    "print(f\"Fold change: {2**(essential.mean() - dispensable.mean()):.1f}x\")\n",
    "print(f\"\\nPearson r: {pearson_r:.3f} (p={pearson_p:.2e})\")\n",
    "print(f\"Spearman ρ: {spearman_r:.3f} (p={spearman_p:.2e})\")\n",
    "print(f\"Mann-Whitney U: p={mw_p:.2e}\")\n",
    "\n",
    "# Save results\n",
    "prot_results = pd.DataFrame([{\n",
    "    'n_total': len(prot_ko),\n",
    "    'n_essential': len(essential),\n",
    "    'n_dispensable': len(dispensable),\n",
    "    'essential_mean': essential.mean(),\n",
    "    'essential_std': essential.std(),\n",
    "    'dispensable_mean': dispensable.mean(),\n",
    "    'dispensable_std': dispensable.std(),\n",
    "    'log2_diff': essential.mean() - dispensable.mean(),\n",
    "    'fold_change': 2**(essential.mean() - dispensable.mean()),\n",
    "    'pearson_r': pearson_r,\n",
    "    'pearson_p': pearson_p,\n",
    "    'spearman_r': spearman_r,\n",
    "    'spearman_p': spearman_p,\n",
    "    'mannwhitney_p': mw_p\n",
    "}])\n",
    "prot_results.to_csv('../data/proteomics_correlation.csv', index=False)\n",
    "print(\"\\nSaved to: ../data/proteomics_correlation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ROC Curve Analysis\n",
    "\n",
    "Evaluate continuous predictors: fitness, essentiality_fraction, proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ROC analysis\n",
    "roc_results = []\n",
    "\n",
    "# Rich media: Fitness vs KO\n",
    "fitness_rich = ev[ev['fitness_mean'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "if len(fitness_rich) > 0:\n",
    "    y_true = fitness_rich['ko_rich_essential'].astype(int)\n",
    "    # Invert fitness: lower fitness = more essential\n",
    "    y_score = -fitness_rich['fitness_mean']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    roc_results.append({\n",
    "        'set': 'Rich Media',\n",
    "        'predictor': 'Fitness (inverted)',\n",
    "        'n': len(fitness_rich),\n",
    "        'auc': auc_score\n",
    "    })\n",
    "    print(f\"Fitness (inverted) vs KO Rich: AUC = {auc_score:.3f} (n={len(fitness_rich):,})\")\n",
    "\n",
    "# Rich media: Essentiality fraction vs KO\n",
    "ef_rich = ev[ev['essentiality_fraction'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "if len(ef_rich) > 0:\n",
    "    y_true = ef_rich['ko_rich_essential'].astype(int)\n",
    "    y_score = ef_rich['essentiality_fraction']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    roc_results.append({\n",
    "        'set': 'Rich Media',\n",
    "        'predictor': 'Essentiality Fraction',\n",
    "        'n': len(ef_rich),\n",
    "        'auc': auc_score\n",
    "    })\n",
    "    print(f\"Essentiality Fraction vs KO Rich: AUC = {auc_score:.3f} (n={len(ef_rich):,})\")\n",
    "\n",
    "# Minimal media: Fitness vs KO\n",
    "fitness_min = ev[ev['fitness_mean'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "if len(fitness_min) > 0:\n",
    "    y_true = fitness_min['ko_min_essential'].astype(int)\n",
    "    y_score = -fitness_min['fitness_mean']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    roc_results.append({\n",
    "        'set': 'Minimal Media',\n",
    "        'predictor': 'Fitness (inverted)',\n",
    "        'n': len(fitness_min),\n",
    "        'auc': auc_score\n",
    "    })\n",
    "    print(f\"Fitness (inverted) vs KO Min: AUC = {auc_score:.3f} (n={len(fitness_min):,})\")\n",
    "\n",
    "# Minimal media: Essentiality fraction vs KO\n",
    "ef_min = ev[ev['essentiality_fraction'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "if len(ef_min) > 0:\n",
    "    y_true = ef_min['ko_min_essential'].astype(int)\n",
    "    y_score = ef_min['essentiality_fraction']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    roc_results.append({\n",
    "        'set': 'Minimal Media',\n",
    "        'predictor': 'Essentiality Fraction',\n",
    "        'n': len(ef_min),\n",
    "        'auc': auc_score\n",
    "    })\n",
    "    print(f\"Essentiality Fraction vs KO Min: AUC = {auc_score:.3f} (n={len(ef_min):,})\")\n",
    "\n",
    "# Minimal media: Proteomics vs KO\n",
    "prot_min = ev[ev['proteomics_avg_log2'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "if len(prot_min) > 0:\n",
    "    y_true = prot_min['ko_min_essential'].astype(int)\n",
    "    y_score = prot_min['proteomics_avg_log2']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    roc_results.append({\n",
    "        'set': 'Minimal Media',\n",
    "        'predictor': 'Proteomics (log2)',\n",
    "        'n': len(prot_min),\n",
    "        'auc': auc_score\n",
    "    })\n",
    "    print(f\"Proteomics vs KO Min: AUC = {auc_score:.3f} (n={len(prot_min):,})\")\n",
    "\n",
    "# Save ROC results\n",
    "roc_df = pd.DataFrame(roc_results)\n",
    "roc_df.to_csv('../data/roc_summary.csv', index=False)\n",
    "print(\"\\nSaved to: ../data/roc_summary.csv\")\n",
    "print(\"\\nROC Summary:\")\n",
    "print(roc_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Concordance Summary\n",
    "\n",
    "Combine FBA and TnSeq concordance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive concordance summary\n",
    "concordance_data = []\n",
    "\n",
    "# FBA Rich\n",
    "fba_ko_rich = ev[ev['fba_rich_essential'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "y_true = fba_ko_rich['ko_rich_essential'].astype(int)\n",
    "y_pred = fba_ko_rich['fba_rich_essential'].astype(int)\n",
    "concordance_data.append({\n",
    "    'Set': 'Rich Media',\n",
    "    'Source': 'FBA',\n",
    "    'N': len(fba_ko_rich),\n",
    "    'Recall': recall_score(y_true, y_pred),\n",
    "    'Precision': precision_score(y_true, y_pred),\n",
    "    'F1': f1_score(y_true, y_pred),\n",
    "    'Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "})\n",
    "\n",
    "# TnSeq Rich (all thresholds)\n",
    "for threshold in thresholds:\n",
    "    tnseq_ko_rich = ev[ev['essentiality_fraction'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "    tnseq_ko_rich['tnseq_binary'] = (tnseq_ko_rich['essentiality_fraction'] >= threshold).astype(int)\n",
    "    y_true = tnseq_ko_rich['ko_rich_essential'].astype(int)\n",
    "    y_pred = tnseq_ko_rich['tnseq_binary']\n",
    "    concordance_data.append({\n",
    "        'Set': 'Rich Media',\n",
    "        'Source': f'TnSeq ({threshold})',\n",
    "        'N': len(tnseq_ko_rich),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'F1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "    })\n",
    "\n",
    "# FBA Minimal\n",
    "fba_ko_min = ev[ev['fba_min_essential'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "y_true = fba_ko_min['ko_min_essential'].astype(int)\n",
    "y_pred = fba_ko_min['fba_min_essential'].astype(int)\n",
    "concordance_data.append({\n",
    "    'Set': 'Minimal Media',\n",
    "    'Source': 'FBA',\n",
    "    'N': len(fba_ko_min),\n",
    "    'Recall': recall_score(y_true, y_pred),\n",
    "    'Precision': precision_score(y_true, y_pred),\n",
    "    'F1': f1_score(y_true, y_pred),\n",
    "    'Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "})\n",
    "\n",
    "concordance_df = pd.DataFrame(concordance_data)\n",
    "concordance_df.to_csv('../data/concordance_summary.csv', index=False)\n",
    "print(\"Comprehensive Concordance Summary:\")\n",
    "print(concordance_df.to_string(index=False))\n",
    "print(\"\\nSaved to: ../data/concordance_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discordant Gene Characterization\n",
    "\n",
    "Analyze genes where TnSeq and KO disagree (using optimal threshold 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use threshold 0.05 for detailed discordance analysis\n",
    "threshold = 0.05\n",
    "tnseq_ko = ev[ev['essentiality_fraction'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "tnseq_ko['tnseq_essential'] = (tnseq_ko['essentiality_fraction'] >= threshold).astype(int)\n",
    "tnseq_ko['ko_essential'] = tnseq_ko['ko_rich_essential'].astype(int)\n",
    "\n",
    "# Classify concordance\n",
    "def classify_concordance(row):\n",
    "    if row['ko_essential'] == 1 and row['tnseq_essential'] == 1:\n",
    "        return 'Both Essential'\n",
    "    elif row['ko_essential'] == 0 and row['tnseq_essential'] == 0:\n",
    "        return 'Both Dispensable'\n",
    "    elif row['ko_essential'] == 1 and row['tnseq_essential'] == 0:\n",
    "        return 'KO Essential, TnSeq Dispensable'\n",
    "    else:\n",
    "        return 'KO Dispensable, TnSeq Essential'\n",
    "\n",
    "tnseq_ko['concordance_class'] = tnseq_ko.apply(classify_concordance, axis=1)\n",
    "\n",
    "# Summary by class\n",
    "discord_summary = tnseq_ko.groupby('concordance_class').agg({\n",
    "    'feature_id': 'count',\n",
    "    'essentiality_fraction': 'mean',\n",
    "    'fitness_mean': 'mean'\n",
    "}).rename(columns={'feature_id': 'count'})\n",
    "\n",
    "print(\"Discordance Summary (threshold=0.05):\")\n",
    "print(discord_summary)\n",
    "print(f\"\\nTotal genes: {len(tnseq_ko):,}\")\n",
    "\n",
    "# Save discordance summary\n",
    "discord_summary.to_csv('../data/discordance_summary.csv')\n",
    "print(\"\\nSaved to: ../data/discordance_summary.csv\")\n",
    "\n",
    "# Save discordant gene lists\n",
    "ko_ess_tn_disp = tnseq_ko[tnseq_ko['concordance_class'] == 'KO Essential, TnSeq Dispensable']\n",
    "ko_disp_tn_ess = tnseq_ko[tnseq_ko['concordance_class'] == 'KO Dispensable, TnSeq Essential']\n",
    "\n",
    "ko_ess_tn_disp[['feature_id', 'gene_names', 'rast_function', 'essentiality_fraction', 'fitness_mean']].to_csv(\n",
    "    '../data/discordant_ko_essential_tnseq_dispensable.csv', index=False\n",
    ")\n",
    "ko_disp_tn_ess[['feature_id', 'gene_names', 'rast_function', 'essentiality_fraction', 'fitness_mean']].to_csv(\n",
    "    '../data/discordant_ko_dispensable_tnseq_essential.csv', index=False\n",
    ")\n",
    "print(f\"Saved {len(ko_ess_tn_disp):,} KO essential/TnSeq dispensable genes\")\n",
    "print(f\"Saved {len(ko_disp_tn_ess):,} KO dispensable/TnSeq essential genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations\n",
    "\n",
    "Generate comprehensive figures for the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: FBA Comparison (Rich vs Minimal)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Rich media\n",
    "fba_ko_rich = ev[ev['fba_rich_essential'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "cm_rich = confusion_matrix(fba_ko_rich['ko_rich_essential'], fba_ko_rich['fba_rich_essential'])\n",
    "sns.heatmap(cm_rich, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Disp', 'Ess'], yticklabels=['Disp', 'Ess'])\n",
    "axes[0].set_title(f'FBA Rich Media (n={len(fba_ko_rich):,})\\nκ={cohen_kappa_score(fba_ko_rich[\"ko_rich_essential\"], fba_ko_rich[\"fba_rich_essential\"]):.3f}')\n",
    "axes[0].set_xlabel('FBA Prediction')\n",
    "axes[0].set_ylabel('KO Truth')\n",
    "\n",
    "# Minimal media\n",
    "fba_ko_min = ev[ev['fba_min_essential'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "cm_min = confusion_matrix(fba_ko_min['ko_min_essential'], fba_ko_min['fba_min_essential'])\n",
    "sns.heatmap(cm_min, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Disp', 'Ess'], yticklabels=['Disp', 'Ess'])\n",
    "axes[1].set_title(f'FBA Minimal Media (n={len(fba_ko_min):,})\\nκ={cohen_kappa_score(fba_ko_min[\"ko_min_essential\"], fba_ko_min[\"fba_min_essential\"]):.3f}')\n",
    "axes[1].set_xlabel('FBA Prediction')\n",
    "axes[1].set_ylabel('KO Truth')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/fba_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: ../figures/fba_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: ROC Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Rich media\n",
    "ax = axes[0]\n",
    "# Fitness\n",
    "fitness_rich = ev[ev['fitness_mean'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "y_true = fitness_rich['ko_rich_essential'].astype(int)\n",
    "y_score = -fitness_rich['fitness_mean']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'Fitness (AUC={auc_score:.3f})', linewidth=2)\n",
    "\n",
    "# Essentiality fraction\n",
    "ef_rich = ev[ev['essentiality_fraction'].notna() & ev['ko_rich_essential'].notna()].copy()\n",
    "y_true = ef_rich['ko_rich_essential'].astype(int)\n",
    "y_score = ef_rich['essentiality_fraction']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'Essentiality Fraction (AUC={auc_score:.3f})', linewidth=2)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves: Rich Media')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Minimal media\n",
    "ax = axes[1]\n",
    "# Fitness\n",
    "fitness_min = ev[ev['fitness_mean'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "y_true = fitness_min['ko_min_essential'].astype(int)\n",
    "y_score = -fitness_min['fitness_mean']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'Fitness (AUC={auc_score:.3f})', linewidth=2)\n",
    "\n",
    "# Essentiality fraction\n",
    "ef_min = ev[ev['essentiality_fraction'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "y_true = ef_min['ko_min_essential'].astype(int)\n",
    "y_score = ef_min['essentiality_fraction']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'Essentiality Fraction (AUC={auc_score:.3f})', linewidth=2)\n",
    "\n",
    "# Proteomics\n",
    "prot_min = ev[ev['proteomics_avg_log2'].notna() & ev['ko_min_essential'].notna()].copy()\n",
    "y_true = prot_min['ko_min_essential'].astype(int)\n",
    "y_score = prot_min['proteomics_avg_log2']\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'Proteomics (AUC={auc_score:.3f})', linewidth=2)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves: Minimal Media')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/roc_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: ../figures/roc_comprehensive.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Concordance Heatmap\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Prepare concordance matrix\n",
    "conc_pivot = concordance_df.pivot_table(\n",
    "    index='Source',\n",
    "    columns='Set',\n",
    "    values='Kappa'\n",
    ")\n",
    "\n",
    "sns.heatmap(conc_pivot, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            vmin=-0.2, vmax=0.6, ax=ax, cbar_kws={'label': \"Cohen's Kappa\"})\n",
    "ax.set_title(\"Concordance with KO Experiments (Cohen's Kappa)\\nκ>0.4=Moderate, κ<0=Systematic Disagreement\")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/concordance_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: ../figures/concordance_comprehensive.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Discordance Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Concordance class counts\n",
    "ax = axes[0, 0]\n",
    "counts = tnseq_ko['concordance_class'].value_counts()\n",
    "counts.plot(kind='barh', ax=ax, color=['green', 'lightgreen', 'orange', 'red'])\n",
    "ax.set_xlabel('Number of Genes')\n",
    "ax.set_title(f'Concordance Classification (n={len(tnseq_ko):,}, threshold=0.05)')\n",
    "\n",
    "# Essentiality fraction by class\n",
    "ax = axes[0, 1]\n",
    "tnseq_ko.boxplot(column='essentiality_fraction', by='concordance_class', ax=ax)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Essentiality Fraction')\n",
    "ax.set_title('Essentiality Fraction by Concordance Class')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Fitness by class\n",
    "ax = axes[1, 0]\n",
    "fitness_data = tnseq_ko[tnseq_ko['fitness_mean'].notna()]\n",
    "fitness_data.boxplot(column='fitness_mean', by='concordance_class', ax=ax)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('Fitness by Concordance Class')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Scatter: Essentiality fraction vs Fitness\n",
    "ax = axes[1, 1]\n",
    "for cls, color in zip(['Both Essential', 'Both Dispensable', 'KO Essential, TnSeq Dispensable', 'KO Dispensable, TnSeq Essential'],\n",
    "                      ['green', 'lightgreen', 'orange', 'red']):\n",
    "    subset = tnseq_ko[tnseq_ko['concordance_class'] == cls]\n",
    "    subset = subset[subset['fitness_mean'].notna()]\n",
    "    ax.scatter(subset['essentiality_fraction'], subset['fitness_mean'],\n",
    "              label=cls, alpha=0.6, s=20, color=color)\n",
    "ax.set_xlabel('Essentiality Fraction')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('Essentiality Fraction vs Fitness')\n",
    "ax.legend(fontsize=8, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/discordance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: ../figures/discordance_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook performed comprehensive concordance analysis:\n",
    "\n",
    "**Key Findings:**\n",
    "1. **FBA**: Moderate concordance (κ≈0.49, F1≈0.62-0.67), better in minimal media\n",
    "2. **TnSeq**: Systematic discordance (κ<0 across all thresholds)\n",
    "3. **Fitness**: Best continuous predictor (AUC=0.70-0.73)\n",
    "4. **Proteomics**: Strong correlation with essentiality (AUC=0.74, 6.5-fold expression difference)\n",
    "5. **Essentiality fraction**: Performs worse than random (AUC<0.5)\n",
    "\n",
    "**Actionable Recommendations:**\n",
    "- Use continuous fitness scores, not binary essentiality_fraction\n",
    "- FBA is useful for first-pass screening but requires experimental validation\n",
    "- TnSeq and KO measure different biology (fitness vs lethality)\n",
    "\n",
    "All results saved to:\n",
    "- `../data/concordance_summary.csv`\n",
    "- `../data/tnseq_threshold_comparison.csv`\n",
    "- `../data/roc_summary.csv`\n",
    "- `../data/proteomics_correlation.csv`\n",
    "- `../data/discordance_summary.csv`\n",
    "- `../data/discordant_*.csv`\n",
    "\n",
    "Figures saved to:\n",
    "- `../figures/fba_comparison.png`\n",
    "- `../figures/roc_comprehensive.png`\n",
    "- `../figures/concordance_comprehensive.png`\n",
    "- `../figures/discordance_analysis.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
