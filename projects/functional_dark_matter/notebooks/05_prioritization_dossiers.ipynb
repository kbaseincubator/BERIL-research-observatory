{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB05: Prioritization & Candidate Dossiers\n",
    "\n",
    "**No Spark required** — this notebook uses only local pandas on outputs from NB01–NB04.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Score, rank, and produce experimental prioritization for functional dark matter genes.\n",
    "Multi-dimensional scoring across 6 evidence axes:\n",
    "\n",
    "1. **Fitness importance** (0.25): max |fitness|, # specific phenotypes, essentiality\n",
    "2. **Cross-organism conservation** (0.20): # FB organisms with ortholog, concordance score\n",
    "3. **Functional inference quality** (0.20): module membership, co-fitness, domains, GapMind\n",
    "4. **Pangenome distribution** (0.15): phylogenetic breadth, core/accessory\n",
    "5. **Biogeographic signal** (0.10): environmental pattern, lab-field concordance\n",
    "6. **Experimental tractability** (0.10): tractable organism, not essential, has partners\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- `data/dark_genes_integrated.tsv` (NB01) — unified dark gene table\n",
    "- `data/dark_genes_only.tsv` (NB01) — dark genes subset\n",
    "- `data/gapmind_gap_candidates.tsv` (NB02) — GapMind pathway gaps\n",
    "- `data/concordance_scores.tsv` (NB02) — cross-organism concordance\n",
    "- `data/phylogenetic_breadth.tsv` (NB02) — pangenome distribution\n",
    "- `data/carrier_noncarrier_tests.tsv` (NB03) — biogeographic tests\n",
    "- `data/lab_field_concordance.tsv` (NB04) — lab-field concordance\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `data/prioritized_candidates.tsv` — top 100 ranked candidates\n",
    "- `data/scoring_all_dark.tsv` — scores for all scored dark genes\n",
    "- `figures/fig13_score_components.png`\n",
    "- `figures/fig14_top20_dossiers.png`\n",
    "- `figures/fig15_organism_distribution.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:23.029373Z",
     "iopub.status.busy": "2026-02-25T21:04:23.029136Z",
     "iopub.status.idle": "2026-02-25T21:04:24.889445Z",
     "shell.execute_reply": "2026-02-25T21:04:24.888590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project dir: /home/aparkin/BERIL-research-observatory/projects/functional_dark_matter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Path setup\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "else:\n",
    "    PROJECT_DIR = os.getcwd()\n",
    "    _d = PROJECT_DIR\n",
    "    while _d != '/':\n",
    "        if os.path.exists(os.path.join(_d, 'PROJECT.md')):\n",
    "            break\n",
    "        _d = os.path.dirname(_d)\n",
    "\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "FIG_DIR = os.path.join(PROJECT_DIR, 'figures')\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "print(f'Project dir: {PROJECT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load All Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:24.939626Z",
     "iopub.status.busy": "2026-02-25T21:04:24.939318Z",
     "iopub.status.idle": "2026-02-25T21:04:25.253456Z",
     "shell.execute_reply": "2026-02-25T21:04:25.252674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark genes: 57,011\n",
      "GapMind gap candidates: 1,256 (organism-pathway pairs with dark genes near gaps)\n",
      "Concordance scores: 65 ortholog groups\n",
      "Phylogenetic breadth: 30,756 gene clusters\n",
      "Carrier tests: 151 clusters\n",
      "Lab-field concordance: 47 clusters\n"
     ]
    }
   ],
   "source": [
    "# Load all data from NB01-NB04\n",
    "dark = pd.read_csv(os.path.join(DATA_DIR, 'dark_genes_only.tsv'), sep='\\t', low_memory=False)\n",
    "print(f'Dark genes: {len(dark):,}')\n",
    "\n",
    "gapmind = pd.read_csv(os.path.join(DATA_DIR, 'gapmind_gap_candidates.tsv'), sep='\\t')\n",
    "print(f'GapMind gap candidates: {len(gapmind):,} (organism-pathway pairs with dark genes near gaps)')\n",
    "\n",
    "concordance = pd.read_csv(os.path.join(DATA_DIR, 'concordance_scores.tsv'), sep='\\t')\n",
    "print(f'Concordance scores: {len(concordance)} ortholog groups')\n",
    "\n",
    "phylo = pd.read_csv(os.path.join(DATA_DIR, 'phylogenetic_breadth.tsv'), sep='\\t')\n",
    "print(f'Phylogenetic breadth: {len(phylo):,} gene clusters')\n",
    "\n",
    "carrier_tests = pd.read_csv(os.path.join(DATA_DIR, 'carrier_noncarrier_tests.tsv'), sep='\\t')\n",
    "print(f'Carrier tests: {len(carrier_tests)} clusters')\n",
    "\n",
    "lab_field = pd.read_csv(os.path.join(DATA_DIR, 'lab_field_concordance.tsv'), sep='\\t')\n",
    "print(f'Lab-field concordance: {len(lab_field)} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:25.255365Z",
     "iopub.status.busy": "2026-02-25T21:04:25.255253Z",
     "iopub.status.idle": "2026-02-25T21:04:25.271355Z",
     "shell.execute_reply": "2026-02-25T21:04:25.270697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark genes with strong fitness or essential: 17,344\n",
      "  Strong fitness (|fit| >= 2): 7,787\n",
      "  Essential dark: 9,557\n",
      "  Organisms: 48\n",
      "\n",
      "Annotation classes:\n",
      "annotation_class\n",
      "hypothetical       14430\n",
      "no_annotation       1103\n",
      "DUF                  915\n",
      "uncharacterized      896\n"
     ]
    }
   ],
   "source": [
    "# Focus on dark genes with strong fitness effects (the actionable set)\n",
    "# Include both: (1) strong fitness dark genes and (2) essential dark genes\n",
    "strong_dark = dark[\n",
    "    (dark['is_dark'] == True) &\n",
    "    (\n",
    "        (dark['max_abs_fit'].astype(float) >= 2.0) |\n",
    "        (dark['is_essential_dark'] == True)\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(f'Dark genes with strong fitness or essential: {len(strong_dark):,}')\n",
    "print(f'  Strong fitness (|fit| >= 2): {(strong_dark[\"max_abs_fit\"].astype(float) >= 2.0).sum():,}')\n",
    "print(f'  Essential dark: {(strong_dark[\"is_essential_dark\"] == True).sum():,}')\n",
    "print(f'  Organisms: {strong_dark[\"orgId\"].nunique()}')\n",
    "print(f'\\nAnnotation classes:')\n",
    "print(strong_dark['annotation_class'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Scoring Functions\n",
    "\n",
    "Each dimension returns a score in [0, 1]. Higher = better candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:25.273662Z",
     "iopub.status.busy": "2026-02-25T21:04:25.273550Z",
     "iopub.status.idle": "2026-02-25T21:04:25.276432Z",
     "shell.execute_reply": "2026-02-25T21:04:25.275895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring weights: {'fitness': 0.25, 'conservation': 0.2, 'inference': 0.2, 'pangenome': 0.15, 'biogeographic': 0.1, 'tractability': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Scoring weights\n",
    "WEIGHTS = {\n",
    "    'fitness': 0.25,\n",
    "    'conservation': 0.20,\n",
    "    'inference': 0.20,\n",
    "    'pangenome': 0.15,\n",
    "    'biogeographic': 0.10,\n",
    "    'tractability': 0.10,\n",
    "}\n",
    "assert abs(sum(WEIGHTS.values()) - 1.0) < 1e-6\n",
    "print('Scoring weights:', WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:25.278334Z",
     "iopub.status.busy": "2026-02-25T21:04:25.278229Z",
     "iopub.status.idle": "2026-02-25T21:04:25.287993Z",
     "shell.execute_reply": "2026-02-25T21:04:25.287402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring functions defined.\n",
      "Tractable organisms: 30\n"
     ]
    }
   ],
   "source": [
    "def _safe_int(val, default=0):\n",
    "    \"\"\"Safely convert to int, handling NaN/None.\"\"\"\n",
    "    if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "        return default\n",
    "    try:\n",
    "        return int(val)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "def _safe_float(val, default=0.0):\n",
    "    \"\"\"Safely convert to float, handling NaN/None.\"\"\"\n",
    "    if val is None:\n",
    "        return default\n",
    "    try:\n",
    "        f = float(val)\n",
    "        return default if np.isnan(f) else f\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def score_fitness(row):\n",
    "    \"\"\"Score fitness importance (0-1). Weight: 0.25.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # Max |fitness| contribution (0-0.5)\n",
    "    max_fit = _safe_float(row.get('max_abs_fit', 0))\n",
    "    # Normalize: 2 -> 0.25, 4 -> 0.5 (cap at 4)\n",
    "    score += min(max_fit / 8.0, 0.5)\n",
    "    \n",
    "    # Number of specific phenotypes (0-0.25)\n",
    "    n_sp = _safe_int(row.get('n_specific_phenotypes', 0))\n",
    "    score += min(n_sp / 20.0, 0.25)\n",
    "    \n",
    "    # Essential bonus (0.15)\n",
    "    if row.get('is_essential_dark') == True or row.get('essentiality_class') == 'essential_all':\n",
    "        score += 0.15\n",
    "    \n",
    "    # Number of condition classes (0-0.1)\n",
    "    n_cc = _safe_int(row.get('n_condition_classes', 0))\n",
    "    score += min(n_cc / 10.0, 0.1)\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def score_conservation(row, concordance_lookup):\n",
    "    \"\"\"Score cross-organism conservation (0-1). Weight: 0.20.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # Has ortholog in other FB organisms (0.3)\n",
    "    if row.get('has_ortholog') == True:\n",
    "        score += 0.3\n",
    "    \n",
    "    # Number of FB organisms with ortholog (0-0.3)\n",
    "    n_orgs = _safe_int(row.get('og_n_organisms', 0))\n",
    "    score += min(n_orgs / 48.0, 0.3) if n_orgs > 0 else 0\n",
    "    \n",
    "    # Cross-organism fitness concordance (0-0.4)\n",
    "    og_id = str(row.get('OG_id', ''))\n",
    "    if og_id and og_id != 'nan' and og_id in concordance_lookup:\n",
    "        conc = concordance_lookup[og_id]\n",
    "        max_conc = _safe_float(conc.get('max_concordance', 0))\n",
    "        score += max_conc * 0.4\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def score_inference(row, gapmind_org_lookup):\n",
    "    \"\"\"Score functional inference quality (0-1). Weight: 0.20.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # In a module with prediction (0.35)\n",
    "    if row.get('in_module') == True and pd.notna(row.get('module_prediction')) and str(row.get('module_prediction', '')) not in ('', 'nan'):\n",
    "        score += 0.35\n",
    "    elif row.get('in_module') == True:\n",
    "        score += 0.15  # In module but no prediction\n",
    "    \n",
    "    # Has domain annotations (0.15)\n",
    "    n_domains = _safe_int(row.get('n_domains', 0))\n",
    "    if n_domains > 0:\n",
    "        score += 0.15\n",
    "    \n",
    "    # Top co-fitness score (0-0.2)\n",
    "    cofit_score = _safe_float(row.get('top_cofit_score', 0))\n",
    "    if cofit_score > 0:\n",
    "        score += min(cofit_score / 1.0, 0.2)  # cofit typically 0-0.8\n",
    "    \n",
    "    # GapMind gap-filling evidence (0.2)\n",
    "    org_id = row.get('orgId', '')\n",
    "    if org_id in gapmind_org_lookup:\n",
    "        org_gaps = gapmind_org_lookup[org_id]\n",
    "        if any(_safe_int(g.get('n_dark_strong_fitness', 0)) > 0 for g in org_gaps):\n",
    "            score += 0.2\n",
    "        elif any(_safe_int(g.get('n_dark_genes', 0)) > 0 for g in org_gaps):\n",
    "            score += 0.1\n",
    "    \n",
    "    # Essential prediction (0.1)\n",
    "    epred = str(row.get('essential_prediction', ''))\n",
    "    if epred and epred not in ('', 'nan'):\n",
    "        score += 0.1\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def score_pangenome(row, phylo_lookup):\n",
    "    \"\"\"Score pangenome distribution (0-1). Weight: 0.15.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # Has pangenome link (0.2)\n",
    "    if row.get('has_pangenome_link') == True:\n",
    "        score += 0.2\n",
    "    \n",
    "    # Core/accessory classification (0.3)\n",
    "    if row.get('is_core') == True:\n",
    "        score += 0.3  # Core genes are interesting — conserved unknown function\n",
    "    elif row.get('is_auxiliary') == True:\n",
    "        score += 0.2  # Accessory — may have environmental-specific role\n",
    "    \n",
    "    # Phylogenetic breadth (0-0.5)\n",
    "    gc_id = str(row.get('gene_cluster_id', ''))\n",
    "    if gc_id and gc_id != 'nan' and gc_id in phylo_lookup:\n",
    "        breadth = phylo_lookup[gc_id]\n",
    "        bc = str(breadth.get('breadth_class', ''))\n",
    "        if bc == 'widespread':\n",
    "            score += 0.5  # 3+ phyla\n",
    "        elif bc == 'multi-phylum':\n",
    "            score += 0.35\n",
    "        elif bc == 'clade-restricted':\n",
    "            score += 0.2\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def score_biogeographic(row, carrier_lookup, labfield_lookup):\n",
    "    \"\"\"Score biogeographic signal (0-1). Weight: 0.10.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    gc_id = str(row.get('gene_cluster_id', ''))\n",
    "    if not gc_id or gc_id == 'nan':\n",
    "        return 0.0\n",
    "    \n",
    "    # Carrier vs non-carrier test result (0-0.5)\n",
    "    if gc_id in carrier_lookup:\n",
    "        ct = carrier_lookup[gc_id]\n",
    "        # Significant env test\n",
    "        env_fdr = _safe_float(ct.get('env_fdr', 1.0), 1.0)\n",
    "        if env_fdr < 0.05:\n",
    "            score += 0.5\n",
    "        elif env_fdr < 0.2:\n",
    "            score += 0.3\n",
    "        else:\n",
    "            env_p = _safe_float(ct.get('env_p_value', 1.0), 1.0)\n",
    "            if env_p < 0.05:\n",
    "                score += 0.15\n",
    "    \n",
    "    # Lab-field concordance (0-0.5)\n",
    "    if gc_id in labfield_lookup:\n",
    "        lf = labfield_lookup[gc_id]\n",
    "        if lf.get('is_concordant') == True:\n",
    "            score += 0.25\n",
    "            lf_fdr = _safe_float(lf.get('fdr', 1.0), 1.0)\n",
    "            if lf_fdr < 0.05:\n",
    "                score += 0.25\n",
    "            elif lf_fdr < 0.2:\n",
    "                score += 0.15\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "# Tractable organisms (well-developed genetic tools in FB)\n",
    "TRACTABLE_ORGS = {\n",
    "    'Keio', 'Deshi', 'SB2B', 'Pse', 'Pseu', 'pseudo5_N2C3_1', 'pseudo3_N2E2',\n",
    "    'pseudo13_GW456_L13', 'pseudo1_N1B4', 'Shew', 'Shewmr4', 'Marino',\n",
    "    'MR1', 'Smeli', 'BW25113', 'Koxy', 'Acinetobacter', 'Abaumannii',\n",
    "    'Synpcc7942', 'Synpcc6803', 'Rleg', 'Rpha', 'Bfrag', 'Clostridi',\n",
    "    'Caulobacter', 'Geobacter', 'Sinorhizobium', 'Sphingomonas',\n",
    "    'BT', 'Bacteroides_theta',\n",
    "}\n",
    "\n",
    "\n",
    "def score_tractability(row):\n",
    "    \"\"\"Score experimental tractability (0-1). Weight: 0.10.\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # In a tractable organism (0.4)\n",
    "    org = row.get('orgId', '')\n",
    "    if org in TRACTABLE_ORGS:\n",
    "        score += 0.4\n",
    "    \n",
    "    # Not essential (can make knockouts) (0.3)\n",
    "    if row.get('is_essential_dark') != True and row.get('essentiality_class') != 'essential_all':\n",
    "        score += 0.3\n",
    "    else:\n",
    "        score += 0.1  # Essential genes are harder to study but important\n",
    "    \n",
    "    # Has characterized co-fitness partners (0.15)\n",
    "    partners = str(row.get('top_cofit_partners', ''))\n",
    "    if partners and partners not in ('nan', ''):\n",
    "        score += 0.15\n",
    "    \n",
    "    # Has specific phenotype (clear experimental lead) (0.15)\n",
    "    n_sp = _safe_int(row.get('n_specific_phenotypes', 0))\n",
    "    if n_sp > 0:\n",
    "        score += 0.15\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "print('Scoring functions defined.')\n",
    "print(f'Tractable organisms: {len(TRACTABLE_ORGS)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Build Lookups & Score All Dark Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:25.290133Z",
     "iopub.status.busy": "2026-02-25T21:04:25.290020Z",
     "iopub.status.idle": "2026-02-25T21:04:26.269687Z",
     "shell.execute_reply": "2026-02-25T21:04:26.268794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance lookup: 65 OGs\n",
      "GapMind lookup: 44 organisms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phylo lookup: 30,756 clusters\n",
      "Carrier test lookup: 151 clusters\n",
      "Lab-field lookup: 47 clusters\n"
     ]
    }
   ],
   "source": [
    "# Build lookup dictionaries for efficient scoring\n",
    "\n",
    "# Concordance by OG_id\n",
    "concordance_lookup = {}\n",
    "for _, r in concordance.iterrows():\n",
    "    concordance_lookup[str(r['ogId'])] = r.to_dict()\n",
    "print(f'Concordance lookup: {len(concordance_lookup)} OGs')\n",
    "\n",
    "# GapMind by orgId\n",
    "gapmind_org_lookup = {}\n",
    "for _, r in gapmind.iterrows():\n",
    "    org = r['orgId']\n",
    "    if org not in gapmind_org_lookup:\n",
    "        gapmind_org_lookup[org] = []\n",
    "    gapmind_org_lookup[org].append(r.to_dict())\n",
    "print(f'GapMind lookup: {len(gapmind_org_lookup)} organisms')\n",
    "\n",
    "# Phylogenetic breadth by gene_cluster_id\n",
    "phylo_lookup = {}\n",
    "for _, r in phylo.iterrows():\n",
    "    phylo_lookup[r['gene_cluster_id']] = r.to_dict()\n",
    "print(f'Phylo lookup: {len(phylo_lookup):,} clusters')\n",
    "\n",
    "# Carrier tests by gene_cluster_id\n",
    "carrier_lookup = {}\n",
    "for _, r in carrier_tests.iterrows():\n",
    "    carrier_lookup[r['gene_cluster_id']] = r.to_dict()\n",
    "print(f'Carrier test lookup: {len(carrier_lookup)} clusters')\n",
    "\n",
    "# Lab-field concordance by gene_cluster_id\n",
    "labfield_lookup = {}\n",
    "for _, r in lab_field.iterrows():\n",
    "    labfield_lookup[r['gene_cluster_id']] = r.to_dict()\n",
    "print(f'Lab-field lookup: {len(labfield_lookup)} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:26.272051Z",
     "iopub.status.busy": "2026-02-25T21:04:26.271920Z",
     "iopub.status.idle": "2026-02-25T21:04:27.553921Z",
     "shell.execute_reply": "2026-02-25T21:04:27.553048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 17,344 dark genes\n",
      "\n",
      "Score distribution:\n",
      "count    17344.000000\n",
      "mean         0.262347\n",
      "std          0.127407\n",
      "min          0.047500\n",
      "25%          0.155833\n",
      "50%          0.257108\n",
      "75%          0.350000\n",
      "max          0.649986\n",
      "\n",
      "Score quantiles:\n",
      "  99th percentile: 0.547\n",
      "  95th percentile: 0.491\n",
      "  90th percentile: 0.447\n",
      "  75th percentile: 0.350\n",
      "  50th percentile: 0.257\n",
      "  25th percentile: 0.156\n"
     ]
    }
   ],
   "source": [
    "# Score all strong dark genes\n",
    "scores = []\n",
    "\n",
    "for idx, row in strong_dark.iterrows():\n",
    "    s_fit = score_fitness(row)\n",
    "    s_cons = score_conservation(row, concordance_lookup)\n",
    "    s_inf = score_inference(row, gapmind_org_lookup)\n",
    "    s_pan = score_pangenome(row, phylo_lookup)\n",
    "    s_bio = score_biogeographic(row, carrier_lookup, labfield_lookup)\n",
    "    s_tract = score_tractability(row)\n",
    "    \n",
    "    total = (\n",
    "        s_fit * WEIGHTS['fitness'] +\n",
    "        s_cons * WEIGHTS['conservation'] +\n",
    "        s_inf * WEIGHTS['inference'] +\n",
    "        s_pan * WEIGHTS['pangenome'] +\n",
    "        s_bio * WEIGHTS['biogeographic'] +\n",
    "        s_tract * WEIGHTS['tractability']\n",
    "    )\n",
    "    \n",
    "    scores.append({\n",
    "        'orgId': row['orgId'],\n",
    "        'locusId': row['locusId'],\n",
    "        'desc': row.get('desc', ''),\n",
    "        'annotation_class': row.get('annotation_class', ''),\n",
    "        'max_abs_fit': row.get('max_abs_fit', 0),\n",
    "        'top_condition_class': row.get('top_condition_class', ''),\n",
    "        'top_condition_fit': row.get('top_condition_fit', ''),\n",
    "        'n_specific_phenotypes': row.get('n_specific_phenotypes', 0),\n",
    "        'n_condition_classes': row.get('n_condition_classes', 0),\n",
    "        'gene_cluster_id': row.get('gene_cluster_id', ''),\n",
    "        'is_core': row.get('is_core', False),\n",
    "        'is_auxiliary': row.get('is_auxiliary', False),\n",
    "        'module': row.get('module', ''),\n",
    "        'module_prediction': row.get('module_prediction', ''),\n",
    "        'OG_id': row.get('OG_id', ''),\n",
    "        'og_n_organisms': row.get('og_n_organisms', 0),\n",
    "        'essentiality_class': row.get('essentiality_class', ''),\n",
    "        'is_essential_dark': row.get('is_essential_dark', False),\n",
    "        'essential_prediction': row.get('essential_prediction', ''),\n",
    "        'n_domains': row.get('n_domains', 0),\n",
    "        'domain_names': row.get('domain_names', ''),\n",
    "        'top_cofit_partners': row.get('top_cofit_partners', ''),\n",
    "        'top_cofit_score': row.get('top_cofit_score', 0),\n",
    "        's_fitness': s_fit,\n",
    "        's_conservation': s_cons,\n",
    "        's_inference': s_inf,\n",
    "        's_pangenome': s_pan,\n",
    "        's_biogeographic': s_bio,\n",
    "        's_tractability': s_tract,\n",
    "        'total_score': total,\n",
    "    })\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df = scores_df.sort_values('total_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f'Scored {len(scores_df):,} dark genes')\n",
    "print(f'\\nScore distribution:')\n",
    "print(scores_df['total_score'].describe().to_string())\n",
    "print(f'\\nScore quantiles:')\n",
    "for q in [0.99, 0.95, 0.90, 0.75, 0.50, 0.25]:\n",
    "    print(f'  {q*100:.0f}th percentile: {scores_df[\"total_score\"].quantile(q):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:27.555919Z",
     "iopub.status.busy": "2026-02-25T21:04:27.555808Z",
     "iopub.status.idle": "2026-02-25T21:04:27.560534Z",
     "shell.execute_reply": "2026-02-25T21:04:27.559985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component score medians:\n",
      "  fitness        : median=0.150, mean=0.296, non-zero=17344 (100.0%)\n",
      "  conservation   : median=0.000, mean=0.211, non-zero=7938 (45.8%)\n",
      "  inference      : median=0.350, mean=0.346, non-zero=16893 (97.4%)\n",
      "  pangenome      : median=0.400, mean=0.303, non-zero=11168 (64.4%)\n",
      "  biogeographic  : median=0.000, mean=0.001, non-zero=58 (0.3%)\n",
      "  tractability   : median=0.300, mean=0.313, non-zero=17344 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Component score distributions\n",
    "component_cols = ['s_fitness', 's_conservation', 's_inference', 's_pangenome',\n",
    "                  's_biogeographic', 's_tractability']\n",
    "print('Component score medians:')\n",
    "for col in component_cols:\n",
    "    name = col.replace('s_', '')\n",
    "    nonzero = (scores_df[col] > 0).sum()\n",
    "    print(f'  {name:15s}: median={scores_df[col].median():.3f}, '\n",
    "          f'mean={scores_df[col].mean():.3f}, '\n",
    "          f'non-zero={nonzero} ({nonzero/len(scores_df)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Top 100 Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:27.562336Z",
     "iopub.status.busy": "2026-02-25T21:04:27.562231Z",
     "iopub.status.idle": "2026-02-25T21:04:27.567573Z",
     "shell.execute_reply": "2026-02-25T21:04:27.567039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 candidates:\n",
      "  Score range: 0.556 – 0.650\n",
      "  Organisms: 23\n",
      "\n",
      "  Organism distribution:\n",
      "orgId\n",
      "MR1               25\n",
      "pseudo5_N2C3_1    18\n",
      "Marino             9\n",
      "Putida             7\n",
      "Keio               6\n",
      "DvH                4\n",
      "psRCH2             4\n",
      "Smeli              4\n",
      "Koxy               4\n",
      "pseudo1_N1B4       2\n",
      "\n",
      "  Condition classes:\n",
      "top_condition_class\n",
      "stress             46\n",
      "carbon source      27\n",
      "nitrogen source    14\n",
      "motility            7\n",
      "pH                  4\n",
      "vitamin             1\n",
      "anaerobic           1\n",
      "\n",
      "  Annotation classes:\n",
      "annotation_class\n",
      "hypothetical       85\n",
      "uncharacterized    15\n"
     ]
    }
   ],
   "source": [
    "# Select top 100\n",
    "top100 = scores_df.head(100).copy()\n",
    "\n",
    "print(f'Top 100 candidates:')\n",
    "print(f'  Score range: {top100[\"total_score\"].min():.3f} – {top100[\"total_score\"].max():.3f}')\n",
    "print(f'  Organisms: {top100[\"orgId\"].nunique()}')\n",
    "print(f'\\n  Organism distribution:')\n",
    "print(top100['orgId'].value_counts().head(10).to_string())\n",
    "print(f'\\n  Condition classes:')\n",
    "print(top100['top_condition_class'].value_counts().to_string())\n",
    "print(f'\\n  Annotation classes:')\n",
    "print(top100['annotation_class'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:27.569413Z",
     "iopub.status.busy": "2026-02-25T21:04:27.569310Z",
     "iopub.status.idle": "2026-02-25T21:04:27.580496Z",
     "shell.execute_reply": "2026-02-25T21:04:27.579961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis confidence distribution:\n",
      "hypothesis_confidence\n",
      "high      86\n",
      "medium    14\n"
     ]
    }
   ],
   "source": [
    "# Build functional hypothesis for each candidate\n",
    "def build_hypothesis(row):\n",
    "    \"\"\"Construct best functional hypothesis from available evidence.\"\"\"\n",
    "    parts = []\n",
    "    confidence = 'low'\n",
    "    \n",
    "    # Module-based prediction (highest confidence)\n",
    "    pred = row.get('module_prediction', '')\n",
    "    if pd.notna(pred) and pred != '' and pred != 'nan':\n",
    "        parts.append(f'Module prediction: {pred}')\n",
    "        confidence = 'medium'\n",
    "    \n",
    "    # Essential prediction\n",
    "    epred = row.get('essential_prediction', '')\n",
    "    if pd.notna(epred) and epred != '' and epred != 'nan':\n",
    "        parts.append(f'Essential gene prediction: {epred}')\n",
    "        if confidence == 'low':\n",
    "            confidence = 'medium'\n",
    "    \n",
    "    # Domain clues\n",
    "    domains = row.get('domain_names', '')\n",
    "    if pd.notna(domains) and domains != '' and domains != 'nan':\n",
    "        parts.append(f'Domain hits: {domains}')\n",
    "        if confidence == 'low':\n",
    "            confidence = 'low-medium'\n",
    "    \n",
    "    # Condition-based inference\n",
    "    cond = row.get('top_condition_class', '')\n",
    "    if pd.notna(cond) and cond != '' and cond != 'nan':\n",
    "        parts.append(f'Strong fitness under: {cond}')\n",
    "    \n",
    "    # Co-fitness partners\n",
    "    partners = str(row.get('top_cofit_partners', ''))\n",
    "    if partners and partners != 'nan' and partners != '':\n",
    "        # Truncate to first 3\n",
    "        p_list = partners.split(';')[:3]\n",
    "        parts.append(f'Co-fitness partners: {\"; \".join(p_list)}')\n",
    "    \n",
    "    # Multiple supporting evidence raises confidence\n",
    "    if len(parts) >= 3 and confidence == 'medium':\n",
    "        confidence = 'high'\n",
    "    elif len(parts) >= 2 and confidence == 'low-medium':\n",
    "        confidence = 'medium'\n",
    "    \n",
    "    hypothesis = ' | '.join(parts) if parts else 'No functional clues'\n",
    "    return hypothesis, confidence\n",
    "\n",
    "\n",
    "# Condition-specific media recipes\n",
    "MEDIA_RECIPES = {\n",
    "    'stress': 'M9 minimal + 0.2% glucose, ± stress agent (0.3M NaCl, 1 mM H2O2, or 42°C)',\n",
    "    'carbon source': 'M9 minimal + varied carbon (0.2% glucose, acetate, citrate, or succinate)',\n",
    "    'nitrogen source': 'M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or amino acid supplements',\n",
    "    'anaerobic': 'M9 minimal + 0.2% glucose + 20 mM fumarate, anaerobic chamber',\n",
    "    'motility': 'soft agar (0.3% agar in LB or M9), 30°C for 6-8h',\n",
    "    'pH': 'M9 minimal + 0.2% glucose, buffered at pH 5.5, 7.0, and 8.5',\n",
    "    'temperature': 'LB at 25°C, 37°C, and 42°C; OD600 growth curves',\n",
    "    'vitamin': 'M9 minimal + 0.2% glucose, ± vitamin supplement (B12, thiamine)',\n",
    "}\n",
    "\n",
    "\n",
    "def suggest_experiment(row):\n",
    "    \"\"\"Suggest experimental approach with specific protocols.\"\"\"\n",
    "    org = row.get('orgId', '')\n",
    "    cond = str(row.get('top_condition_class', ''))\n",
    "    locus = row.get('locusId', '')\n",
    "    is_ess = row.get('is_essential_dark') == True\n",
    "    \n",
    "    # Select media based on condition\n",
    "    media = MEDIA_RECIPES.get(cond, 'LB rich media at 37°C')\n",
    "    \n",
    "    if is_ess:\n",
    "        parts = [\n",
    "            f'CRISPRi knockdown: sgRNA targeting first 50% of {locus} ORF in {org}',\n",
    "            f'Media: {media}',\n",
    "            f'Controls: non-targeting sgRNA + uninduced dCas9',\n",
    "            f'Readout: OD600 at 0, 6, 12, 24h (n=3)',\n",
    "            f'Success: >20% growth reduction vs control at 12h',\n",
    "        ]\n",
    "    else:\n",
    "        parts = [\n",
    "            f'RB-TnSeq validation: confirm fitness defect for {locus} mutant in {org}',\n",
    "            f'Media: {media}',\n",
    "            f'Controls: WT strain + known-phenotype mutant under same conditions',\n",
    "            f'Readout: barcode sequencing fitness score; expect |fitness| >= 2',\n",
    "        ]\n",
    "    \n",
    "    # Add module-based functional test\n",
    "    pred = row.get('module_prediction', '')\n",
    "    if pd.notna(pred) and pred != '' and pred != 'nan':\n",
    "        parts.append(f'Functional test: assay for predicted activity ({pred})')\n",
    "    \n",
    "    # Add complementation\n",
    "    parts.append(f'Validation: complement with WT {locus} on plasmid to confirm specificity')\n",
    "    \n",
    "    return '; '.join(parts)\n",
    "\n",
    "\n",
    "# Apply to top 100\n",
    "hypotheses = []\n",
    "experiments = []\n",
    "confidences = []\n",
    "\n",
    "for _, row in top100.iterrows():\n",
    "    hyp, conf = build_hypothesis(row)\n",
    "    hypotheses.append(hyp)\n",
    "    confidences.append(conf)\n",
    "    experiments.append(suggest_experiment(row))\n",
    "\n",
    "top100['functional_hypothesis'] = hypotheses\n",
    "top100['hypothesis_confidence'] = confidences\n",
    "top100['suggested_experiment'] = experiments\n",
    "\n",
    "print('Hypothesis confidence distribution:')\n",
    "print(top100['hypothesis_confidence'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:27.582332Z",
     "iopub.status.busy": "2026-02-25T21:04:27.582227Z",
     "iopub.status.idle": "2026-02-25T21:04:27.589218Z",
     "shell.execute_reply": "2026-02-25T21:04:27.588664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 20 FUNCTIONAL DARK MATTER CANDIDATES\n",
      "================================================================================\n",
      "\n",
      "--- Rank 1 (score: 0.650) ---\n",
      "  Gene: pseudo5_N2C3_1:AO356_11255\n",
      "  Description: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.3595443, Condition: nitrogen source\n",
      "  Specific phenotypes: 2, Condition classes: 2.0\n",
      "  Pangenome: ACCESSORY\n",
      "  Scores: fit=0.62 cons=0.60 inf=0.70 pan=0.40 bio=0.90 tract=0.85\n",
      "  Hypothesis (high): Module prediction: D-alanyl-D-alanine carboxypeptidase (EC 3.4.16.4) | Domain hits: EamA | Strong fitness under: nitroge\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for AO356_11255 mutant in pseudo5_N2C3_1; Media: M9 minimal + 0.2% glucose, \n",
      "\n",
      "--- Rank 2 (score: 0.632) ---\n",
      "  Gene: MR1:202463\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 6.355357, Condition: stress\n",
      "  Specific phenotypes: 6, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.85 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF01145 | Domain hits: YGGT | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 202463 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± stress agent (\n",
      "\n",
      "--- Rank 3 (score: 0.632) ---\n",
      "  Gene: MR1:199738\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 5.504226, Condition: nitrogen source\n",
      "  Specific phenotypes: 6, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.85 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: K03306 | Domain hits: Gcw_chp | TIGR02001 | Strong fitness under: nitrogen source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 199738 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or\n",
      "\n",
      "--- Rank 4 (score: 0.629) ---\n",
      "  Gene: MR1:203545\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.9569993, Condition: nitrogen source\n",
      "  Specific phenotypes: 6, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.84 cons=0.59 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: K03306 | Domain hits: DUF4124 | Strong fitness under: nitrogen source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 203545 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or\n",
      "\n",
      "--- Rank 5 (score: 0.628) ---\n",
      "  Gene: MR1:202450\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.864402, Condition: nitrogen source\n",
      "  Specific phenotypes: 6, Condition classes: 3.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.83 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: K03306 | Domain hits: Gly_transporter | Strong fitness under: nitrogen source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 202450 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or\n",
      "\n",
      "--- Rank 6 (score: 0.624) ---\n",
      "  Gene: pseudo5_N2C3_1:AO356_18320\n",
      "  Description: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.7920349, Condition: motility\n",
      "  Specific phenotypes: 6, Condition classes: 3.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.82 cons=0.59 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF00460 | Domain hits: MotY_N | OmpA | Strong fitness under: motility\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for AO356_18320 mutant in pseudo5_N2C3_1; Media: soft agar (0.3% agar in LB \n",
      "\n",
      "--- Rank 7 (score: 0.622) ---\n",
      "  Gene: pseudo1_N1B4:Pf1N1B4_3696\n",
      "  Description: FIG00955360: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.6684575, Condition: pH\n",
      "  Specific phenotypes: 5, Condition classes: 3.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.81 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF00361 | Domain hits: DUF3108 | Strong fitness under: pH\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for Pf1N1B4_3696 mutant in pseudo1_N1B4; Media: M9 minimal + 0.2% glucose, b\n",
      "\n",
      "--- Rank 8 (score: 0.620) ---\n",
      "  Gene: pseudo5_N2C3_1:AO356_15270\n",
      "  Description: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 5.587468, Condition: carbon source\n",
      "  Specific phenotypes: 4, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.80 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF02589 | Domain hits: LrgB | Strong fitness under: carbon source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for AO356_15270 mutant in pseudo5_N2C3_1; Media: M9 minimal + varied carbon \n",
      "\n",
      "--- Rank 9 (score: 0.620) ---\n",
      "  Gene: MR1:203247\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 4.6191206, Condition: stress\n",
      "  Specific phenotypes: 4, Condition classes: 4.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.80 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF01145 | Domain hits: GBBH-like_N | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 203247 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± stress agent (\n",
      "\n",
      "--- Rank 10 (score: 0.620) ---\n",
      "  Gene: MR1:201124\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 5.010497, Condition: nitrogen source\n",
      "  Specific phenotypes: 4, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.80 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF01144 | Domain hits: HgmA_N | HgmA_C | Strong fitness under: nitrogen source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 201124 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or\n",
      "\n",
      "--- Rank 11 (score: 0.613) ---\n",
      "  Gene: Marino:GFF2506\n",
      "  Description: conserved hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.379443, Condition: stress\n",
      "  Specific phenotypes: 6, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.77 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: Polymyxin resistance protein ArnT, undecaprenyl phosphate-alpha-L-Ara4N transferase; Melittin resista\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for GFF2506 mutant in Marino; Media: M9 minimal + 0.2% glucose, ± stress age\n",
      "\n",
      "--- Rank 12 (score: 0.611) ---\n",
      "  Gene: Marino:GFF1827\n",
      "  Description: protein belonging to uncharacterized protein family UPF0005\n",
      "  Class: uncharacterized\n",
      "  Max |fitness|: 3.706578, Condition: stress\n",
      "  Specific phenotypes: 4, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.76 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF01145 | Domain hits: Bax1-I | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for GFF1827 mutant in Marino; Media: M9 minimal + 0.2% glucose, ± stress age\n",
      "\n",
      "--- Rank 13 (score: 0.609) ---\n",
      "  Gene: MR1:201731\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.9589162, Condition: motility\n",
      "  Specific phenotypes: 7, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.84 cons=0.49 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: TIGR00254 | Domain hits: ZapC_C | ZapC_N | Strong fitness under: motility\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 201731 mutant in MR1; Media: soft agar (0.3% agar in LB or M9), 30°C for\n",
      "\n",
      "--- Rank 14 (score: 0.607) ---\n",
      "  Gene: Marino:GFF1367\n",
      "  Description: conserved hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 5.712205, Condition: stress\n",
      "  Specific phenotypes: 3, Condition classes: 1.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.75 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF00270 | Domain hits: IMS | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for GFF1367 mutant in Marino; Media: M9 minimal + 0.2% glucose, ± stress age\n",
      "\n",
      "--- Rank 15 (score: 0.607) ---\n",
      "  Gene: MR1:202474\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 7.1395607, Condition: carbon source\n",
      "  Specific phenotypes: 3, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.75 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: PF00460 | Domain hits: YggL_50S_bp | Strong fitness under: carbon source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 202474 mutant in MR1; Media: M9 minimal + varied carbon (0.2% glucose, a\n",
      "\n",
      "--- Rank 16 (score: 0.606) ---\n",
      "  Gene: pseudo5_N2C3_1:AO356_17245\n",
      "  Description: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.5553362, Condition: stress\n",
      "  Specific phenotypes: 4, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.74 cons=0.60 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: K00763 | Domain hits: Biotin_lipoyl_2 | HlyD_D23 | HlyD_3 | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for AO356_17245 mutant in pseudo5_N2C3_1; Media: M9 minimal + 0.2% glucose, \n",
      "\n",
      "--- Rank 17 (score: 0.605) ---\n",
      "  Gene: pseudo5_N2C3_1:AO356_08210\n",
      "  Description: hypothetical protein\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.978839, Condition: stress\n",
      "  Specific phenotypes: 4, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.80 cons=0.53 inf=0.70 pan=0.50 bio=0.00 tract=0.85\n",
      "  Hypothesis (high): Module prediction: K03808 | Domain hits: DUF3426 | zinc_ribbon_5 | zinc_ribbon_4 | Strong fitness under: stress\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for AO356_08210 mutant in pseudo5_N2C3_1; Media: M9 minimal + 0.2% glucose, \n",
      "\n",
      "--- Rank 18 (score: 0.605) ---\n",
      "  Gene: MR1:203720\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 4.537897, Condition: nitrogen source\n",
      "  Specific phenotypes: 4, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.80 cons=0.60 inf=0.55 pan=0.50 bio=0.00 tract=1.00\n",
      "  Hypothesis (medium): Domain hits: Ser_hydrolase | Strong fitness under: nitrogen source | Co-fitness partners: chaperone protein HscA (NCBI p\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 203720 mutant in MR1; Media: M9 minimal + 0.2% glucose, ± 10 mM NH4Cl or\n",
      "\n",
      "--- Rank 19 (score: 0.603) ---\n",
      "  Gene: Putida:PP_0765\n",
      "  Description: conserved exported protein of unknown function\n",
      "  Class: uncharacterized\n",
      "  Max |fitness|: 4.0637174, Condition: carbon source\n",
      "  Specific phenotypes: 5, Condition classes: 1.0\n",
      "  Pangenome: ACCESSORY\n",
      "  Scores: fit=0.85 cons=0.60 inf=0.70 pan=0.40 bio=0.25 tract=0.45\n",
      "  Hypothesis (high): Module prediction: PF00196 | Domain hits: DUF1302 | Strong fitness under: carbon source\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for PP_0765 mutant in Putida; Media: M9 minimal + varied carbon (0.2% glucos\n",
      "\n",
      "--- Rank 20 (score: 0.602) ---\n",
      "  Gene: MR1:203026\n",
      "  Description: conserved hypothetical protein (NCBI ptt file)\n",
      "  Class: hypothetical\n",
      "  Max |fitness|: 3.4892945, Condition: carbon source\n",
      "  Specific phenotypes: 6, Condition classes: 2.0\n",
      "  Pangenome: CORE\n",
      "  Scores: fit=0.79 cons=0.60 inf=0.55 pan=0.50 bio=0.00 tract=1.00\n",
      "  Hypothesis (medium): Domain hits: AFG1_ATPase | Strong fitness under: carbon source | Co-fitness partners: methylcitrate synthase (NCBI ptt f\n",
      "  Experiment: RB-TnSeq validation: confirm fitness defect for 203026 mutant in MR1; Media: M9 minimal + varied carbon (0.2% glucose, a\n"
     ]
    }
   ],
   "source": [
    "# Display top 20 candidates\n",
    "print('=' * 80)\n",
    "print('TOP 20 FUNCTIONAL DARK MATTER CANDIDATES')\n",
    "print('=' * 80)\n",
    "\n",
    "for i, (_, row) in enumerate(top100.head(20).iterrows()):\n",
    "    print(f'\\n--- Rank {i+1} (score: {row[\"total_score\"]:.3f}) ---')\n",
    "    print(f'  Gene: {row[\"orgId\"]}:{row[\"locusId\"]}')\n",
    "    print(f'  Description: {row[\"desc\"]}')\n",
    "    print(f'  Class: {row[\"annotation_class\"]}')\n",
    "    print(f'  Max |fitness|: {row[\"max_abs_fit\"]}, Condition: {row[\"top_condition_class\"]}')\n",
    "    print(f'  Specific phenotypes: {row[\"n_specific_phenotypes\"]}, Condition classes: {row[\"n_condition_classes\"]}')\n",
    "    if row.get('is_essential_dark') == True:\n",
    "        print(f'  ** ESSENTIAL **')\n",
    "    if row.get('is_core') == True:\n",
    "        print(f'  Pangenome: CORE')\n",
    "    elif row.get('is_auxiliary') == True:\n",
    "        print(f'  Pangenome: ACCESSORY')\n",
    "    print(f'  Scores: fit={row[\"s_fitness\"]:.2f} cons={row[\"s_conservation\"]:.2f} '\n",
    "          f'inf={row[\"s_inference\"]:.2f} pan={row[\"s_pangenome\"]:.2f} '\n",
    "          f'bio={row[\"s_biogeographic\"]:.2f} tract={row[\"s_tractability\"]:.2f}')\n",
    "    print(f'  Hypothesis ({row[\"hypothesis_confidence\"]}): {row[\"functional_hypothesis\"][:120]}')\n",
    "    print(f'  Experiment: {row[\"suggested_experiment\"][:120]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:27.590846Z",
     "iopub.status.busy": "2026-02-25T21:04:27.590741Z",
     "iopub.status.idle": "2026-02-25T21:04:28.355761Z",
     "shell.execute_reply": "2026-02-25T21:04:28.355018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fig13_score_components.png\n"
     ]
    }
   ],
   "source": [
    "# Figure 13: Score component breakdown\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "component_names = {\n",
    "    's_fitness': 'Fitness Importance (0.25)',\n",
    "    's_conservation': 'Cross-Organism Conservation (0.20)',\n",
    "    's_inference': 'Functional Inference (0.20)',\n",
    "    's_pangenome': 'Pangenome Distribution (0.15)',\n",
    "    's_biogeographic': 'Biogeographic Signal (0.10)',\n",
    "    's_tractability': 'Experimental Tractability (0.10)',\n",
    "}\n",
    "\n",
    "for ax, (col, name) in zip(axes.flat, component_names.items()):\n",
    "    # All genes in gray, top 100 in color\n",
    "    ax.hist(scores_df[col], bins=30, alpha=0.4, color='gray', label='All dark genes')\n",
    "    ax.hist(top100[col], bins=30, alpha=0.7, color='steelblue', label='Top 100')\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(name, fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "\n",
    "plt.suptitle(f'Scoring Component Distributions\\n(N={len(scores_df):,} dark genes, top 100 highlighted)',\n",
    "             fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig13_score_components.png'), dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print('Saved fig13_score_components.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:28.357933Z",
     "iopub.status.busy": "2026-02-25T21:04:28.357818Z",
     "iopub.status.idle": "2026-02-25T21:04:28.610638Z",
     "shell.execute_reply": "2026-02-25T21:04:28.609808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fig14_top20_dossiers.png\n"
     ]
    }
   ],
   "source": [
    "# Figure 14: Top 20 candidate dossier summary (stacked bar)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top20 = top100.head(20).copy()\n",
    "labels = [f'{row[\"orgId\"]}:{row[\"locusId\"]}' for _, row in top20.iterrows()]\n",
    "# Truncate long labels\n",
    "labels = [l[:25] for l in labels]\n",
    "\n",
    "y_pos = np.arange(len(top20))\n",
    "colors = ['#E53935', '#1E88E5', '#43A047', '#FB8C00', '#8E24AA', '#00ACC1']\n",
    "component_keys = ['s_fitness', 's_conservation', 's_inference', 's_pangenome',\n",
    "                  's_biogeographic', 's_tractability']\n",
    "component_labels = ['Fitness', 'Conservation', 'Inference', 'Pangenome',\n",
    "                    'Biogeographic', 'Tractability']\n",
    "\n",
    "left = np.zeros(len(top20))\n",
    "for i, (key, label) in enumerate(zip(component_keys, component_labels)):\n",
    "    vals = top20[key].values * list(WEIGHTS.values())[i]\n",
    "    ax.barh(y_pos, vals, left=left, color=colors[i], label=f'{label} ({list(WEIGHTS.values())[i]:.2f})',\n",
    "            alpha=0.8)\n",
    "    left += vals\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels, fontsize=9)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Weighted Score')\n",
    "ax.set_title('Top 20 Dark Matter Candidates — Score Breakdown')\n",
    "ax.legend(loc='lower right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig14_top20_dossiers.png'), dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print('Saved fig14_top20_dossiers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:28.612961Z",
     "iopub.status.busy": "2026-02-25T21:04:28.612846Z",
     "iopub.status.idle": "2026-02-25T21:04:28.799205Z",
     "shell.execute_reply": "2026-02-25T21:04:28.798474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fig15_organism_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Figure 15: Organism distribution and condition class breakdown\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel A: Organism distribution of top 100\n",
    "ax = axes[0]\n",
    "org_counts = top100['orgId'].value_counts().head(15)\n",
    "y_pos = range(len(org_counts))\n",
    "ax.barh(y_pos, org_counts.values, color='steelblue', alpha=0.7)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(org_counts.index, fontsize=9)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Number of top-100 candidates')\n",
    "ax.set_title('Top 100 Candidates by Organism')\n",
    "\n",
    "# Panel B: Condition class pie chart\n",
    "ax = axes[1]\n",
    "cond_counts = top100['top_condition_class'].fillna('unknown').value_counts()\n",
    "colors_pie = plt.cm.Set3(np.linspace(0, 1, len(cond_counts)))\n",
    "wedges, texts, autotexts = ax.pie(cond_counts.values, labels=cond_counts.index,\n",
    "                                   autopct='%1.0f%%', colors=colors_pie, startangle=90)\n",
    "for text in texts:\n",
    "    text.set_fontsize(9)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(8)\n",
    "ax.set_title('Top 100 by Condition Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'fig15_organism_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print('Saved fig15_organism_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Save Outputs & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:28.801397Z",
     "iopub.status.busy": "2026-02-25T21:04:28.801285Z",
     "iopub.status.idle": "2026-02-25T21:04:28.945594Z",
     "shell.execute_reply": "2026-02-25T21:04:28.944860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prioritized_candidates.tsv: 100 candidates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scoring_all_dark.tsv: 17,344 genes\n"
     ]
    }
   ],
   "source": [
    "# Save top 100 candidates\n",
    "top100.to_csv(os.path.join(DATA_DIR, 'prioritized_candidates.tsv'), sep='\\t', index=False)\n",
    "print(f'Saved prioritized_candidates.tsv: {len(top100)} candidates')\n",
    "\n",
    "# Save all scores\n",
    "scores_df.to_csv(os.path.join(DATA_DIR, 'scoring_all_dark.tsv'), sep='\\t', index=False)\n",
    "print(f'Saved scoring_all_dark.tsv: {len(scores_df):,} genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:28.947564Z",
     "iopub.status.busy": "2026-02-25T21:04:28.947449Z",
     "iopub.status.idle": "2026-02-25T21:04:29.204939Z",
     "shell.execute_reply": "2026-02-25T21:04:29.204207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NB05: PRIORITIZATION & CANDIDATE DOSSIERS — SUMMARY\n",
      "======================================================================\n",
      "\n",
      "--- Scoring ---\n",
      "Genes scored: 17,344 (strong fitness + essential dark)\n",
      "Scoring dimensions: 6 (fitness, conservation, inference, pangenome, biogeographic, tractability)\n",
      "Score range: 0.048 – 0.650\n",
      "\n",
      "--- Top 100 Candidates ---\n",
      "Score range: 0.556 – 0.650\n",
      "Organisms: 23\n",
      "Essential: 0\n",
      "With module prediction: 89\n",
      "With domains: 97\n",
      "\n",
      "Hypothesis confidence:\n",
      "hypothesis_confidence\n",
      "high      86\n",
      "medium    14\n",
      "\n",
      "--- Project-Wide Dark Gene Statistics ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dark genes: 57,011"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  With pangenome link: 39,532\n",
      "  In module: 6,142\n",
      "  With strong fitness: 7,787\n",
      "  Essential: 9,557\n",
      "\n",
      "Output files:\n",
      "  prioritized_candidates.tsv: 80.0 KB\n",
      "  scoring_all_dark.tsv: 3538.1 KB\n",
      "\n",
      "Figures:\n",
      "  fig13_score_components.png\n",
      "  fig14_top20_dossiers.png\n",
      "  fig15_organism_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Project-wide summary statistics\n",
    "print('=' * 70)\n",
    "print('NB05: PRIORITIZATION & CANDIDATE DOSSIERS — SUMMARY')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'\\n--- Scoring ---')\n",
    "print(f'Genes scored: {len(scores_df):,} (strong fitness + essential dark)')\n",
    "print(f'Scoring dimensions: 6 (fitness, conservation, inference, pangenome, biogeographic, tractability)')\n",
    "print(f'Score range: {scores_df[\"total_score\"].min():.3f} – {scores_df[\"total_score\"].max():.3f}')\n",
    "\n",
    "print(f'\\n--- Top 100 Candidates ---')\n",
    "print(f'Score range: {top100[\"total_score\"].min():.3f} – {top100[\"total_score\"].max():.3f}')\n",
    "print(f'Organisms: {top100[\"orgId\"].nunique()}')\n",
    "print(f'Essential: {(top100[\"is_essential_dark\"] == True).sum()}')\n",
    "print(f'With module prediction: {top100[\"module_prediction\"].notna().sum() - (top100[\"module_prediction\"] == \"\").sum()}')\n",
    "print(f'With domains: {(top100[\"n_domains\"].fillna(0).astype(int) > 0).sum()}')\n",
    "\n",
    "print(f'\\nHypothesis confidence:')\n",
    "print(top100['hypothesis_confidence'].value_counts().to_string())\n",
    "\n",
    "print(f'\\n--- Project-Wide Dark Gene Statistics ---')\n",
    "all_dark = pd.read_csv(os.path.join(DATA_DIR, 'dark_genes_only.tsv'), sep='\\t', low_memory=False)\n",
    "print(f'Total dark genes: {len(all_dark):,}')\n",
    "print(f'  With pangenome link: {all_dark[\"has_pangenome_link\"].sum():,}')\n",
    "print(f'  In module: {(all_dark[\"in_module\"] == True).sum():,}')\n",
    "print(f'  With strong fitness: {(all_dark[\"max_abs_fit\"].astype(float) >= 2.0).sum():,}')\n",
    "print(f'  Essential: {(all_dark[\"is_essential_dark\"] == True).sum():,}')\n",
    "\n",
    "print(f'\\nOutput files:')\n",
    "for f in ['prioritized_candidates.tsv', 'scoring_all_dark.tsv']:\n",
    "    fp = os.path.join(DATA_DIR, f)\n",
    "    if os.path.exists(fp):\n",
    "        size_kb = os.path.getsize(fp) / 1024\n",
    "        print(f'  {f}: {size_kb:.1f} KB')\n",
    "print(f'\\nFigures:')\n",
    "for f in ['fig13_score_components.png', 'fig14_top20_dossiers.png', 'fig15_organism_distribution.png']:\n",
    "    fp = os.path.join(FIG_DIR, f)\n",
    "    if os.path.exists(fp):\n",
    "        print(f'  {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Robustness Check\n",
    "\n",
    "Test whether the top-ranked fitness-active dark gene candidates are sensitive to arbitrary weight choices by re-scoring under 6 alternative weight configurations and measuring rank stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T21:04:29.207010Z",
     "iopub.status.busy": "2026-02-25T21:04:29.206900Z",
     "iopub.status.idle": "2026-02-25T21:04:29.284627Z",
     "shell.execute_reply": "2026-02-25T21:04:29.283888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB05 Fitness-Active Scoring Sensitivity Analysis\n",
      "======================================================================\n",
      "  original                   rho=1.0000  top-50=50/50 (100%)  top-100=100/100 (100%)\n",
      "  equal                      rho=0.9926  top-50=39/50 (78%)  top-100=71/100 (71%)\n",
      "  fitness_dominant           rho=0.9694  top-50=42/50 (84%)  top-100=79/100 (79%)\n",
      "  conservation_dominant      rho=0.9366  top-50=32/50 (64%)  top-100=54/100 (54%)\n",
      "  drop_biogeographic         rho=0.9998  top-50=46/50 (92%)  top-100=93/100 (93%)\n",
      "  drop_tractability          rho=0.9872  top-50=32/50 (64%)  top-100=70/100 (70%)\n",
      "\n",
      "Across 5 alternative configurations:\n",
      "  Rank correlation range: 0.9366 – 0.9998 (mean=0.9771)\n",
      "  Top-50 overlap range: 32/50 – 46/50\n",
      "  Top-100 overlap range: 54/100 – 93/100\n",
      "\n",
      "  FRAGILE: Rankings sensitive to weight choices — report as limitation\n",
      "\n",
      "Saved scoring_sensitivity_nb05.tsv\n"
     ]
    }
   ],
   "source": [
    "# Scoring sensitivity analysis for NB05 fitness-active dark gene prioritization\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Load scored data\n",
    "scored = pd.read_csv(os.path.join(DATA_DIR, 'scoring_all_dark.tsv'), sep='\\t')\n",
    "\n",
    "# Weight configurations to test (6 dimensions)\n",
    "weight_configs = {\n",
    "    'original': {'fitness': 0.25, 'conservation': 0.20, 'inference': 0.20, 'pangenome': 0.15, 'biogeographic': 0.10, 'tractability': 0.10},\n",
    "    'equal': {'fitness': 1/6, 'conservation': 1/6, 'inference': 1/6, 'pangenome': 1/6, 'biogeographic': 1/6, 'tractability': 1/6},\n",
    "    'fitness_dominant': {'fitness': 0.40, 'conservation': 0.12, 'inference': 0.12, 'pangenome': 0.12, 'biogeographic': 0.12, 'tractability': 0.12},\n",
    "    'conservation_dominant': {'fitness': 0.12, 'conservation': 0.40, 'inference': 0.12, 'pangenome': 0.12, 'biogeographic': 0.12, 'tractability': 0.12},\n",
    "    'drop_biogeographic': {'fitness': 0.27, 'conservation': 0.22, 'inference': 0.22, 'pangenome': 0.17, 'biogeographic': 0.0, 'tractability': 0.12},\n",
    "    'drop_tractability': {'fitness': 0.28, 'conservation': 0.22, 'inference': 0.22, 'pangenome': 0.17, 'biogeographic': 0.11, 'tractability': 0.0},\n",
    "}\n",
    "\n",
    "# Original ranking\n",
    "original_rank = scored['total_score'].rank(ascending=False).values\n",
    "original_top50 = set(scored.nlargest(50, 'total_score').index)\n",
    "original_top100 = set(scored.nlargest(100, 'total_score').index)\n",
    "\n",
    "results = []\n",
    "for config_name, weights in weight_configs.items():\n",
    "    # Compute new total score\n",
    "    new_score = sum(scored[f's_{dim}'] * w for dim, w in weights.items())\n",
    "    new_rank = new_score.rank(ascending=False).values\n",
    "    \n",
    "    # Spearman rank correlation with original\n",
    "    rho, p = spearmanr(original_rank, new_rank)\n",
    "    \n",
    "    # Top-50 and top-100 overlap\n",
    "    new_top50 = set(new_score.nlargest(50).index)\n",
    "    new_top100 = set(new_score.nlargest(100).index)\n",
    "    overlap_50 = len(original_top50 & new_top50)\n",
    "    overlap_100 = len(original_top100 & new_top100)\n",
    "    \n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'spearman_rho': rho,\n",
    "        'spearman_p': p,\n",
    "        'top50_overlap': overlap_50,\n",
    "        'top50_pct': 100 * overlap_50 / 50,\n",
    "        'top100_overlap': overlap_100,\n",
    "        'top100_pct': 100 * overlap_100 / 100,\n",
    "        'weights': str(weights),\n",
    "    })\n",
    "\n",
    "sensitivity_nb05 = pd.DataFrame(results)\n",
    "print('NB05 Fitness-Active Scoring Sensitivity Analysis')\n",
    "print('=' * 70)\n",
    "for _, row in sensitivity_nb05.iterrows():\n",
    "    print(f'  {row[\"config\"]:25s}  rho={row[\"spearman_rho\"]:.4f}  '\n",
    "          f'top-50={row[\"top50_overlap\"]}/50 ({row[\"top50_pct\"]:.0f}%)  '\n",
    "          f'top-100={row[\"top100_overlap\"]}/100 ({row[\"top100_pct\"]:.0f}%)')\n",
    "\n",
    "# Summary statistics\n",
    "non_original = sensitivity_nb05[sensitivity_nb05['config'] != 'original']\n",
    "min_rho = non_original['spearman_rho'].min()\n",
    "mean_rho = non_original['spearman_rho'].mean()\n",
    "min_overlap_50 = non_original['top50_overlap'].min()\n",
    "min_overlap_100 = non_original['top100_overlap'].min()\n",
    "\n",
    "print(f'\\nAcross 5 alternative configurations:')\n",
    "print(f'  Rank correlation range: {min_rho:.4f} – {non_original[\"spearman_rho\"].max():.4f} (mean={mean_rho:.4f})')\n",
    "print(f'  Top-50 overlap range: {min_overlap_50}/50 – {non_original[\"top50_overlap\"].max()}/50')\n",
    "print(f'  Top-100 overlap range: {min_overlap_100}/100 – {non_original[\"top100_overlap\"].max()}/100')\n",
    "\n",
    "if min_rho > 0.95 and min_overlap_50 >= 45:\n",
    "    print(f'\\n  ROBUST: Rankings stable under all weight perturbations')\n",
    "elif min_rho > 0.85 and min_overlap_50 >= 35:\n",
    "    print(f'\\n  MODERATELY ROBUST: Rankings mostly stable')\n",
    "else:\n",
    "    print(f'\\n  FRAGILE: Rankings sensitive to weight choices — report as limitation')\n",
    "\n",
    "# Save\n",
    "sensitivity_nb05.to_csv(os.path.join(DATA_DIR, 'scoring_sensitivity_nb05.tsv'), sep='\\t', index=False)\n",
    "print(f'\\nSaved scoring_sensitivity_nb05.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
