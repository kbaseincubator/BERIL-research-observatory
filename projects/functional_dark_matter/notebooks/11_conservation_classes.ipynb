{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NB11: Conservation × Dark Matter Classes with Experimental Prioritization\n\n**Goal**: Use the full pangenome (27,690 species) to properly rank dark gene OGs by taxonomic breadth, cross-reference with hypothesis strength, compute an importance score (conservation × ignorance), and solve a weighted minimum covering set to order experiments for maximum novel functional discovery.\n\n**Sections**:\n1. Pangenome Species Distribution (Spark)\n2. Taxonomic Tier Classification\n3. Hypothesis Status Classification\n4. Importance Score (conservation × ignorance)\n5. Minimum Covering Set (conservation-weighted)\n6. Per-Organism Experimental Plans\n7. Figures (fig32–fig37)\n\n**Inputs**: `phylogenetic_breadth.tsv`, `dark_genes_integrated.tsv`, `concordance_detailed.tsv`, `gapmind_domain_matched.tsv`, `scoring_all_dark.tsv`\n\n**Outputs**: 6 TSVs + 6 PNGs",
   "id": "927ccba9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, warnings\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\"figure.dpi\": 150, \"savefig.dpi\": 150, \"figure.figsize\": (12, 7)})\n",
    "\n",
    "# Path setup\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "else:\n",
    "    PROJECT_DIR = os.getcwd()\n",
    "\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
    "FIG_DIR = os.path.join(PROJECT_DIR, \"figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "print(f\"Project dir: {PROJECT_DIR}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "ff604531"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Pangenome Species Distribution\n",
    "\n",
    "Load existing phylogenetic breadth data and query the pangenome for full species distribution of dark gene OGs."
   ],
   "id": "0e75efc4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load phylogenetic breadth (30,756 dark gene clusters → 11,774 root_ogs)\n",
    "phylo = pd.read_csv(os.path.join(DATA_DIR, \"phylogenetic_breadth.tsv\"), sep=\"\t\")\n",
    "print(f\"Phylogenetic breadth: {len(phylo):,} clusters, {phylo['root_og'].nunique():,} unique root_ogs\")\n",
    "print(f\"Columns: {list(phylo.columns)}\")\n",
    "\n",
    "# Load dark genes\n",
    "dark_full = pd.read_csv(os.path.join(DATA_DIR, \"dark_genes_integrated.tsv\"), sep=\"\t\", low_memory=False)\n",
    "dark = dark_full[dark_full[\"is_dark\"] == True].copy()\n",
    "print(f\"Dark genes: {len(dark):,} (from {len(dark_full):,} total)\")\n",
    "print(f\"Dark genes with gene_cluster_id: {dark['gene_cluster_id'].notna().sum():,}\")\n",
    "print(f\"Dark genes with root_og (via phylo): {dark['gene_cluster_id'].isin(phylo['gene_cluster_id']).sum():,}\")\n",
    "\n",
    "# Load concordance\n",
    "concordance = pd.read_csv(os.path.join(DATA_DIR, \"concordance_detailed.tsv\"), sep=\"\t\")\n",
    "print(f\"Concordance OGs: {len(concordance):,} (unique ogId: {concordance['ogId'].nunique()})\")\n",
    "\n",
    "# Load GapMind\n",
    "gapmind = pd.read_csv(os.path.join(DATA_DIR, \"gapmind_domain_matched.tsv\"), sep=\"\t\", low_memory=False)\n",
    "print(f\"GapMind matches: {len(gapmind):,}\")\n",
    "\n",
    "# Load scoring (has s_tractability)\n",
    "scored = pd.read_csv(os.path.join(DATA_DIR, \"scoring_all_dark.tsv\"), sep=\"\t\", low_memory=False)\n",
    "print(f\"Scored dark genes: {len(scored):,}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "1243f987"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pangenome Spark Query\n",
    "\n",
    "Query the full pangenome (27,690 species) for species distribution of dark gene OGs.\n",
    "This gives us proper taxonomic breadth instead of the 48-organism FB approximation."
   ],
   "id": "51ddb5c8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get unique root_ogs from dark genes\n",
    "dark_root_ogs = phylo[phylo[\"gene_cluster_id\"].isin(dark[\"gene_cluster_id\"])][\"root_og\"].unique()\n",
    "print(f\"Unique dark gene root_ogs to query: {len(dark_root_ogs):,}\")\n",
    "\n",
    "# Also get ALL root_ogs from phylo for context\n",
    "all_root_ogs = phylo[\"root_og\"].unique()\n",
    "print(f\"All root_ogs in phylo: {len(all_root_ogs):,}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "384e242c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Build Spark query for pangenome species distribution\n# We batch the root_ogs to avoid query size limits\n\nfrom pyspark.sql import SparkSession\n\ntoken = os.environ.get(\"KBASE_AUTH_TOKEN\", \"\")\nspark_url = f\"sc://jupyter-aparkin.jupyterhub-prod:15002/;use_ssl=false;x-kbase-token={token}\"\n\nspark = (SparkSession.builder\n    .remote(spark_url)\n    .getOrCreate())\nprint(\"Spark session established\")",
   "outputs": [],
   "execution_count": null,
   "id": "8fc38288"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Register dark root_ogs as a temp view for filtering\n",
    "dark_ogs_df = spark.createDataFrame(\n",
    "    [(og,) for og in dark_root_ogs],\n",
    "    [\"root_og\"]\n",
    ")\n",
    "dark_ogs_df.createOrReplaceTempView(\"dark_root_ogs\")\n",
    "print(f\"Registered {len(dark_root_ogs):,} dark root_ogs as temp view\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "a077375f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Main query: species + taxonomy distribution per root_og\n",
    "# Uses eggnog_mapper_annotations joined with gene_cluster and gtdb_species_clade\n",
    "result = spark.sql(\"\"\"\n",
    "WITH annotated AS (\n",
    "    SELECT\n",
    "        split(split(ema.eggNOG_OGs, ',')[0], '@')[0] as root_og,\n",
    "        gc.gtdb_species_clade_id,\n",
    "        split(split(gsc.GTDB_taxonomy, ';')[1], '__')[1] as phylum,\n",
    "        split(split(gsc.GTDB_taxonomy, ';')[2], '__')[1] as class,\n",
    "        split(split(gsc.GTDB_taxonomy, ';')[3], '__')[1] as ord,\n",
    "        split(split(gsc.GTDB_taxonomy, ';')[4], '__')[1] as family,\n",
    "        split(split(gsc.GTDB_taxonomy, ';')[5], '__')[1] as genus\n",
    "    FROM kbase_ke_pangenome.eggnog_mapper_annotations ema\n",
    "    JOIN kbase_ke_pangenome.gene_cluster gc\n",
    "        ON gc.gene_cluster_id = ema.query_name\n",
    "    JOIN kbase_ke_pangenome.gtdb_species_clade gsc\n",
    "        ON gsc.gtdb_species_clade_id = gc.gtdb_species_clade_id\n",
    "    WHERE ema.eggNOG_OGs IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "    root_og,\n",
    "    COUNT(DISTINCT gtdb_species_clade_id) as n_species,\n",
    "    COUNT(DISTINCT phylum) as n_phyla,\n",
    "    COUNT(DISTINCT class) as n_classes,\n",
    "    COUNT(DISTINCT ord) as n_orders,\n",
    "    COUNT(DISTINCT family) as n_families,\n",
    "    COUNT(DISTINCT genus) as n_genera,\n",
    "    COLLECT_SET(phylum) as phyla_set\n",
    "FROM annotated\n",
    "WHERE root_og IN (SELECT root_og FROM dark_root_ogs)\n",
    "GROUP BY root_og\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Pangenome distribution: {len(result):,} root_ogs returned\")\n",
    "print(f\"Species range: {result['n_species'].min()} - {result['n_species'].max()}\")\n",
    "print(f\"Phyla range: {result['n_phyla'].min()} - {result['n_phyla'].max()}\")\n",
    "result.head()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "235ad317"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert phyla_set from array to semicolon-delimited string\n",
    "result[\"phyla_set\"] = result[\"phyla_set\"].apply(lambda x: \";\".join(sorted(x)) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Save pangenome distribution\n",
    "out_path = os.path.join(DATA_DIR, \"og_pangenome_distribution.tsv\")\n",
    "result.to_csv(out_path, sep=\"\t\", index=False)\n",
    "print(f\"Saved {len(result):,} rows to {out_path}\")\n",
    "\n",
    "# Summary stats\n",
    "print(f\"\n",
    "Pangenome distribution summary:\")\n",
    "print(result[[\"n_species\", \"n_phyla\", \"n_classes\", \"n_orders\", \"n_families\", \"n_genera\"]].describe())"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "cb686db7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Taxonomic Tier Classification\n",
    "\n",
    "Classify each dark gene OG into a taxonomic tier based on the narrowest rank containing ALL member species. Also detect mobile/HGT elements."
   ],
   "id": "1dbe1e95"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load pangenome distribution (use freshly computed or reload from disk)\n",
    "pg_dist = result.copy()\n",
    "\n",
    "# Merge with phylogenetic breadth to get COG categories\n",
    "phylo_cog = phylo[[\"root_og\", \"COG_category\"]].drop_duplicates(\"root_og\")\n",
    "pg_dist = pg_dist.merge(phylo_cog, on=\"root_og\", how=\"left\")\n",
    "\n",
    "print(f\"Pangenome distribution with COG: {len(pg_dist):,} root_ogs\")\n",
    "print(f\"COG category X (mobilome): {(pg_dist['COG_category'] == 'X').sum()}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0853bfea"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def classify_taxonomic_tier(row):\n",
    "    \"\"\"Classify OG into taxonomic tier based on species distribution.\n",
    "    \n",
    "    Mobile detection: phylogenetic patchiness (distant phyla, few species per phylum)\n",
    "    or COG category X (mobilome: prophages, transposons).\n",
    "    \"\"\"\n",
    "    n_sp = row[\"n_species\"]\n",
    "    n_ph = row[\"n_phyla\"]\n",
    "    n_cl = row[\"n_classes\"]\n",
    "    n_or = row[\"n_orders\"]\n",
    "    n_fa = row[\"n_families\"]\n",
    "    n_ge = row[\"n_genera\"]\n",
    "    cog = str(row.get(\"COG_category\", \"-\"))\n",
    "    \n",
    "    # Mobile detection: COG-X or patchy distribution (multi-phylum but few species per phylum)\n",
    "    if cog == \"X\":\n",
    "        return \"mobile\"\n",
    "    if n_ph >= 2 and n_sp / n_ph <= 10:\n",
    "        return \"mobile\"\n",
    "    \n",
    "    # Standard tier assignment (broadest first)\n",
    "    if n_ph > 1:\n",
    "        return \"kingdom\"\n",
    "    if n_cl > 1:\n",
    "        return \"phylum\"\n",
    "    if n_or > 1:\n",
    "        return \"class\"\n",
    "    if n_fa > 1:\n",
    "        return \"order\"\n",
    "    if n_ge > 1:\n",
    "        return \"family\"\n",
    "    if n_sp > 1:\n",
    "        return \"genus\"\n",
    "    return \"species\"\n",
    "\n",
    "pg_dist[\"taxonomic_tier\"] = pg_dist.apply(classify_taxonomic_tier, axis=1)\n",
    "\n",
    "print(\"Taxonomic tier distribution (pangenome OGs):\")\n",
    "tier_counts = pg_dist[\"taxonomic_tier\"].value_counts()\n",
    "for tier, n in tier_counts.items():\n",
    "    print(f\"  {tier:12s}: {n:6,} ({100*n/len(pg_dist):5.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "ebb0259d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fallback for dark genes without pangenome root_og:\n",
    "# Use 48-organism OG from essential_genome project + hard-coded taxonomy\n",
    "\n",
    "# Load 48-organism OGs\n",
    "og_path = os.path.join(PROJECT_DIR, \"..\", \"essential_genome\", \"data\", \"all_ortholog_groups.csv\")\n",
    "fb_ogs = pd.read_csv(og_path)\n",
    "print(f\"FB ortholog groups: {len(fb_ogs):,} rows, {fb_ogs['OG_id'].nunique():,} OGs\")\n",
    "\n",
    "# Hard-coded phylum for 48 FB organisms (from GTDB taxonomy)\n",
    "ORG_PHYLUM = {\n",
    "    # Pseudomonadota (Proteobacteria) — 37 organisms\n",
    "    \"Keio\": \"Pseudomonadota\", \"Koxy\": \"Pseudomonadota\", \"MR1\": \"Pseudomonadota\",\n",
    "    \"ANA3\": \"Pseudomonadota\", \"PV4\": \"Pseudomonadota\", \"SB2B\": \"Pseudomonadota\",\n",
    "    \"Marino\": \"Pseudomonadota\", \"DvH\": \"Pseudomonadota\", \"Miya\": \"Pseudomonadota\",\n",
    "    \"Putida\": \"Pseudomonadota\", \"pseudo5_N2C3_1\": \"Pseudomonadota\",\n",
    "    \"pseudo1_N1B4\": \"Pseudomonadota\", \"pseudo3_N2E3\": \"Pseudomonadota\",\n",
    "    \"pseudo6_N2E2\": \"Pseudomonadota\", \"pseudo13_GW456_L13\": \"Pseudomonadota\",\n",
    "    \"psRCH2\": \"Pseudomonadota\", \"SyringaeB728a\": \"Pseudomonadota\",\n",
    "    \"SyringaeB728a_mexBdelta\": \"Pseudomonadota\", \"WCS417\": \"Pseudomonadota\",\n",
    "    \"acidovorax_3H11\": \"Pseudomonadota\", \"BFirm\": \"Pseudomonadota\",\n",
    "    \"Burk376\": \"Pseudomonadota\", \"Cup4G11\": \"Pseudomonadota\",\n",
    "    \"RalstoniaBSBF1503\": \"Pseudomonadota\", \"RalstoniaGMI1000\": \"Pseudomonadota\",\n",
    "    \"RalstoniaPSI07\": \"Pseudomonadota\", \"RalstoniaUW163\": \"Pseudomonadota\",\n",
    "    \"HerbieS\": \"Pseudomonadota\", \"azobra\": \"Pseudomonadota\",\n",
    "    \"Magneto\": \"Pseudomonadota\", \"Dino\": \"Pseudomonadota\",\n",
    "    \"PS\": \"Pseudomonadota\", \"Smeli\": \"Pseudomonadota\",\n",
    "    \"Caulo\": \"Pseudomonadota\", \"Phaeo\": \"Pseudomonadota\",\n",
    "    \"Dda3937\": \"Pseudomonadota\", \"Ddia6719\": \"Pseudomonadota\",\n",
    "    \"DdiaME23\": \"Pseudomonadota\", \"Dyella79\": \"Pseudomonadota\",\n",
    "    # Bacteroidota — 4 organisms\n",
    "    \"Btheta\": \"Bacteroidota\", \"Pedo557\": \"Bacteroidota\",\n",
    "    \"Ponti\": \"Bacteroidota\", \"Cola\": \"Bacteroidota\",\n",
    "    # Cyanobacteriota — 1 organism\n",
    "    \"SynE\": \"Cyanobacteriota\",\n",
    "    # Euryarchaeota — 2 organisms  \n",
    "    \"Methanococcus_JJ\": \"Halobacteriota\", \"Methanococcus_S2\": \"Halobacteriota\",\n",
    "    # Spirochaetota — 0 in FB, others:\n",
    "    \"Korea\": \"Pseudomonadota\",  # Sphingomonas\n",
    "    \"Kang\": \"Pseudomonadota\",   # Kangiella\n",
    "}\n",
    "\n",
    "# Count organisms per OG with phylum info\n",
    "fb_og_orgs = fb_ogs.merge(\n",
    "    pd.DataFrame(list(ORG_PHYLUM.items()), columns=[\"orgId\", \"phylum\"]),\n",
    "    on=\"orgId\", how=\"left\"\n",
    ")\n",
    "fb_og_summary = fb_og_orgs.groupby(\"OG_id\").agg(\n",
    "    n_fb_orgs=(\"orgId\", \"nunique\"),\n",
    "    n_fb_phyla=(\"phylum\", \"nunique\"),\n",
    ").reset_index()\n",
    "print(f\"FB OG summary: {len(fb_og_summary):,} OGs\")\n",
    "print(f\"Multi-phylum FB OGs: {(fb_og_summary['n_fb_phyla'] > 1).sum()}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "b26b0aba"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build gene-level taxonomic tier assignment\n",
    "# Map dark genes → root_og → pangenome tier\n",
    "# For genes without root_og, use FB OG fallback\n",
    "\n",
    "# Step 1: root_og mapping via gene_cluster_id\n",
    "gc_to_og = phylo[[\"gene_cluster_id\", \"root_og\"]].drop_duplicates(\"gene_cluster_id\")\n",
    "dark_with_og = dark.merge(gc_to_og, on=\"gene_cluster_id\", how=\"left\")\n",
    "print(f\"Dark genes with root_og: {dark_with_og['root_og'].notna().sum():,} / {len(dark):,}\")\n",
    "\n",
    "# Step 2: merge pangenome tier\n",
    "og_tier = pg_dist[[\"root_og\", \"taxonomic_tier\", \"n_species\", \"n_phyla\", \"n_classes\",\n",
    "                     \"n_orders\", \"n_families\", \"n_genera\"]].copy()\n",
    "dark_with_tier = dark_with_og.merge(og_tier, on=\"root_og\", how=\"left\")\n",
    "print(f\"Dark genes with pangenome tier: {dark_with_tier['taxonomic_tier'].notna().sum():,}\")\n",
    "\n",
    "# Step 3: Fallback for genes without pangenome tier — use FB OG\n",
    "no_tier = dark_with_tier[\"taxonomic_tier\"].isna()\n",
    "print(f\"Dark genes needing FB fallback: {no_tier.sum():,}\")\n",
    "\n",
    "# Map FB OG_id → tier (simplified: phylum info from 48 orgs)\n",
    "def fb_tier(row, fb_og_summary):\n",
    "    og_id = row.get(\"OG_id\")\n",
    "    if pd.isna(og_id) or og_id == \"\":\n",
    "        return \"species\", 1, 1  # singleton\n",
    "    match = fb_og_summary[fb_og_summary[\"OG_id\"] == og_id]\n",
    "    if len(match) == 0:\n",
    "        return \"species\", 1, 1\n",
    "    n_orgs = match.iloc[0][\"n_fb_orgs\"]\n",
    "    n_phyla = match.iloc[0][\"n_fb_phyla\"]\n",
    "    if n_phyla > 1:\n",
    "        return \"kingdom\", n_orgs, n_phyla\n",
    "    elif n_orgs > 1:\n",
    "        return \"genus\", n_orgs, 1  # within one phylum but can't resolve further from 48 orgs\n",
    "    else:\n",
    "        return \"species\", 1, 1\n",
    "\n",
    "# Apply fallback\n",
    "fb_results = dark_with_tier[no_tier].apply(lambda r: fb_tier(r, fb_og_summary), axis=1, result_type=\"expand\")\n",
    "fb_results.columns = [\"taxonomic_tier_fb\", \"n_species_fb\", \"n_phyla_fb\"]\n",
    "\n",
    "dark_with_tier.loc[no_tier, \"taxonomic_tier\"] = fb_results[\"taxonomic_tier_fb\"].values\n",
    "dark_with_tier.loc[no_tier, \"n_species\"] = fb_results[\"n_species_fb\"].values\n",
    "dark_with_tier.loc[no_tier, \"n_phyla\"] = fb_results[\"n_phyla_fb\"].values\n",
    "\n",
    "# Mark FB-only tiers as lower confidence\n",
    "dark_with_tier[\"tier_source\"] = \"pangenome\"\n",
    "dark_with_tier.loc[no_tier, \"tier_source\"] = \"FB-only\"\n",
    "\n",
    "print(f\"\n",
    "Final tier distribution (all {len(dark_with_tier):,} dark genes):\")\n",
    "tier_dist = dark_with_tier[\"taxonomic_tier\"].value_counts()\n",
    "for tier, n in tier_dist.items():\n",
    "    print(f\"  {tier:12s}: {n:6,} ({100*n/len(dark_with_tier):5.1f}%)\")\n",
    "print(f\"\n",
    "Tier source: {dark_with_tier['tier_source'].value_counts().to_dict()}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "35b585a1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Hypothesis Status Classification\n",
    "\n",
    "Classify each dark gene into three tiers based on functional evidence:\n",
    "- **Strong testable hypothesis**: module prediction with EC/enzyme, high concordance, high-confidence GapMind, named domain + strong fitness\n",
    "- **Weak lead**: DUF-only domain, bare module prediction, medium/low GapMind, strong fitness alone, named domain alone\n",
    "- **True knowledge gap**: zero functional evidence of any kind"
   ],
   "id": "99a85bf8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Prepare evidence indicators for hypothesis classification\n\n# 1. Module prediction with EC/enzyme function\ndark_with_tier[\"has_ec_prediction\"] = dark_with_tier[\"module_prediction\"].apply(\n    lambda x: bool(re.search(r\"EC\\s*[\\d\\.]+|ase\\b|synthase|transferase|kinase|reductase|oxidase|hydrolase|lyase|ligase|isomerase\", \n                              str(x), re.IGNORECASE)) if pd.notna(x) else False\n)\n\n# 2. High concordance (>0.7)\nhigh_conc_ogs = set(concordance[concordance[\"concordance_frac\"] > 0.7][\"ogId\"].astype(str).values)\ndark_with_tier[\"has_high_concordance\"] = dark_with_tier[\"OG_id\"].astype(str).isin(high_conc_ogs)\n\n# 3. GapMind matches by confidence\ngapmind_gene = gapmind.groupby([\"orgId\", \"locusId\"]).agg(\n    best_confidence=(\"confidence_tier\", \"first\"),  # already sorted by confidence\n    n_gapmind_matches=(\"confidence_tier\", \"size\"),\n).reset_index()\n# Mark high-confidence GapMind\ngapmind_high = set(\n    gapmind[gapmind[\"confidence_tier\"] == \"High\"]\n    .apply(lambda r: f\"{r['orgId']}_{r['locusId']}\", axis=1)\n)\ngapmind_any = set(\n    gapmind.apply(lambda r: f\"{r['orgId']}_{r['locusId']}\", axis=1)\n)\ndark_with_tier[\"gene_key\"] = dark_with_tier[\"orgId\"] + \"_\" + dark_with_tier[\"locusId\"].astype(str)\ndark_with_tier[\"has_gapmind_high\"] = dark_with_tier[\"gene_key\"].isin(gapmind_high)\ndark_with_tier[\"has_gapmind_any\"] = dark_with_tier[\"gene_key\"].isin(gapmind_any)\n\n# 4. Domain analysis: named vs DUF-only\ndef is_duf_only(domain_names):\n    if pd.isna(domain_names) or str(domain_names).strip() in (\"\", \"nan\"):\n        return False  # no domains = not DUF-only\n    names = str(domain_names).split(\";\")\n    return all(re.match(r\"^(DUF|UPF)\\d+$\", n.strip()) for n in names if n.strip())\n\ndef has_named_domain(domain_names):\n    if pd.isna(domain_names) or str(domain_names).strip() in (\"\", \"nan\"):\n        return False\n    names = str(domain_names).split(\";\")\n    return any(not re.match(r\"^(DUF|UPF)\\d+$\", n.strip()) for n in names if n.strip())\n\ndark_with_tier[\"is_duf_only\"] = dark_with_tier[\"domain_names\"].apply(is_duf_only)\ndark_with_tier[\"has_named_domain\"] = dark_with_tier[\"domain_names\"].apply(has_named_domain)\n\n# 5. Strong fitness\ndark_with_tier[\"has_strong_fitness\"] = dark_with_tier[\"max_abs_fit\"].fillna(0) >= 2\n\n# Summary\nprint(\"Evidence indicators:\")\nfor col in [\"has_ec_prediction\", \"has_high_concordance\", \"has_gapmind_high\", \"has_gapmind_any\",\n            \"is_duf_only\", \"has_named_domain\", \"has_strong_fitness\"]:\n    print(f\"  {col}: {dark_with_tier[col].sum():,}\")",
   "outputs": [],
   "execution_count": null,
   "id": "291d750b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def classify_hypothesis_status(row):\n",
    "    \"\"\"Three-tier hypothesis classification.\n",
    "    \n",
    "    Strong testable hypothesis: clear experimental path to function\n",
    "    Weak lead: some evidence but not actionable without more work\n",
    "    True knowledge gap: zero functional evidence\n",
    "    \"\"\"\n",
    "    # Strong testable hypothesis (any of):\n",
    "    if row[\"has_ec_prediction\"]:\n",
    "        return \"strong_hypothesis\"\n",
    "    if row[\"has_high_concordance\"]:\n",
    "        return \"strong_hypothesis\"\n",
    "    if row[\"has_gapmind_high\"]:\n",
    "        return \"strong_hypothesis\"\n",
    "    if row[\"has_named_domain\"] and row[\"has_strong_fitness\"]:\n",
    "        return \"strong_hypothesis\"\n",
    "    \n",
    "    # Weak lead (any of):\n",
    "    if row[\"is_duf_only\"]:\n",
    "        return \"weak_lead\"\n",
    "    if pd.notna(row[\"module_prediction\"]) and str(row[\"module_prediction\"]).strip() not in (\"\", \"nan\"):\n",
    "        return \"weak_lead\"  # bare module prediction (PFam/TIGR/KEGG ID)\n",
    "    if row[\"has_gapmind_any\"]:\n",
    "        return \"weak_lead\"\n",
    "    if row[\"has_strong_fitness\"]:\n",
    "        return \"weak_lead\"  # fitness without annotation\n",
    "    if row[\"has_named_domain\"]:\n",
    "        return \"weak_lead\"  # domain without fitness\n",
    "    \n",
    "    # True knowledge gap\n",
    "    return \"true_knowledge_gap\"\n",
    "\n",
    "dark_with_tier[\"hypothesis_status\"] = dark_with_tier.apply(classify_hypothesis_status, axis=1)\n",
    "\n",
    "print(\"Hypothesis status distribution:\")\n",
    "hyp_counts = dark_with_tier[\"hypothesis_status\"].value_counts()\n",
    "for status, n in hyp_counts.items():\n",
    "    print(f\"  {status:25s}: {n:6,} ({100*n/len(dark_with_tier):5.1f}%)\")\n",
    "\n",
    "# Cross-tabulation: tier × hypothesis\n",
    "ct = pd.crosstab(dark_with_tier[\"taxonomic_tier\"], dark_with_tier[\"hypothesis_status\"])\n",
    "print(f\"\n",
    "Tier × Hypothesis cross-tabulation:\")\n",
    "print(ct)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "a1b12eb1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Importance Score\n\n**Principle**: The more conserved a gene and the less we know about it, the more important it is to study experimentally.\n\n`importance = conservation_score × ignorance_score`\n\nConservation is tier-adjusted + log-scaled species count. Ignorance reflects hypothesis status.",
   "id": "910e806e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Conservation score: tier-adjusted + log-scaled species count\n",
    "TIER_SCORE = {\n",
    "    \"kingdom\": 7, \"phylum\": 6, \"class\": 5, \"order\": 4,\n",
    "    \"family\": 3, \"genus\": 2, \"species\": 1, \"mobile\": 4  # mobile = interesting\n",
    "}\n",
    "\n",
    "# Ignorance score\n",
    "IGNORANCE_SCORE = {\n",
    "    \"true_knowledge_gap\": 3,\n",
    "    \"weak_lead\": 2,\n",
    "    \"strong_hypothesis\": 1\n",
    "}\n",
    "\n",
    "MAX_SPECIES = 27690  # pangenome total\n",
    "\n",
    "def compute_importance(row):\n",
    "    tier = row[\"taxonomic_tier\"]\n",
    "    n_sp = max(row.get(\"n_species\", 1) or 1, 1)\n",
    "    hypothesis = row[\"hypothesis_status\"]\n",
    "    \n",
    "    tier_score = TIER_SCORE.get(tier, 1)\n",
    "    # Within-tier modulation by log2(n_species) normalized to 0-1\n",
    "    species_bonus = np.log2(n_sp) / np.log2(MAX_SPECIES) if n_sp > 1 else 0\n",
    "    conservation = tier_score + species_bonus\n",
    "    \n",
    "    ignorance = IGNORANCE_SCORE.get(hypothesis, 1)\n",
    "    \n",
    "    return conservation * ignorance\n",
    "\n",
    "dark_with_tier[\"conservation_score\"] = dark_with_tier.apply(\n",
    "    lambda r: TIER_SCORE.get(r[\"taxonomic_tier\"], 1) + \n",
    "              (np.log2(max(r.get(\"n_species\", 1) or 1, 1)) / np.log2(MAX_SPECIES) if max(r.get(\"n_species\", 1) or 1, 1) > 1 else 0),\n",
    "    axis=1\n",
    ")\n",
    "dark_with_tier[\"ignorance_score\"] = dark_with_tier[\"hypothesis_status\"].map(IGNORANCE_SCORE)\n",
    "dark_with_tier[\"importance_score\"] = dark_with_tier[\"conservation_score\"] * dark_with_tier[\"ignorance_score\"]\n",
    "\n",
    "print(\"Importance score distribution:\")\n",
    "print(dark_with_tier[\"importance_score\"].describe())\n",
    "print(f\"\n",
    "Top 10 importance scores:\")\n",
    "print(dark_with_tier.nlargest(10, \"importance_score\")[[\"orgId\", \"locusId\", \"taxonomic_tier\", \n",
    "    \"hypothesis_status\", \"conservation_score\", \"ignorance_score\", \"importance_score\", \"desc\"]])"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e7ef7f37"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute OG-level importance ranking\n",
    "# For each root_og, take the max importance score and aggregate evidence\n",
    "og_importance = dark_with_tier[dark_with_tier[\"root_og\"].notna()].groupby(\"root_og\").agg(\n",
    "    n_genes=(\"locusId\", \"nunique\"),\n",
    "    n_organisms=(\"orgId\", \"nunique\"),\n",
    "    mean_importance=(\"importance_score\", \"mean\"),\n",
    "    max_importance=(\"importance_score\", \"max\"),\n",
    "    taxonomic_tier=(\"taxonomic_tier\", \"first\"),\n",
    "    hypothesis_status=(\"hypothesis_status\", lambda x: x.value_counts().index[0]),  # mode\n",
    "    n_species=(\"n_species\", \"first\"),\n",
    "    n_phyla=(\"n_phyla\", \"first\"),\n",
    "    mean_fitness=(\"max_abs_fit\", lambda x: x.fillna(0).mean()),\n",
    "    any_strong_fitness=(\"has_strong_fitness\", \"any\"),\n",
    "    any_named_domain=(\"has_named_domain\", \"any\"),\n",
    "    any_gapmind=(\"has_gapmind_any\", \"any\"),\n",
    ").reset_index()\n",
    "og_importance = og_importance.sort_values(\"max_importance\", ascending=False)\n",
    "\n",
    "print(f\"OG importance ranking: {len(og_importance):,} root_ogs\")\n",
    "print(f\"\n",
    "Top 20 most important OGs (conservation × ignorance):\")\n",
    "print(og_importance.head(20)[[\"root_og\", \"n_genes\", \"n_organisms\", \"taxonomic_tier\",\n",
    "    \"hypothesis_status\", \"n_species\", \"n_phyla\", \"max_importance\"]].to_string(index=False))\n",
    "\n",
    "# Save OG importance ranking\n",
    "og_importance.to_csv(os.path.join(DATA_DIR, \"og_importance_ranked.tsv\"), sep=\"\t\", index=False)\n",
    "print(f\"\n",
    "Saved to data/og_importance_ranked.tsv\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "9e6e69a1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build evidence summary string\n",
    "def evidence_summary(row):\n",
    "    parts = []\n",
    "    if row[\"has_ec_prediction\"]:\n",
    "        parts.append(\"EC-prediction\")\n",
    "    if row[\"has_high_concordance\"]:\n",
    "        parts.append(\"high-concordance\")\n",
    "    if row[\"has_gapmind_high\"]:\n",
    "        parts.append(\"GapMind-high\")\n",
    "    elif row[\"has_gapmind_any\"]:\n",
    "        parts.append(\"GapMind-low\")\n",
    "    if row[\"has_named_domain\"]:\n",
    "        parts.append(\"named-domain\")\n",
    "    elif row[\"is_duf_only\"]:\n",
    "        parts.append(\"DUF-only\")\n",
    "    if row[\"has_strong_fitness\"]:\n",
    "        parts.append(\"strong-fitness\")\n",
    "    if pd.notna(row[\"module_prediction\"]) and str(row[\"module_prediction\"]).strip() not in (\"\", \"nan\"):\n",
    "        if not row[\"has_ec_prediction\"]:\n",
    "            parts.append(\"module-bare\")\n",
    "    return \"; \".join(parts) if parts else \"none\"\n",
    "\n",
    "dark_with_tier[\"evidence_summary\"] = dark_with_tier.apply(evidence_summary, axis=1)\n",
    "\n",
    "# Save per-gene classification\n",
    "gene_classes = dark_with_tier[[\"orgId\", \"locusId\", \"gene_cluster_id\", \"root_og\", \"OG_id\",\n",
    "    \"taxonomic_tier\", \"tier_source\", \"hypothesis_status\",\n",
    "    \"conservation_score\", \"ignorance_score\", \"importance_score\",\n",
    "    \"n_species\", \"n_phyla\", \"evidence_summary\"]].copy()\n",
    "gene_classes.to_csv(os.path.join(DATA_DIR, \"dark_gene_classes.tsv\"), sep=\"\t\", index=False)\n",
    "print(f\"Saved {len(gene_classes):,} rows to data/dark_gene_classes.tsv\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "482f9078"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Minimum Covering Set (Conservation-Weighted)\n",
    "\n",
    "Find the ordered subset of 48 FB organisms that covers the most high-priority OGs, weighted by experimental tractability. Unlike NB09 (which covered ALL dark genes), this covering set focuses on high-importance OGs where experimental characterization would produce the most novel insight."
   ],
   "id": "4379bd5a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup: tractability scores and genus mapping\n",
    "\n",
    "CRISPRI_TRACTABILITY = {\n",
    "    \"Keio\": 0.9, \"BW25113\": 0.9, \"Deshi\": 0.85,\n",
    "    \"MR1\": 0.8, \"SB2B\": 0.7,\n",
    "    \"Putida\": 0.8, \"pseudo5_N2C3_1\": 0.75,\n",
    "    \"pseudo1_N1B4\": 0.7, \"pseudo3_N2E2\": 0.7,\n",
    "    \"pseudo13_GW456_L13\": 0.65,\n",
    "    \"Pse\": 0.7, \"Pseu\": 0.7,\n",
    "    \"BT\": 0.75, \"Bacteroides_theta\": 0.75,\n",
    "    \"Smeli\": 0.6, \"Koxy\": 0.65,\n",
    "    \"Marino\": 0.5, \"DvH\": 0.5,\n",
    "    \"Geobacter\": 0.45, \"Caulobacter\": 0.6,\n",
    "    \"Synpcc7942\": 0.55, \"Synpcc6803\": 0.55,\n",
    "    \"psRCH2\": 0.55, \"Rleg\": 0.5,\n",
    "}\n",
    "DEFAULT_CRISPRI = 0.3\n",
    "\n",
    "# Genus mapping\n",
    "org_map_path = os.path.join(PROJECT_DIR, \"..\", \"conservation_vs_fitness\", \"data\", \"organism_mapping.tsv\")\n",
    "org_map = pd.read_csv(org_map_path, sep=\"\t\")\n",
    "ORG_GENUS = dict(zip(org_map[\"orgId\"], org_map[\"genus\"]))\n",
    "# Manual fallbacks for organisms not in mapping\n",
    "ORG_GENUS.setdefault(\"SB2B\", \"Shewanella\")\n",
    "ORG_GENUS.setdefault(\"Magneto\", \"Magnetospirillum\")\n",
    "ORG_GENUS.setdefault(\"Cola\", \"Echinicola\")\n",
    "ORG_GENUS.setdefault(\"Kang\", \"Kangiella\")\n",
    "\n",
    "print(f\"Tractability scores for {len(CRISPRI_TRACTABILITY)} organisms\")\n",
    "print(f\"Genus mapping for {len(ORG_GENUS)} organisms\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "ca32b561"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define universe: high-importance OGs (top quartile OR kingdom/phylum-level gaps/leads)\n",
    "importance_threshold = dark_with_tier[\"importance_score\"].quantile(0.75)\n",
    "print(f\"Importance threshold (75th percentile): {importance_threshold:.2f}\")\n",
    "\n",
    "# Universe: genes above threshold\n",
    "universe = dark_with_tier[\n",
    "    (dark_with_tier[\"importance_score\"] >= importance_threshold) |\n",
    "    ((dark_with_tier[\"taxonomic_tier\"].isin([\"kingdom\", \"phylum\"])) & \n",
    "     (dark_with_tier[\"hypothesis_status\"].isin([\"true_knowledge_gap\", \"weak_lead\"])))\n",
    "].copy()\n",
    "print(f\"Universe: {len(universe):,} dark genes (from {dark_with_tier['orgId'].nunique()} organisms)\")\n",
    "print(f\"Universe organisms: {universe['orgId'].nunique()}\")\n",
    "\n",
    "# Ensure gene_key is set\n",
    "universe[\"gene_key\"] = universe[\"orgId\"] + \"_\" + universe[\"locusId\"].astype(str)\n",
    "\n",
    "# Build org → gene_key sets\n",
    "org_sets = {}\n",
    "for org, grp in universe.groupby(\"orgId\"):\n",
    "    org_sets[org] = set(grp[\"gene_key\"].values)\n",
    "\n",
    "print(f\"Organisms with universe genes: {len(org_sets)}\")\n",
    "for org in sorted(org_sets, key=lambda o: -len(org_sets[o]))[:10]:\n",
    "    print(f\"  {org}: {len(org_sets[org]):,} genes\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "93017208"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Greedy weighted set-cover\n",
    "gene_priority = dict(zip(universe[\"gene_key\"], universe[\"importance_score\"]))\n",
    "total_priority = sum(gene_priority.values())\n",
    "target_coverage = 0.95 * total_priority\n",
    "\n",
    "uncovered = set(universe[\"gene_key\"].values)\n",
    "covered_priority = 0.0\n",
    "selected_genera = set()\n",
    "covering_sequence = []\n",
    "\n",
    "step = 0\n",
    "while covered_priority < target_coverage and uncovered:\n",
    "    best_org = None\n",
    "    best_value = -1\n",
    "    best_uncovered_genes = []\n",
    "    best_sum_priority = 0\n",
    "\n",
    "    for org, gene_set in org_sets.items():\n",
    "        org_uncovered = [g for g in gene_set if g in uncovered]\n",
    "        if not org_uncovered:\n",
    "            continue\n",
    "        \n",
    "        sum_priority = sum(gene_priority[g] for g in org_uncovered)\n",
    "        tractability = CRISPRI_TRACTABILITY.get(org, DEFAULT_CRISPRI)\n",
    "        genus = ORG_GENUS.get(org, org)\n",
    "        phylo_bonus = 0.5 if genus in selected_genera else 1.0\n",
    "        \n",
    "        value = sum_priority * tractability * phylo_bonus\n",
    "        \n",
    "        if value > best_value:\n",
    "            best_value = value\n",
    "            best_org = org\n",
    "            best_uncovered_genes = org_uncovered\n",
    "            best_sum_priority = sum_priority\n",
    "\n",
    "    if best_org is None:\n",
    "        break\n",
    "\n",
    "    step += 1\n",
    "    genus = ORG_GENUS.get(best_org, best_org)\n",
    "    tractability = CRISPRI_TRACTABILITY.get(best_org, DEFAULT_CRISPRI)\n",
    "    phylo_bonus = 0.5 if genus in selected_genera else 1.0\n",
    "\n",
    "    for g in best_uncovered_genes:\n",
    "        uncovered.discard(g)\n",
    "    covered_priority += best_sum_priority\n",
    "    selected_genera.add(genus)\n",
    "\n",
    "    covering_sequence.append({\n",
    "        \"step\": step,\n",
    "        \"orgId\": best_org,\n",
    "        \"genus\": genus,\n",
    "        \"tractability\": tractability,\n",
    "        \"n_new_genes\": len(best_uncovered_genes),\n",
    "        \"sum_importance\": best_sum_priority,\n",
    "        \"objective_value\": best_value,\n",
    "        \"cumulative_genes\": len(universe) - len(uncovered),\n",
    "        \"cumulative_importance\": covered_priority,\n",
    "        \"pct_covered\": 100 * covered_priority / total_priority,\n",
    "    })\n",
    "\n",
    "covering_df = pd.DataFrame(covering_sequence)\n",
    "print(f\"Set-cover completed in {step} steps\")\n",
    "print(f\"Coverage: {covered_priority:.1f} / {total_priority:.1f} ({100*covered_priority/total_priority:.1f}%)\")\n",
    "print(f\"Unique genera: {len(selected_genera)}\")\n",
    "print(f\"\n",
    "Covering sequence:\")\n",
    "print(covering_df[[\"step\", \"orgId\", \"genus\", \"tractability\", \"n_new_genes\", \n",
    "    \"pct_covered\"]].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "1e467d88"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Assign genes to organisms in covering set order\n",
    "gene_assignment = {}\n",
    "for _, step_row in covering_df.iterrows():\n",
    "    org = step_row[\"orgId\"]\n",
    "    for g in org_sets[org]:\n",
    "        if g not in gene_assignment:\n",
    "            gene_assignment[g] = org\n",
    "\n",
    "# Add assignment to universe\n",
    "universe[\"assigned_organism\"] = universe[\"gene_key\"].map(gene_assignment)\n",
    "assigned = universe[universe[\"assigned_organism\"].notna()].copy()\n",
    "print(f\"Genes assigned: {len(assigned):,} / {len(universe):,}\")\n",
    "\n",
    "# Per-organism breakdown by tier × hypothesis\n",
    "for _, step_row in covering_df.head(10).iterrows():\n",
    "    org = step_row[\"orgId\"]\n",
    "    org_genes = assigned[assigned[\"assigned_organism\"] == org]\n",
    "    ct = pd.crosstab(org_genes[\"taxonomic_tier\"], org_genes[\"hypothesis_status\"])\n",
    "    print(f\"\n",
    "{org} ({step_row['genus']}, step {int(step_row['step'])}): {len(org_genes)} genes\")\n",
    "    print(ct.to_string())\n",
    "\n",
    "# Save covering set\n",
    "covering_df.to_csv(os.path.join(DATA_DIR, \"conservation_covering_set.tsv\"), sep=\"\t\", index=False)\n",
    "print(f\"\n",
    "Saved covering set to data/conservation_covering_set.tsv\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e0c390e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Per-Organism Experimental Plans\n",
    "\n",
    "For each selected organism (in covering-set order), generate an experimental action plan with OG breakdown by tier × hypothesis, recommended experiments, and expected novel functions."
   ],
   "id": "6475d7c3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Condition recommendation from NB09\n",
    "KEYWORD_TO_CONDITION = {\n",
    "    \"transport\": \"carbon/nitrogen source panel\",\n",
    "    \"permease\": \"carbon/nitrogen source panel\",\n",
    "    \"iron\": \"iron limitation/excess\",\n",
    "    \"sulfur\": \"sulfur source panel\",\n",
    "    \"nitrogen\": \"nitrogen source panel\",\n",
    "    \"flagell\": \"motility/soft agar\",\n",
    "    \"chemotaxis\": \"motility/soft agar\",\n",
    "    \"membrane\": \"membrane stress (SDS, EDTA)\",\n",
    "    \"oxidase\": \"oxidative stress (H2O2, paraquat)\",\n",
    "    \"reductase\": \"electron acceptor panel\",\n",
    "    \"kinase\": \"signaling conditions (osmotic, pH)\",\n",
    "    \"regulator\": \"regulatory screen (stress panel)\",\n",
    "    \"ribosom\": \"translation stress (antibiotics)\",\n",
    "    \"protease\": \"protein stress (heat, ethanol)\",\n",
    "    \"secretion\": \"secretion assays\",\n",
    "    \"atp\": \"energy metabolism panel\",\n",
    "    \"nad\": \"redox conditions panel\",\n",
    "    \"phospho\": \"phosphate limitation\",\n",
    "    \"dehydrogenase\": \"electron donor panel\",\n",
    "    \"synthase\": \"biosynthesis conditions\",\n",
    "}\n",
    "\n",
    "def recommend_experiment(row):\n",
    "    \"\"\"Recommend experiment type based on available evidence.\"\"\"\n",
    "    org = row[\"orgId\"]\n",
    "    has_crispri = org in CRISPRI_TRACTABILITY\n",
    "    is_essential = str(row.get(\"essentiality_class\", \"\")) == \"essential_all\"\n",
    "    has_fitness = row.get(\"has_strong_fitness\", False)\n",
    "    hypothesis = row[\"hypothesis_status\"]\n",
    "    \n",
    "    if is_essential and has_crispri:\n",
    "        return \"CRISPRi knockdown\"\n",
    "    elif has_fitness:\n",
    "        return \"condition-specific TnSeq\"\n",
    "    elif hypothesis == \"true_knowledge_gap\":\n",
    "        return \"broad phenotypic screen\"\n",
    "    else:\n",
    "        return \"targeted TnSeq\"\n",
    "\n",
    "assigned[\"recommended_experiment\"] = assigned.apply(recommend_experiment, axis=1)\n",
    "\n",
    "# Recommended condition (from fitness data or keyword inference)\n",
    "def recommend_condition(row):\n",
    "    top_cond = str(row.get(\"top_condition_class\", \"\"))\n",
    "    if top_cond and top_cond not in (\"\", \"nan\", \"None\"):\n",
    "        return top_cond\n",
    "    desc = str(row.get(\"desc\", \"\")).lower()\n",
    "    for kw, cond in KEYWORD_TO_CONDITION.items():\n",
    "        if kw in desc:\n",
    "            return cond\n",
    "    pred = str(row.get(\"module_prediction\", \"\"))\n",
    "    if pred and pred not in (\"\", \"nan\"):\n",
    "        return f\"module: {pred[:40]}\"\n",
    "    return \"broad screen\"\n",
    "\n",
    "assigned[\"recommended_condition\"] = assigned.apply(recommend_condition, axis=1)\n",
    "print(f\"Experiment types: {assigned['recommended_experiment'].value_counts().to_dict()}\")\n",
    "print(f\"Top conditions: {assigned['recommended_condition'].value_counts().head(10).to_dict()}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "568886b3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build per-organism experiment plan\n",
    "experiment_plans = []\n",
    "\n",
    "for _, step_row in covering_df.iterrows():\n",
    "    org = step_row[\"orgId\"]\n",
    "    org_genes = assigned[assigned[\"assigned_organism\"] == org]\n",
    "    if len(org_genes) == 0:\n",
    "        continue\n",
    "    \n",
    "    n_total = len(org_genes)\n",
    "    tractability = CRISPRI_TRACTABILITY.get(org, DEFAULT_CRISPRI)\n",
    "    \n",
    "    # Tier × hypothesis counts\n",
    "    tier_hyp = pd.crosstab(org_genes[\"taxonomic_tier\"], org_genes[\"hypothesis_status\"])\n",
    "    \n",
    "    # Key counts\n",
    "    n_kingdom_gaps = tier_hyp.loc[\"kingdom\", \"true_knowledge_gap\"] if \"kingdom\" in tier_hyp.index and \"true_knowledge_gap\" in tier_hyp.columns else 0\n",
    "    n_phylum_gaps = tier_hyp.loc[\"phylum\", \"true_knowledge_gap\"] if \"phylum\" in tier_hyp.index and \"true_knowledge_gap\" in tier_hyp.columns else 0\n",
    "    n_kingdom_leads = tier_hyp.loc[\"kingdom\", \"weak_lead\"] if \"kingdom\" in tier_hyp.index and \"weak_lead\" in tier_hyp.columns else 0\n",
    "    n_phylum_leads = tier_hyp.loc[\"phylum\", \"weak_lead\"] if \"phylum\" in tier_hyp.index and \"weak_lead\" in tier_hyp.columns else 0\n",
    "    \n",
    "    # Expected novel functions: true_knowledge_gap + weak_lead counts\n",
    "    n_novel = org_genes[org_genes[\"hypothesis_status\"].isin([\"true_knowledge_gap\", \"weak_lead\"])].shape[0]\n",
    "    \n",
    "    # Experiment summary\n",
    "    exp_types = org_genes[\"recommended_experiment\"].value_counts()\n",
    "    exp_str = \" + \".join(exp_types.index[:3])\n",
    "    \n",
    "    # Top conditions\n",
    "    top_conds = org_genes[\"recommended_condition\"].value_counts().head(3)\n",
    "    cond_str = \"; \".join(f\"{c}({n})\" for c, n in top_conds.items())\n",
    "    \n",
    "    experiment_plans.append({\n",
    "        \"priority\": int(step_row[\"step\"]),\n",
    "        \"orgId\": org,\n",
    "        \"genus\": step_row[\"genus\"],\n",
    "        \"tractability\": tractability,\n",
    "        \"n_OGs_covered\": n_total,\n",
    "        \"n_kingdom_gaps\": int(n_kingdom_gaps),\n",
    "        \"n_phylum_gaps\": int(n_phylum_gaps),\n",
    "        \"n_kingdom_leads\": int(n_kingdom_leads),\n",
    "        \"n_phylum_leads\": int(n_phylum_leads),\n",
    "        \"expected_novel\": n_novel,\n",
    "        \"experiment_type\": exp_str,\n",
    "        \"top_conditions\": cond_str,\n",
    "        \"pct_covered\": step_row[\"pct_covered\"],\n",
    "    })\n",
    "\n",
    "plan_df = pd.DataFrame(experiment_plans)\n",
    "plan_df.to_csv(os.path.join(DATA_DIR, \"conservation_experiment_plans.tsv\"), sep=\"\t\", index=False)\n",
    "print(f\"Saved {len(plan_df)} organism plans to data/conservation_experiment_plans.tsv\")\n",
    "print(f\"\n",
    "Experimental priority table:\")\n",
    "print(plan_df[[\"priority\", \"orgId\", \"tractability\", \"n_OGs_covered\", \n",
    "    \"n_kingdom_gaps\", \"n_phylum_gaps\", \"expected_novel\", \"experiment_type\"]].head(15).to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "4066a49c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Figures\n",
    "\n",
    "Six figures visualizing conservation × dark matter classification and experimental prioritization."
   ],
   "id": "525c0807"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig32: FB organism taxonomy context — showing sparse sampling\n",
    "# Phylum-colored bar chart of 48 organisms\n",
    "\n",
    "org_phyla = pd.DataFrame(list(ORG_PHYLUM.items()), columns=[\"orgId\", \"phylum\"])\n",
    "phylum_counts = org_phyla[\"phylum\"].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = {\"Pseudomonadota\": \"#1f77b4\", \"Bacteroidota\": \"#ff7f0e\", \n",
    "          \"Cyanobacteriota\": \"#2ca02c\", \"Halobacteriota\": \"#d62728\"}\n",
    "bars = ax.bar(phylum_counts.index, phylum_counts.values,\n",
    "              color=[colors.get(p, \"#999999\") for p in phylum_counts.index])\n",
    "ax.set_ylabel(\"Number of FB organisms\")\n",
    "ax.set_title(\"Fitness Browser Organism Sampling — Sparse Taxonomic Coverage\n",
    "(48 organisms dominated by Pseudomonadota)\")\n",
    "ax.set_xlabel(\"Phylum\")\n",
    "for bar, val in zip(bars, phylum_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "            str(val), ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig32_organism_taxonomy.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig32_organism_taxonomy.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "fdf29440"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig33: Conservation tier distribution (stacked bars × hypothesis status)\n",
    "tier_order = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\", \"mobile\"]\n",
    "hyp_order = [\"strong_hypothesis\", \"weak_lead\", \"true_knowledge_gap\"]\n",
    "hyp_colors = {\"strong_hypothesis\": \"#2ca02c\", \"weak_lead\": \"#ff7f0e\", \"true_knowledge_gap\": \"#d62728\"}\n",
    "\n",
    "ct = pd.crosstab(dark_with_tier[\"taxonomic_tier\"], dark_with_tier[\"hypothesis_status\"])\n",
    "ct = ct.reindex(index=[t for t in tier_order if t in ct.index], \n",
    "                columns=[h for h in hyp_order if h in ct.columns], fill_value=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Absolute counts\n",
    "ct.plot(kind=\"bar\", stacked=True, ax=axes[0], \n",
    "        color=[hyp_colors[h] for h in ct.columns])\n",
    "axes[0].set_title(\"Dark Gene Count by Conservation Tier × Hypothesis Status\")\n",
    "axes[0].set_ylabel(\"Number of dark genes\")\n",
    "axes[0].set_xlabel(\"Taxonomic tier\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "axes[0].legend(title=\"Hypothesis status\", loc=\"upper right\")\n",
    "\n",
    "# Normalized (%)\n",
    "ct_norm = ct.div(ct.sum(axis=1), axis=0) * 100\n",
    "ct_norm.plot(kind=\"bar\", stacked=True, ax=axes[1],\n",
    "             color=[hyp_colors[h] for h in ct_norm.columns])\n",
    "axes[1].set_title(\"Proportion by Conservation Tier × Hypothesis Status\")\n",
    "axes[1].set_ylabel(\"Percentage\")\n",
    "axes[1].set_xlabel(\"Taxonomic tier\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "axes[1].legend(title=\"Hypothesis status\", loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig33_conservation_tiers.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig33_conservation_tiers.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0fddbe7e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig34: 2D classification heatmap (tier × hypothesis, counts + percentages)\n",
    "ct_full = pd.crosstab(dark_with_tier[\"taxonomic_tier\"], dark_with_tier[\"hypothesis_status\"])\n",
    "ct_full = ct_full.reindex(index=[t for t in tier_order if t in ct_full.index],\n",
    "                           columns=[h for h in hyp_order if h in ct_full.columns], fill_value=0)\n",
    "\n",
    "# Annotations: count + percentage\n",
    "total = ct_full.sum().sum()\n",
    "annot = ct_full.copy().astype(str)\n",
    "for i in ct_full.index:\n",
    "    for j in ct_full.columns:\n",
    "        v = ct_full.loc[i, j]\n",
    "        pct = 100 * v / total\n",
    "        annot.loc[i, j] = f\"{v:,}\n",
    "({pct:.1f}%)\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.heatmap(ct_full, annot=annot, fmt=\"\", cmap=\"YlOrRd\", ax=ax,\n",
    "            linewidths=0.5, linecolor=\"white\",\n",
    "            cbar_kws={\"label\": \"Gene count\"})\n",
    "ax.set_title(f\"Dark Gene Classification: Conservation Tier × Hypothesis Status\n",
    "(N = {total:,} dark genes)\")\n",
    "ax.set_ylabel(\"Conservation tier (pangenome)\")\n",
    "ax.set_xlabel(\"Hypothesis status\")\n",
    "\n",
    "# Highlight key cells (kingdom × true_knowledge_gap)\n",
    "if \"kingdom\" in ct_full.index and \"true_knowledge_gap\" in ct_full.columns:\n",
    "    row_idx = list(ct_full.index).index(\"kingdom\")\n",
    "    col_idx = list(ct_full.columns).index(\"true_knowledge_gap\")\n",
    "    ax.add_patch(plt.Rectangle((col_idx, row_idx), 1, 1, fill=False, \n",
    "                                edgecolor=\"blue\", linewidth=3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig34_classification_heatmap.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig34_classification_heatmap.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "51839d92"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig35: Top true knowledge gap OGs (most conserved, zero evidence)\n",
    "true_gaps = og_importance[og_importance[\"hypothesis_status\"] == \"true_knowledge_gap\"].head(25)\n",
    "print(f\"Top 25 true knowledge gap OGs (most conserved, zero evidence):\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "y_pos = range(len(true_gaps))\n",
    "bars = ax.barh(y_pos, true_gaps[\"n_species\"].fillna(1).values, \n",
    "               color=[\"#d62728\" if p > 1 else \"#999999\" for p in true_gaps[\"n_phyla\"].fillna(1).values])\n",
    "\n",
    "# Label with root_og and phyla count\n",
    "labels = [f\"{row['root_og']} ({int(row.get('n_phyla', 0) or 0)}p, {int(row['n_organisms'])}org)\" \n",
    "          for _, row in true_gaps.iterrows()]\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels, fontsize=8)\n",
    "ax.set_xlabel(\"Number of pangenome species\")\n",
    "ax.set_title(\"Top 25 True Knowledge Gap OGs — Most Conserved with Zero Functional Evidence\n",
    "(red = multi-phylum, label: root_og (phyla, FB organisms))\")\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig35_top_knowledge_gaps.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig35_top_knowledge_gaps.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "eae456bf"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig36: Covering set optimization curve\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Cumulative coverage\n",
    "color1 = \"#1f77b4\"\n",
    "ax1.plot(covering_df[\"step\"], covering_df[\"pct_covered\"], \"o-\", color=color1, linewidth=2)\n",
    "ax1.set_xlabel(\"Organism added (step)\")\n",
    "ax1.set_ylabel(\"Cumulative coverage (%)\", color=color1)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color1)\n",
    "ax1.axhline(y=95, color=color1, linestyle=\"--\", alpha=0.5, label=\"95% target\")\n",
    "\n",
    "# Marginal genes per step (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "color2 = \"#ff7f0e\"\n",
    "bars = ax2.bar(covering_df[\"step\"], covering_df[\"n_new_genes\"], alpha=0.4, color=color2)\n",
    "\n",
    "# Color bars by tractability\n",
    "for bar, tract in zip(bars, covering_df[\"tractability\"]):\n",
    "    bar.set_alpha(0.3 + 0.7 * tract)\n",
    "\n",
    "ax2.set_ylabel(\"New genes covered (per step)\", color=color2)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color2)\n",
    "\n",
    "# Label top organisms\n",
    "for _, row in covering_df.head(8).iterrows():\n",
    "    ax1.annotate(row[\"orgId\"], (row[\"step\"], row[\"pct_covered\"]),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), fontsize=7,\n",
    "                 ha=\"left\", rotation=20)\n",
    "\n",
    "ax1.set_title(\"Conservation-Weighted Covering Set Optimization\n",
    "(bar opacity = tractability score)\")\n",
    "ax1.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig36_covering_set_curve.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig36_covering_set_curve.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "f14fc846"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# fig37: Per-organism experimental plan summary heatmap\n",
    "\n",
    "# Build matrix: organisms × tier, gene count\n",
    "plan_top = plan_df.head(20).copy()  # top 20 organisms\n",
    "\n",
    "# Get tier counts per organism from assigned genes\n",
    "org_tier_matrix = []\n",
    "for _, row in plan_top.iterrows():\n",
    "    org = row[\"orgId\"]\n",
    "    org_genes = assigned[assigned[\"assigned_organism\"] == org]\n",
    "    tier_counts = org_genes[\"taxonomic_tier\"].value_counts()\n",
    "    entry = {\"orgId\": org, \"tractability\": row[\"tractability\"]}\n",
    "    for t in tier_order:\n",
    "        entry[t] = tier_counts.get(t, 0)\n",
    "    org_tier_matrix.append(entry)\n",
    "\n",
    "otm = pd.DataFrame(org_tier_matrix).set_index(\"orgId\")\n",
    "tract_col = otm.pop(\"tractability\")\n",
    "# Only keep tiers that have nonzero values\n",
    "otm = otm[[t for t in tier_order if t in otm.columns and otm[t].sum() > 0]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(otm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", ax=ax,\n",
    "            linewidths=0.5, linecolor=\"white\",\n",
    "            cbar_kws={\"label\": \"Gene count\"})\n",
    "ax.set_title(\"Per-Organism Dark Gene Coverage by Conservation Tier\n",
    "(top 20 organisms in covering set order)\")\n",
    "ax.set_ylabel(\"Organism (covering set order)\")\n",
    "ax.set_xlabel(\"Conservation tier\")\n",
    "\n",
    "# Add tractability as color bar on the right\n",
    "for i, (org, tract) in enumerate(tract_col.items()):\n",
    "    ax.text(len(otm.columns) + 0.3, i + 0.5, f\"{tract:.1f}\", va=\"center\", fontsize=8)\n",
    "ax.text(len(otm.columns) + 0.3, -0.5, \"Tract.\", va=\"center\", fontsize=8, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"fig37_experiment_plan_heatmap.png\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved fig37_experiment_plan_heatmap.png\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e091e728"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "NB11 provides a conservation-aware experimental prioritization for dark gene characterization:\n",
    "\n",
    "1. **Pangenome distribution**: Queried 27,690 pangenome species for taxonomic breadth of dark gene OGs\n",
    "2. **Taxonomic tier classification**: 8-tier system (kingdom → species + mobile) replacing the coarse eggNOG breadth_class\n",
    "3. **Hypothesis status**: 3-tier evidence assessment (strong hypothesis, weak lead, true knowledge gap)\n",
    "4. **Importance score**: conservation × ignorance ranking to find the most valuable unknowns\n",
    "5. **Minimum covering set**: Ordered organism list for experiments, weighted by importance + tractability\n",
    "6. **Experimental plans**: Per-organism action plans with OG breakdowns and recommended experiments"
   ],
   "id": "7f1050c5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Final summary statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"NB11 SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\n",
    "Dark genes classified: {len(dark_with_tier):,}\")\n",
    "print(f\"OGs with pangenome distribution: {len(pg_dist):,}\")\n",
    "print(f\"OGs ranked by importance: {len(og_importance):,}\")\n",
    "print(f\"\n",
    "Taxonomic tier distribution:\")\n",
    "for tier, n in dark_with_tier[\"taxonomic_tier\"].value_counts().items():\n",
    "    print(f\"  {tier:12s}: {n:6,} ({100*n/len(dark_with_tier):5.1f}%)\")\n",
    "print(f\"\n",
    "Hypothesis status:\")\n",
    "for hyp, n in dark_with_tier[\"hypothesis_status\"].value_counts().items():\n",
    "    print(f\"  {hyp:25s}: {n:6,} ({100*n/len(dark_with_tier):5.1f}%)\")\n",
    "print(f\"\n",
    "Covering set: {len(covering_df)} organisms for 95% priority coverage\")\n",
    "print(f\"Expected novel functions (top organism): {plan_df.iloc[0]['expected_novel']}\")\n",
    "print(f\"\n",
    "Output files:\")\n",
    "for f in [\"og_pangenome_distribution.tsv\", \"dark_gene_classes.tsv\", \n",
    "          \"og_importance_ranked.tsv\", \"conservation_covering_set.tsv\",\n",
    "          \"conservation_experiment_plans.tsv\"]:\n",
    "    path = os.path.join(DATA_DIR, f)\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path)\n",
    "        print(f\"  {f}: {size:,} bytes\")\n",
    "print(f\"\n",
    "Figures: fig32-fig37 saved to {FIG_DIR}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e2b70a7b"
  }
 ]
}