{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Explore BERDL Data & Pangenome Structure\n",
    "\n",
    "This notebook explores the BERDL pangenome collection to understand its structure and prepare for antibiotic resistance gene (ARG) detection.\n",
    "\n",
    "## Goals\n",
    "1. Connect to BERDL and verify access\n",
    "2. Explore pangenome collection tables and schemas\n",
    "3. Understand the relationship between genomes, genes, and orthogroups\n",
    "4. Document table structures and row counts\n",
    "5. Identify metadata fields for downstream analysis (environment, taxonomy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session (if not already initialized)\n",
    "# Note: In BERDL JupyterHub, spark session is usually pre-initialized\n",
    "try:\n",
    "    spark\n",
    "    print(\"Spark session already initialized\")\n",
    "except NameError:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"resistance_hotspots\") \\\n",
    "        .getOrCreate()\n",
    "    print(\"Spark session created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Available Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available databases/collections\n",
    "databases = spark.sql(\"SHOW DATABASES\").collect()\n",
    "print(f\"Available databases: {len(databases)}\")\n",
    "for db in databases:\n",
    "    print(f\"  - {db.namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the pangenome collection\n",
    "pangenome_tables = spark.sql(\"SHOW TABLES IN kbase_ke_pangenome\").collect()\n",
    "print(f\"Tables in kbase_ke_pangenome: {len(pangenome_tables)}\")\nfor table in pangenome_tables:\n",
    "    print(f\"  - {table.tableName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Key Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pangenome table\n",
    "pangenome_df = spark.sql(\"SELECT * FROM kbase_ke_pangenome.pangenome LIMIT 5\")\n",
    "print(\"Pangenome Table Schema:\")\n",
    "pangenome_df.printSchema()\n",
    "print(f\"\\nRow count: {spark.sql('SELECT COUNT(*) as count FROM kbase_ke_pangenome.pangenome').collect()[0]['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check gene table\ngene_df = spark.sql(\"SELECT * FROM kbase_ke_pangenome.gene LIMIT 5\")\nprint(\"Gene Table Schema:\")\ngene_df.printSchema()\nprint(f\"\\nRow count: {spark.sql('SELECT COUNT(*) as count FROM kbase_ke_pangenome.gene').collect()[0]['count']}\")\n\n# Check eggNOG annotations (functional annotations including potential resistance genes)\neggnog_df = spark.sql(\"SELECT * FROM kbase_ke_pangenome.eggnog_mapper_annotations LIMIT 5\")\nprint(\"\\neggNOG Annotations Table Schema:\")\neggnog_df.printSchema()\nprint(f\"\\nRow count: {spark.sql('SELECT COUNT(*) as count FROM kbase_ke_pangenome.eggnog_mapper_annotations').collect()[0]['count']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check orthogroup table\n",
    "orthogroup_df = spark.sql(\"SELECT * FROM kbase_ke_pangenome.orthogroup LIMIT 5\")\n",
    "print(\"Orthogroup Table Schema:\")\n",
    "orthogroup_df.printSchema()\n",
    "print(f\"\\nRow count: {spark.sql('SELECT COUNT(*) as count FROM kbase_ke_pangenome.orthogroup').collect()[0]['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GTDB species taxonomy\n",
    "gtdb_df = spark.sql(\"SELECT * FROM kbase_ke_pangenome.gtdb_species_clade LIMIT 5\")\n",
    "print(\"GTDB Species Clade Table Schema:\")\n",
    "gtdb_df.printSchema()\n",
    "print(f\"\\nRow count: {spark.sql('SELECT COUNT(*) as count FROM kbase_ke_pangenome.gtdb_species_clade').collect()[0]['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "stats_query = \"\"\"\n",
    "SELECT \n",
    "    (SELECT COUNT(DISTINCT pangenome_id) FROM kbase_ke_pangenome.pangenome) as n_pangenomes,\n",
    "    (SELECT COUNT(DISTINCT genome_id) FROM kbase_ke_pangenome.genome) as n_genomes,\n",
    "    (SELECT COUNT(*) FROM kbase_ke_pangenome.gene) as n_genes,\n",
    "    (SELECT COUNT(*) FROM kbase_ke_pangenome.orthogroup) as n_orthogroups\n",
    "\"\"\"\n",
    "\n",
    "stats = spark.sql(stats_query).collect()[0]\n",
    "print(\"BERDL Pangenome Collection Summary:\")\n",
    "print(f\"  Pangenomes: {stats.n_pangenomes}\")\n",
    "print(f\"  Genomes: {stats.n_genomes}\")\n",
    "print(f\"  Genes: {stats.n_genes}\")\n",
    "print(f\"  Orthogroups: {stats.n_orthogroups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Identify which tables contain functional annotations or gene descriptions\n",
    "2. Look for any existing resistance-related annotations in the database\n",
    "3. Plan ARG detection strategy in notebook 02_identify_args.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}