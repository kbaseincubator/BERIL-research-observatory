{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NB 03: Robust ICA Module Decomposition\n\nDecompose each organism's fitness matrix into stable independent\ncomponents (modules) using the robust ICA pipeline.\n\nAlgorithm (adapted from Borchert et al. 2019):\n1. Standardize: center each gene row to mean 0, scale by std\n2. Determine n_components via PCA (Marchenko-Pastur threshold)\n3. Run FastICA 30-50× with different random seeds\n4. Cluster all components by |cosine similarity| (DBSCAN)\n5. Stable clusters = modules; compute gene weights (Pearson r)\n6. Threshold membership: |weight| >= 0.3, max 50 genes per module\n\n**Run locally** — no Spark needed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for pipeline import\n",
    "sys.path.insert(0, str(Path('../src').resolve()))\n",
    "from ica_pipeline import (\n",
    "    standardize_matrix, select_n_components, robust_ica,\n",
    "    compute_gene_weights, threshold_membership\n",
    ")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MATRIX_DIR = DATA_DIR / 'matrices'\n",
    "MODULE_DIR = DATA_DIR / 'modules'\n",
    "MODULE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure dependencies\n",
    "try:\n",
    "    from sklearn.decomposition import FastICA\n",
    "    print(\"scikit-learn available\")\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'scikit-learn'])\n",
    "    print(\"Installed scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pilot organisms\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")\n",
    "\n",
    "# Load matrix summary\n",
    "summary = pd.read_csv(MATRIX_DIR / 'matrix_summary.csv')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCA Dimensionality Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, len(pilot_ids), figsize=(4*len(pilot_ids), 4))\n",
    "if len(pilot_ids) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "n_components_selected = {}\n",
    "\n",
    "for ax, org_id in zip(axes, pilot_ids):\n",
    "    fit_matrix = pd.read_csv(MATRIX_DIR / f'{org_id}_fitness_matrix.csv', index_col=0)\n",
    "    X = fit_matrix.values\n",
    "    X_std, _, _ = standardize_matrix(X)\n",
    "    \n",
    "    n_comp, eigenvalues = select_n_components(X_std, method='marchenko_pastur')\n",
    "    n_components_selected[org_id] = n_comp\n",
    "    \n",
    "    ax.plot(range(1, len(eigenvalues)+1), eigenvalues, 'b.-')\n",
    "    ax.axvline(n_comp, color='r', linestyle='--', label=f'n={n_comp}')\n",
    "    ax.set_xlabel('Component')\n",
    "    ax.set_ylabel('Eigenvalue')\n",
    "    ax.set_title(f'{org_id}')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, min(100, len(eigenvalues)))\n",
    "    \n",
    "    print(f\"{org_id}: matrix {X.shape}, selected {n_comp} components\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/pca_eigenvalues.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Robust ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "N_RUNS = 30\nMAX_COMP = 80      # cap; also limited to 40% of n_experiments\nEPS = 0.15\nMIN_SAMPLES = 15\nMIN_WEIGHT = 0.3   # absolute |weight| threshold for membership\nMAX_MEMBERS = 50   # max genes per module\n\nfor org_id in pilot_ids:\n    profile_file = MODULE_DIR / f'{org_id}_module_profiles.csv'\n    weights_file = MODULE_DIR / f'{org_id}_gene_weights.csv'\n    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n    params_file = MODULE_DIR / f'{org_id}_ica_params.json'\n    \n    if profile_file.exists() and profile_file.stat().st_size > 0:\n        print(f\"CACHED: {org_id}\")\n        continue\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Processing {org_id}\")\n    print(f\"{'='*60}\")\n    \n    # Load and standardize\n    fit_matrix = pd.read_csv(MATRIX_DIR / f'{org_id}_fitness_matrix.csv', index_col=0)\n    X = fit_matrix.values\n    n_genes, n_exps = X.shape\n    X_std, means, stds = standardize_matrix(X)\n    \n    # Select components: min(MP threshold, MAX_COMP, 40% of experiments)\n    n_comp_mp, eigenvalues = select_n_components(X_std, method='marchenko_pastur')\n    n_comp = min(n_comp_mp, MAX_COMP, int(n_exps * 0.4))\n    n_components_selected[org_id] = n_comp\n    \n    print(f\"Matrix: {n_genes} genes × {n_exps} experiments\")\n    print(f\"Components: {n_comp} (MP={n_comp_mp}, cap={MAX_COMP})\")\n    print(f\"Running {N_RUNS} ICA iterations...\")\n    \n    # Run robust ICA\n    modules, labels, all_components, metadata = robust_ica(\n        X_std, n_comp, n_runs=N_RUNS, eps=EPS, min_samples=MIN_SAMPLES,\n        max_iter=500, tol=1e-3\n    )\n    \n    print(f\"  Converged: {metadata['n_converged']}/{N_RUNS}\")\n    print(f\"  Stable modules: {metadata['n_stable_modules']}\")\n    print(f\"  Noise components: {metadata['n_noise_components']}\")\n    \n    if metadata['n_stable_modules'] == 0:\n        print(f\"  WARNING: No stable modules found for {org_id}.\")\n        continue\n    \n    # Compute gene weights and threshold membership\n    weights = compute_gene_weights(X_std, modules)\n    membership, thresholds = threshold_membership(weights,\n                                                   min_weight=MIN_WEIGHT,\n                                                   max_members=MAX_MEMBERS)\n    \n    # Drop modules with 0 members\n    n_members_per_module = membership.sum(axis=0)\n    has_members = n_members_per_module > 0\n    modules = modules[has_members]\n    weights = weights[:, has_members]\n    membership = membership[:, has_members]\n    n_members_per_module = n_members_per_module[has_members]\n    thresholds = thresholds[has_members]\n    \n    print(f\"  Modules with members: {len(modules)}\")\n    print(f\"  Members per module: min={n_members_per_module.min()}, \"\n          f\"median={np.median(n_members_per_module):.0f}, \"\n          f\"max={n_members_per_module.max()}\")\n    \n    # Save\n    module_names = [f'M{i:03d}' for i in range(len(modules))]\n    pd.DataFrame(modules, index=module_names, columns=fit_matrix.columns).to_csv(profile_file)\n    pd.DataFrame(weights, index=fit_matrix.index, columns=module_names).to_csv(weights_file)\n    pd.DataFrame(membership, index=fit_matrix.index, columns=module_names).to_csv(member_file)\n    \n    params = {\n        'orgId': org_id,\n        'n_genes': int(n_genes),\n        'n_experiments': int(n_exps),\n        'n_components_mp': n_comp_mp,\n        'n_components_used': n_comp,\n        'n_runs': N_RUNS,\n        'eps': EPS,\n        'min_samples': MIN_SAMPLES,\n        'min_weight': MIN_WEIGHT,\n        'max_members': MAX_MEMBERS,\n        'n_stable_modules': int(metadata['n_stable_modules']),\n        'n_modules_with_members': int(len(modules)),\n        'n_converged': int(metadata['n_converged']),\n        'members_per_module': n_members_per_module.tolist(),\n        'thresholds': thresholds.tolist()\n    }\n    with open(params_file, 'w') as f:\n        json.dump(params, f, indent=2)\n    \n    print(f\"  Saved to {MODULE_DIR}/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Module Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary across all organisms\n",
    "all_params = []\n",
    "for org_id in pilot_ids:\n",
    "    params_file = MODULE_DIR / f'{org_id}_ica_params.json'\n",
    "    if params_file.exists():\n",
    "        with open(params_file) as f:\n",
    "            all_params.append(json.load(f))\n",
    "\n",
    "params_df = pd.DataFrame(all_params)\n",
    "print(\"ICA Module Summary:\")\n",
    "params_df[['orgId', 'n_genes', 'n_experiments', 'n_components', 'n_stable_modules', 'n_converged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize module size distributions\n",
    "fig, axes = plt.subplots(1, len(pilot_ids), figsize=(4*len(pilot_ids), 4))\n",
    "if len(pilot_ids) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, org_id in zip(axes, pilot_ids):\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    if not member_file.exists():\n",
    "        continue\n",
    "    membership = pd.read_csv(member_file, index_col=0)\n",
    "    module_sizes = membership.sum(axis=0)\n",
    "    ax.bar(range(len(module_sizes)), sorted(module_sizes, reverse=True))\n",
    "    ax.set_xlabel('Module rank')\n",
    "    ax.set_ylabel('Number of genes')\n",
    "    ax.set_title(f'{org_id} ({len(module_sizes)} modules)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/module_size_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}