{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 03: Robust ICA Module Decomposition\n",
    "\n",
    "Decompose each pilot organism's fitness matrix into stable independent\n",
    "components (modules) using the robust ICA pipeline.\n",
    "\n",
    "Algorithm (Borchert et al. 2019):\n",
    "1. Standardize: center each gene row to mean 0, scale by std\n",
    "2. Determine n_components via PCA (Marchenko-Pastur threshold)\n",
    "3. Run FastICA 100× with different random seeds\n",
    "4. Cluster all components by |cosine similarity| (DBSCAN)\n",
    "5. Stable clusters = modules; compute gene weights\n",
    "6. Threshold membership via D'Agostino K² normality test\n",
    "\n",
    "**Run locally** — no Spark needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for pipeline import\n",
    "sys.path.insert(0, str(Path('../src').resolve()))\n",
    "from ica_pipeline import (\n",
    "    standardize_matrix, select_n_components, robust_ica,\n",
    "    compute_gene_weights, threshold_membership\n",
    ")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MATRIX_DIR = DATA_DIR / 'matrices'\n",
    "MODULE_DIR = DATA_DIR / 'modules'\n",
    "MODULE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure dependencies\n",
    "try:\n",
    "    from sklearn.decomposition import FastICA\n",
    "    print(\"scikit-learn available\")\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'scikit-learn'])\n",
    "    print(\"Installed scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pilot organisms\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")\n",
    "\n",
    "# Load matrix summary\n",
    "summary = pd.read_csv(MATRIX_DIR / 'matrix_summary.csv')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCA Dimensionality Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, len(pilot_ids), figsize=(4*len(pilot_ids), 4))\n",
    "if len(pilot_ids) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "n_components_selected = {}\n",
    "\n",
    "for ax, org_id in zip(axes, pilot_ids):\n",
    "    fit_matrix = pd.read_csv(MATRIX_DIR / f'{org_id}_fitness_matrix.csv', index_col=0)\n",
    "    X = fit_matrix.values\n",
    "    X_std, _, _ = standardize_matrix(X)\n",
    "    \n",
    "    n_comp, eigenvalues = select_n_components(X_std, method='marchenko_pastur')\n",
    "    n_components_selected[org_id] = n_comp\n",
    "    \n",
    "    ax.plot(range(1, len(eigenvalues)+1), eigenvalues, 'b.-')\n",
    "    ax.axvline(n_comp, color='r', linestyle='--', label=f'n={n_comp}')\n",
    "    ax.set_xlabel('Component')\n",
    "    ax.set_ylabel('Eigenvalue')\n",
    "    ax.set_title(f'{org_id}')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, min(100, len(eigenvalues)))\n",
    "    \n",
    "    print(f\"{org_id}: matrix {X.shape}, selected {n_comp} components\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/pca_eigenvalues.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Robust ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 100\n",
    "EPS = 0.15\n",
    "MIN_SAMPLES = 50\n",
    "\n",
    "for org_id in pilot_ids:\n",
    "    profile_file = MODULE_DIR / f'{org_id}_module_profiles.csv'\n",
    "    weights_file = MODULE_DIR / f'{org_id}_gene_weights.csv'\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    params_file = MODULE_DIR / f'{org_id}_ica_params.json'\n",
    "    \n",
    "    if profile_file.exists() and profile_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {org_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load and standardize\n",
    "    fit_matrix = pd.read_csv(MATRIX_DIR / f'{org_id}_fitness_matrix.csv', index_col=0)\n",
    "    X = fit_matrix.values\n",
    "    X_std, means, stds = standardize_matrix(X)\n",
    "    n_comp = n_components_selected[org_id]\n",
    "    \n",
    "    print(f\"Matrix: {X.shape[0]} genes × {X.shape[1]} experiments\")\n",
    "    print(f\"Components: {n_comp}\")\n",
    "    print(f\"Running {N_RUNS} ICA iterations...\")\n",
    "    \n",
    "    # Run robust ICA\n",
    "    modules, labels, all_components, metadata = robust_ica(\n",
    "        X_std, n_comp, n_runs=N_RUNS, eps=EPS, min_samples=MIN_SAMPLES\n",
    "    )\n",
    "    \n",
    "    print(f\"  Converged: {metadata['n_converged']}/{N_RUNS}\")\n",
    "    print(f\"  Stable modules: {metadata['n_stable_modules']}\")\n",
    "    print(f\"  Noise components: {metadata['n_noise_components']}\")\n",
    "    \n",
    "    if metadata['n_stable_modules'] == 0:\n",
    "        print(f\"  WARNING: No stable modules found for {org_id}. Try different eps/min_samples.\")\n",
    "        continue\n",
    "    \n",
    "    # Compute gene weights\n",
    "    weights = compute_gene_weights(X_std, modules)\n",
    "    \n",
    "    # Threshold membership\n",
    "    membership, thresholds = threshold_membership(weights)\n",
    "    \n",
    "    # Module summary\n",
    "    n_members_per_module = membership.sum(axis=0)\n",
    "    print(f\"  Members per module: min={n_members_per_module.min()}, \"\n",
    "          f\"median={np.median(n_members_per_module):.0f}, \"\n",
    "          f\"max={n_members_per_module.max()}\")\n",
    "    \n",
    "    # Save module profiles (module × experiment)\n",
    "    module_names = [f'M{i:03d}' for i in range(len(modules))]\n",
    "    profiles_df = pd.DataFrame(modules, index=module_names, columns=fit_matrix.columns)\n",
    "    profiles_df.to_csv(profile_file)\n",
    "    \n",
    "    # Save gene weights (gene × module)\n",
    "    weights_df = pd.DataFrame(weights, index=fit_matrix.index, columns=module_names)\n",
    "    weights_df.to_csv(weights_file)\n",
    "    \n",
    "    # Save binary membership (gene × module)\n",
    "    member_df = pd.DataFrame(membership, index=fit_matrix.index, columns=module_names)\n",
    "    member_df.to_csv(member_file)\n",
    "    \n",
    "    # Save parameters\n",
    "    params = {\n",
    "        'orgId': org_id,\n",
    "        'n_genes': int(X.shape[0]),\n",
    "        'n_experiments': int(X.shape[1]),\n",
    "        'n_components': n_comp,\n",
    "        'n_runs': N_RUNS,\n",
    "        'eps': EPS,\n",
    "        'min_samples': MIN_SAMPLES,\n",
    "        'n_stable_modules': int(metadata['n_stable_modules']),\n",
    "        'n_converged': int(metadata['n_converged']),\n",
    "        'members_per_module': n_members_per_module.tolist(),\n",
    "        'thresholds': thresholds.tolist()\n",
    "    }\n",
    "    with open(params_file, 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "    \n",
    "    print(f\"  Saved to {MODULE_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Module Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary across all organisms\n",
    "all_params = []\n",
    "for org_id in pilot_ids:\n",
    "    params_file = MODULE_DIR / f'{org_id}_ica_params.json'\n",
    "    if params_file.exists():\n",
    "        with open(params_file) as f:\n",
    "            all_params.append(json.load(f))\n",
    "\n",
    "params_df = pd.DataFrame(all_params)\n",
    "print(\"ICA Module Summary:\")\n",
    "params_df[['orgId', 'n_genes', 'n_experiments', 'n_components', 'n_stable_modules', 'n_converged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize module size distributions\n",
    "fig, axes = plt.subplots(1, len(pilot_ids), figsize=(4*len(pilot_ids), 4))\n",
    "if len(pilot_ids) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, org_id in zip(axes, pilot_ids):\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    if not member_file.exists():\n",
    "        continue\n",
    "    membership = pd.read_csv(member_file, index_col=0)\n",
    "    module_sizes = membership.sum(axis=0)\n",
    "    ax.bar(range(len(module_sizes)), sorted(module_sizes, reverse=True))\n",
    "    ax.set_xlabel('Module rank')\n",
    "    ax.set_ylabel('Number of genes')\n",
    "    ax.set_title(f'{org_id} ({len(module_sizes)} modules)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/module_size_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
