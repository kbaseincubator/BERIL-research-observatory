{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 02: Extract Gene-Fitness Matrices\n",
    "\n",
    "Build gene × experiment fitness matrices for each pilot organism.\n",
    "Also extracts gene metadata and experiment metadata.\n",
    "\n",
    "**Strategy**: Try `fitbyexp_{orgId}` tables first (pre-pivoted),\n",
    "fall back to pivoting `genefitness` if needed.\n",
    "\n",
    "**Run on BERDL JupyterHub** for Spark access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark_session()\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MATRIX_DIR = DATA_DIR / 'matrices'\n",
    "ANNOT_DIR = DATA_DIR / 'annotations'\n",
    "MATRIX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ANNOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pilot organisms\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Gene Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for org_id in pilot_ids:\n",
    "    out_file = ANNOT_DIR / f'{org_id}_genes.csv'\n",
    "    if out_file.exists() and out_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id} genes\")\n",
    "        continue\n",
    "    \n",
    "    genes = spark.sql(f\"\"\"\n",
    "        SELECT locusId, sysName, gene, desc, scaffoldId,\n",
    "               CAST(begin AS INT) as begin, CAST(end AS INT) as end, strand\n",
    "        FROM kescience_fitnessbrowser.gene\n",
    "        WHERE orgId = '{org_id}'\n",
    "        ORDER BY scaffoldId, begin\n",
    "    \"\"\").toPandas()\n",
    "    genes.to_csv(out_file, index=False)\n",
    "    print(f\"Saved: {org_id} — {len(genes)} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for org_id in pilot_ids:\n",
    "    out_file = ANNOT_DIR / f'{org_id}_experiments.csv'\n",
    "    if out_file.exists() and out_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id} experiments\")\n",
    "        continue\n",
    "    \n",
    "    exps = spark.sql(f\"\"\"\n",
    "        SELECT expName, expDesc, expGroup, condition_1, media,\n",
    "               CAST(cor12 AS FLOAT) as cor12,\n",
    "               CAST(mad12 AS FLOAT) as mad12,\n",
    "               CAST(nMapped AS INT) as nMapped\n",
    "        FROM kescience_fitnessbrowser.experiment\n",
    "        WHERE orgId = '{org_id}'\n",
    "        ORDER BY expName\n",
    "    \"\"\").toPandas()\n",
    "    exps.to_csv(out_file, index=False)\n",
    "    print(f\"Saved: {org_id} — {len(exps)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Fitness Matrices\n",
    "\n",
    "Try `fitbyexp_{orgId}` first; fall back to `genefitness` pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fitness_matrix_fitbyexp(spark, org_id):\n",
    "    \"\"\"Extract fitness matrix from pre-pivoted fitbyexp table.\"\"\"\n",
    "    table_name = f\"kescience_fitnessbrowser.fitbyexp_{org_id.lower()}\"\n",
    "    try:\n",
    "        df = spark.sql(f\"SELECT * FROM {table_name}\").toPandas()\n",
    "        if len(df) == 0:\n",
    "            return None\n",
    "        \n",
    "        # First column is locusId (or similar identifier)\n",
    "        id_col = df.columns[0]\n",
    "        df = df.set_index(id_col)\n",
    "        \n",
    "        # Convert all fitness values to numeric\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"  fitbyexp_{org_id.lower()} not available: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_fitness_matrix_genefitness(spark, org_id):\n",
    "    \"\"\"Extract and pivot fitness matrix from genefitness table.\"\"\"\n",
    "    gf = spark.sql(f\"\"\"\n",
    "        SELECT locusId, expName,\n",
    "               CAST(fit AS FLOAT) as fit\n",
    "        FROM kescience_fitnessbrowser.genefitness\n",
    "        WHERE orgId = '{org_id}'\n",
    "    \"\"\").toPandas()\n",
    "    \n",
    "    if len(gf) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Pivot to gene x experiment matrix\n",
    "    matrix = gf.pivot(index='locusId', columns='expName', values='fit')\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extract_t_matrix(spark, org_id):\n",
    "    \"\"\"Extract t-statistic matrix from genefitness table.\"\"\"\n",
    "    gf = spark.sql(f\"\"\"\n",
    "        SELECT locusId, expName,\n",
    "               CAST(t AS FLOAT) as t\n",
    "        FROM kescience_fitnessbrowser.genefitness\n",
    "        WHERE orgId = '{org_id}'\n",
    "    \"\"\").toPandas()\n",
    "    \n",
    "    if len(gf) == 0:\n",
    "        return None\n",
    "    \n",
    "    matrix = gf.pivot(index='locusId', columns='expName', values='t')\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_summary = []\n",
    "\n",
    "for org_id in pilot_ids:\n",
    "    fit_file = MATRIX_DIR / f'{org_id}_fitness_matrix.csv'\n",
    "    t_file = MATRIX_DIR / f'{org_id}_t_matrix.csv'\n",
    "    \n",
    "    if fit_file.exists() and fit_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id} fitness matrix\")\n",
    "        fit_matrix = pd.read_csv(fit_file, index_col=0)\n",
    "    else:\n",
    "        print(f\"\\nExtracting {org_id}...\")\n",
    "        \n",
    "        # Try fitbyexp first\n",
    "        fit_matrix = extract_fitness_matrix_fitbyexp(spark, org_id)\n",
    "        if fit_matrix is None:\n",
    "            print(f\"  Falling back to genefitness pivot...\")\n",
    "            fit_matrix = extract_fitness_matrix_genefitness(spark, org_id)\n",
    "        \n",
    "        if fit_matrix is None:\n",
    "            print(f\"  ERROR: No fitness data for {org_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Load experiment QC to filter bad experiments\n",
    "        exp_meta = pd.read_csv(ANNOT_DIR / f'{org_id}_experiments.csv')\n",
    "        good_exps = exp_meta[exp_meta['cor12'] >= 0.1]['expName'].tolist()\n",
    "        shared_exps = [e for e in good_exps if e in fit_matrix.columns]\n",
    "        fit_matrix = fit_matrix[shared_exps]\n",
    "        print(f\"  Kept {len(shared_exps)}/{len(fit_matrix.columns)} experiments (cor12 >= 0.1)\")\n",
    "        \n",
    "        # Drop genes missing fitness in >50% of experiments\n",
    "        missing_frac = fit_matrix.isna().mean(axis=1)\n",
    "        fit_matrix = fit_matrix[missing_frac <= 0.5]\n",
    "        print(f\"  Kept {len(fit_matrix)} genes (<=50% missing)\")\n",
    "        \n",
    "        # Fill remaining NaN with 0\n",
    "        fit_matrix = fit_matrix.fillna(0.0)\n",
    "        \n",
    "        fit_matrix.to_csv(fit_file)\n",
    "        print(f\"  Saved: {fit_file}\")\n",
    "    \n",
    "    # Extract t-statistic matrix\n",
    "    if t_file.exists() and t_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id} t-statistic matrix\")\n",
    "    else:\n",
    "        print(f\"  Extracting t-statistics for {org_id}...\")\n",
    "        t_matrix = extract_t_matrix(spark, org_id)\n",
    "        if t_matrix is not None:\n",
    "            # Apply same filters as fitness matrix\n",
    "            shared_cols = [c for c in fit_matrix.columns if c in t_matrix.columns]\n",
    "            shared_rows = [r for r in fit_matrix.index if r in t_matrix.index]\n",
    "            t_matrix = t_matrix.loc[shared_rows, shared_cols].fillna(0.0)\n",
    "            t_matrix.to_csv(t_file)\n",
    "            print(f\"  Saved: {t_file}\")\n",
    "    \n",
    "    matrix_summary.append({\n",
    "        'orgId': org_id,\n",
    "        'n_genes': fit_matrix.shape[0],\n",
    "        'n_experiments': fit_matrix.shape[1],\n",
    "        'matrix_density': (fit_matrix != 0).mean().mean(),\n",
    "        'mean_fitness': fit_matrix.values.mean(),\n",
    "        'std_fitness': fit_matrix.values.std()\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(matrix_summary)\n",
    "summary_df.to_csv(MATRIX_DIR / 'matrix_summary.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MATRIX EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
