{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 07: Benchmarking Module-Based Predictions\n",
    "\n",
    "Evaluate module-based function predictions against baselines:\n",
    "1. **Cofitness voting**: top-N cofit partners → majority vote\n",
    "2. **Ortholog transfer**: BBH annotation transfer\n",
    "3. **Domain-only**: TIGRFam/PFam classification\n",
    "\n",
    "Evaluation: hold out 20% of annotated genes, predict, measure precision/recall/F1\n",
    "at KEGG KO level.\n",
    "\n",
    "Additional validation:\n",
    "- Within-module cofitness density\n",
    "- Genomic adjacency (operon proximity)\n",
    "- Concordance with specific phenotype hits\n",
    "\n",
    "**Run locally** — no Spark needed (uses extracted data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MODULE_DIR = DATA_DIR / 'modules'\n",
    "ANNOT_DIR = DATA_DIR / 'annotations'\n",
    "ORTHO_DIR = DATA_DIR / 'orthologs'\n",
    "PRED_DIR = DATA_DIR / 'predictions'\n",
    "FIG_DIR = Path('../figures')\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Gold Standard from KEGG Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build gold standard: genes with KEGG annotations\n",
    "gold_standard = {}\n",
    "\n",
    "for org_id in pilot_ids:\n",
    "    kegg_file = ANNOT_DIR / f'{org_id}_kegg.csv'\n",
    "    if not kegg_file.exists():\n",
    "        continue\n",
    "    kegg = pd.read_csv(kegg_file)\n",
    "    kegg['locusId'] = kegg['locusId'].astype(str)\n",
    "    \n",
    "    # Gene → set of KEGG groups (a gene can have multiple KOs)\n",
    "    gene_kegg = kegg.groupby('locusId')['kgroup'].apply(set).to_dict()\n",
    "    gold_standard[org_id] = gene_kegg\n",
    "    print(f\"{org_id}: {len(gene_kegg)} genes with KEGG annotations\")\n",
    "\n",
    "print(f\"\\nTotal annotated genes: {sum(len(v) for v in gold_standard.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hold-Out Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "holdout_frac = 0.2\n",
    "\n",
    "train_genes = {}  # genes used for enrichment\n",
    "test_genes = {}   # genes used for evaluation\n",
    "\n",
    "for org_id, gene_kegg in gold_standard.items():\n",
    "    all_loci = list(gene_kegg.keys())\n",
    "    train_loci, test_loci = train_test_split(all_loci, test_size=holdout_frac,\n",
    "                                              random_state=42)\n",
    "    train_genes[org_id] = {l: gene_kegg[l] for l in train_loci}\n",
    "    test_genes[org_id] = {l: gene_kegg[l] for l in test_loci}\n",
    "    print(f\"{org_id}: train={len(train_loci)}, test={len(test_loci)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Module-Based Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_predict(org_id, test_loci, train_kegg, membership, weights, kegg_df):\n",
    "    \"\"\"Predict KEGG group for test genes using module enrichment.\"\"\"\n",
    "    # Build module → enriched KEGG terms using TRAINING genes only\n",
    "    module_kegg = {}\n",
    "    for mod in membership.columns:\n",
    "        mod_genes = set(membership.index[membership[mod] == 1].astype(str))\n",
    "        # Only use training genes for enrichment\n",
    "        mod_train = mod_genes & set(train_kegg.keys())\n",
    "        if not mod_train:\n",
    "            continue\n",
    "        # Most common KEGG group in module\n",
    "        kegg_counts = Counter()\n",
    "        for g in mod_train:\n",
    "            for kg in train_kegg[g]:\n",
    "                kegg_counts[kg] += 1\n",
    "        if kegg_counts:\n",
    "            module_kegg[mod] = kegg_counts.most_common(1)[0][0]\n",
    "    \n",
    "    predictions = {}\n",
    "    for locus in test_loci:\n",
    "        if locus not in membership.index.astype(str).tolist():\n",
    "            continue\n",
    "        gene_mods = membership.columns[membership.loc[membership.index.astype(str) == locus].iloc[0] == 1]\n",
    "        if len(gene_mods) == 0:\n",
    "            continue\n",
    "        # Pick module with highest |weight|\n",
    "        best_mod = None\n",
    "        best_weight = 0\n",
    "        for mod in gene_mods:\n",
    "            w = abs(weights.loc[weights.index.astype(str) == locus, mod].values[0])\n",
    "            if w > best_weight and mod in module_kegg:\n",
    "                best_weight = w\n",
    "                best_mod = mod\n",
    "        if best_mod:\n",
    "            predictions[locus] = module_kegg[best_mod]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline: Cofitness Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofit_predict(org_id, test_loci, train_kegg, top_n=6):\n",
    "    \"\"\"Predict KEGG group using top-N cofitness partners (majority vote).\"\"\"\n",
    "    # Load precomputed gene weights to get cofitness from fitness matrix\n",
    "    fit_file = DATA_DIR / 'matrices' / f'{org_id}_fitness_matrix.csv'\n",
    "    if not fit_file.exists():\n",
    "        return {}\n",
    "    \n",
    "    fit_matrix = pd.read_csv(fit_file, index_col=0)\n",
    "    fit_matrix.index = fit_matrix.index.astype(str)\n",
    "    \n",
    "    # Compute correlations on the fly for test genes\n",
    "    predictions = {}\n",
    "    for locus in test_loci:\n",
    "        if locus not in fit_matrix.index:\n",
    "            continue\n",
    "        gene_profile = fit_matrix.loc[locus].values\n",
    "        \n",
    "        # Correlate with all training genes\n",
    "        train_loci_in_matrix = [l for l in train_kegg if l in fit_matrix.index]\n",
    "        if not train_loci_in_matrix:\n",
    "            continue\n",
    "        \n",
    "        corrs = []\n",
    "        for tl in train_loci_in_matrix:\n",
    "            r = np.corrcoef(gene_profile, fit_matrix.loc[tl].values)[0, 1]\n",
    "            corrs.append((tl, r))\n",
    "        corrs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_partners = corrs[:top_n]\n",
    "        \n",
    "        # Majority vote\n",
    "        kegg_votes = Counter()\n",
    "        for partner, _ in top_partners:\n",
    "            for kg in train_kegg[partner]:\n",
    "                kegg_votes[kg] += 1\n",
    "        if kegg_votes:\n",
    "            predictions[locus] = kegg_votes.most_common(1)[0][0]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline: Ortholog Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortholog_predict(org_id, test_loci, all_train_kegg, bbh_pairs):\n",
    "    \"\"\"Predict KEGG group by transferring from BBH ortholog in other organism.\"\"\"\n",
    "    predictions = {}\n",
    "    org_bbh = bbh_pairs[bbh_pairs['orgId1'] == org_id]\n",
    "    \n",
    "    for locus in test_loci:\n",
    "        hits = org_bbh[org_bbh['locusId1'].astype(str) == locus]\n",
    "        if len(hits) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Check if any ortholog has a KEGG annotation (from training set)\n",
    "        for _, hit in hits.iterrows():\n",
    "            other_org = hit['orgId2']\n",
    "            other_locus = str(hit['locusId2'])\n",
    "            if other_org in all_train_kegg and other_locus in all_train_kegg[other_org]:\n",
    "                # Transfer first KEGG annotation\n",
    "                predictions[locus] = list(all_train_kegg[other_org][other_locus])[0]\n",
    "                break\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline: Domain-Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_predict(org_id, test_loci, train_kegg, domains_df):\n",
    "    \"\"\"Predict KEGG group from domain annotations.\n",
    "    Build domain→KEGG mapping from training genes, apply to test.\"\"\"\n",
    "    if domains_df is None or len(domains_df) == 0:\n",
    "        return {}\n",
    "    \n",
    "    domains_df['locusId'] = domains_df['locusId'].astype(str)\n",
    "    \n",
    "    # Build domain → KEGG mapping from training genes\n",
    "    domain_kegg = {}\n",
    "    for locus, kegg_groups in train_kegg.items():\n",
    "        gene_domains = domains_df[domains_df['locusId'] == locus]['domainId'].tolist()\n",
    "        for dom in gene_domains:\n",
    "            if dom not in domain_kegg:\n",
    "                domain_kegg[dom] = Counter()\n",
    "            for kg in kegg_groups:\n",
    "                domain_kegg[dom][kg] += 1\n",
    "    \n",
    "    # Predict test genes\n",
    "    predictions = {}\n",
    "    for locus in test_loci:\n",
    "        gene_domains = domains_df[domains_df['locusId'] == locus]['domainId'].tolist()\n",
    "        kegg_votes = Counter()\n",
    "        for dom in gene_domains:\n",
    "            if dom in domain_kegg:\n",
    "                kegg_votes.update(domain_kegg[dom])\n",
    "        if kegg_votes:\n",
    "            predictions[locus] = kegg_votes.most_common(1)[0][0]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run All Methods & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shared data\n",
    "bbh_file = ORTHO_DIR / 'pilot_bbh_pairs.csv'\n",
    "bbh_pairs = pd.read_csv(bbh_file) if bbh_file.exists() else pd.DataFrame()\n",
    "\n",
    "results = []\n",
    "\n",
    "for org_id in pilot_ids:\n",
    "    if org_id not in test_genes:\n",
    "        continue\n",
    "    \n",
    "    test_loci = list(test_genes[org_id].keys())\n",
    "    true_labels = test_genes[org_id]  # dict: locus → set of KEGG groups\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{org_id}: {len(test_loci)} test genes\")\n",
    "    \n",
    "    # Load data\n",
    "    membership = pd.read_csv(MODULE_DIR / f'{org_id}_gene_membership.csv', index_col=0)\n",
    "    weights = pd.read_csv(MODULE_DIR / f'{org_id}_gene_weights.csv', index_col=0)\n",
    "    kegg = pd.read_csv(ANNOT_DIR / f'{org_id}_kegg.csv')\n",
    "    domain_file = ANNOT_DIR / f'{org_id}_domains.csv'\n",
    "    domains = pd.read_csv(domain_file) if domain_file.exists() else None\n",
    "    \n",
    "    methods = {\n",
    "        'Module-ICA': module_predict(org_id, test_loci, train_genes[org_id],\n",
    "                                     membership, weights, kegg),\n",
    "        'Cofitness': cofit_predict(org_id, test_loci, train_genes[org_id]),\n",
    "        'Ortholog': ortholog_predict(org_id, test_loci, train_genes, bbh_pairs),\n",
    "        'Domain': domain_predict(org_id, test_loci, train_genes[org_id], domains),\n",
    "    }\n",
    "    \n",
    "    for method_name, preds in methods.items():\n",
    "        if not preds:\n",
    "            print(f\"  {method_name}: no predictions\")\n",
    "            continue\n",
    "        \n",
    "        # Evaluate: is predicted KEGG group in gene's true set?\n",
    "        n_correct = 0\n",
    "        n_predicted = 0\n",
    "        for locus, pred_kg in preds.items():\n",
    "            if locus in true_labels:\n",
    "                n_predicted += 1\n",
    "                if pred_kg in true_labels[locus]:\n",
    "                    n_correct += 1\n",
    "        \n",
    "        precision = n_correct / n_predicted if n_predicted > 0 else 0\n",
    "        coverage = n_predicted / len(test_loci)\n",
    "        \n",
    "        results.append({\n",
    "            'orgId': org_id,\n",
    "            'method': method_name,\n",
    "            'n_test': len(test_loci),\n",
    "            'n_predicted': n_predicted,\n",
    "            'n_correct': n_correct,\n",
    "            'precision': precision,\n",
    "            'coverage': coverage\n",
    "        })\n",
    "        print(f\"  {method_name}: precision={precision:.3f}, coverage={coverage:.3f} \"\n",
    "              f\"({n_correct}/{n_predicted} correct, {n_predicted}/{len(test_loci)} covered)\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(PRED_DIR / 'benchmark_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across organisms\n",
    "agg = results_df.groupby('method').agg(\n",
    "    mean_precision=('precision', 'mean'),\n",
    "    std_precision=('precision', 'std'),\n",
    "    mean_coverage=('coverage', 'mean'),\n",
    "    total_correct=('n_correct', 'sum'),\n",
    "    total_predicted=('n_predicted', 'sum')\n",
    ").reset_index()\n",
    "agg['overall_precision'] = agg['total_correct'] / agg['total_predicted']\n",
    "\n",
    "print(\"\\nAggregate Results:\")\n",
    "print(agg.to_string(index=False))\n",
    "\n",
    "# Bar chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "methods_order = ['Module-ICA', 'Cofitness', 'Ortholog', 'Domain']\n",
    "colors = ['#2196F3', '#FF9800', '#4CAF50', '#9C27B0']\n",
    "\n",
    "# Precision\n",
    "for i, method in enumerate(methods_order):\n",
    "    row = agg[agg['method'] == method]\n",
    "    if len(row) > 0:\n",
    "        ax1.bar(i, row['mean_precision'].values[0], color=colors[i],\n",
    "                yerr=row['std_precision'].values[0], capsize=5)\n",
    "ax1.set_xticks(range(len(methods_order)))\n",
    "ax1.set_xticklabels(methods_order, rotation=30, ha='right')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('KEGG Group Prediction Precision')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Coverage\n",
    "for i, method in enumerate(methods_order):\n",
    "    row = agg[agg['method'] == method]\n",
    "    if len(row) > 0:\n",
    "        ax2.bar(i, row['mean_coverage'].values[0], color=colors[i])\n",
    "ax2.set_xticks(range(len(methods_order)))\n",
    "ax2.set_xticklabels(methods_order, rotation=30, ha='right')\n",
    "ax2.set_ylabel('Coverage')\n",
    "ax2.set_title('Prediction Coverage (fraction of test genes)')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'benchmark_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validation: Within-Module Cofitness Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that module genes are more cofit than random gene pairs\n",
    "for org_id in pilot_ids:\n",
    "    fit_file = DATA_DIR / 'matrices' / f'{org_id}_fitness_matrix.csv'\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    \n",
    "    if not fit_file.exists() or not member_file.exists():\n",
    "        continue\n",
    "    \n",
    "    fit_matrix = pd.read_csv(fit_file, index_col=0)\n",
    "    membership = pd.read_csv(member_file, index_col=0)\n",
    "    \n",
    "    # Compute correlation matrix (subsample for speed)\n",
    "    n_sample = min(500, len(fit_matrix))\n",
    "    sample_idx = np.random.choice(len(fit_matrix), n_sample, replace=False)\n",
    "    sample_corr = np.corrcoef(fit_matrix.values[sample_idx])\n",
    "    \n",
    "    # Within-module vs random correlations\n",
    "    within_corrs = []\n",
    "    for mod in membership.columns:\n",
    "        mod_genes = membership.index[membership[mod] == 1]\n",
    "        mod_idx = [i for i, g in enumerate(fit_matrix.index[sample_idx])\n",
    "                   if g in mod_genes.values]\n",
    "        if len(mod_idx) >= 2:\n",
    "            for i in range(len(mod_idx)):\n",
    "                for j in range(i+1, len(mod_idx)):\n",
    "                    within_corrs.append(sample_corr[mod_idx[i], mod_idx[j]])\n",
    "    \n",
    "    # Random pairs\n",
    "    random_corrs = []\n",
    "    for _ in range(len(within_corrs)):\n",
    "        i, j = np.random.choice(n_sample, 2, replace=False)\n",
    "        random_corrs.append(sample_corr[i, j])\n",
    "    \n",
    "    if within_corrs and random_corrs:\n",
    "        print(f\"{org_id}:\")\n",
    "        print(f\"  Within-module cofitness: mean={np.mean(within_corrs):.3f}, \"\n",
    "              f\"median={np.median(within_corrs):.3f} (n={len(within_corrs)})\")\n",
    "        print(f\"  Random pairs cofitness: mean={np.mean(random_corrs):.3f}, \"\n",
    "              f\"median={np.median(random_corrs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validation: Genomic Adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if module members show elevated genomic proximity (operon-like)\n",
    "for org_id in pilot_ids:\n",
    "    gene_file = ANNOT_DIR / f'{org_id}_genes.csv'\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    \n",
    "    if not gene_file.exists() or not member_file.exists():\n",
    "        continue\n",
    "    \n",
    "    genes = pd.read_csv(gene_file)\n",
    "    genes['locusId'] = genes['locusId'].astype(str)\n",
    "    membership = pd.read_csv(member_file, index_col=0)\n",
    "    membership.index = membership.index.astype(str)\n",
    "    \n",
    "    # Sort genes by genomic position\n",
    "    genes = genes.sort_values(['scaffoldId', 'begin'])\n",
    "    genes['gene_order'] = range(len(genes))\n",
    "    locus_to_order = dict(zip(genes['locusId'], genes['gene_order']))\n",
    "    \n",
    "    # Count adjacent pairs within modules vs expected by chance\n",
    "    n_adjacent_within = 0\n",
    "    n_pairs_within = 0\n",
    "    \n",
    "    for mod in membership.columns:\n",
    "        mod_genes = membership.index[membership[mod] == 1].tolist()\n",
    "        orders = sorted([locus_to_order[g] for g in mod_genes if g in locus_to_order])\n",
    "        \n",
    "        for i in range(len(orders)):\n",
    "            for j in range(i+1, len(orders)):\n",
    "                n_pairs_within += 1\n",
    "                if abs(orders[i] - orders[j]) <= 3:  # within 3 genes\n",
    "                    n_adjacent_within += 1\n",
    "    \n",
    "    # Expected adjacency by chance\n",
    "    n_total_genes = len(genes)\n",
    "    expected_adj_rate = 6 / n_total_genes  # ±3 neighbors out of N genes\n",
    "    \n",
    "    if n_pairs_within > 0:\n",
    "        observed_rate = n_adjacent_within / n_pairs_within\n",
    "        enrichment = observed_rate / expected_adj_rate if expected_adj_rate > 0 else 0\n",
    "        print(f\"{org_id}: adjacency enrichment = {enrichment:.1f}× \"\n",
    "              f\"(observed={observed_rate:.4f}, expected={expected_adj_rate:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BENCHMARKING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Results saved: {PRED_DIR / 'benchmark_results.csv'}\")\n",
    "print(f\"Figure saved: {FIG_DIR / 'benchmark_comparison.png'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
