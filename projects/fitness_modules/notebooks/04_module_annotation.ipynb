{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 04: Module Functional Annotation\n",
    "\n",
    "Label each ICA module with biological function using enrichment analysis.\n",
    "\n",
    "**Part 1 (JupyterHub)**: Extract KEGG, SEED, domain, and specific phenotype\n",
    "annotations from Spark.\n",
    "\n",
    "**Part 2 (local)**: Fisher exact test enrichment for each module.\n",
    "\n",
    "Run Part 1 on JupyterHub first, then Part 2 can run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy import stats as scipy_stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "ANNOT_DIR = DATA_DIR / 'annotations'\n",
    "MODULE_DIR = DATA_DIR / 'modules'\n",
    "ANNOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Extract Annotations from Spark\n",
    "\n",
    "**Run this section on JupyterHub.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark (comment out if running Part 2 locally)\n",
    "try:\n",
    "    spark = get_spark_session()\n",
    "    HAS_SPARK = True\n",
    "    print(f\"Spark version: {spark.version}\")\n",
    "except Exception:\n",
    "    HAS_SPARK = False\n",
    "    print(\"No Spark available — running Part 2 only (local mode)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPARK:\n",
    "    for org_id in pilot_ids:\n",
    "        # KEGG annotations\n",
    "        kegg_file = ANNOT_DIR / f'{org_id}_kegg.csv'\n",
    "        if not (kegg_file.exists() and kegg_file.stat().st_size > 0):\n",
    "            kegg = spark.sql(f\"\"\"\n",
    "                SELECT km.locusId, km.kgroup, kd.desc as kgroup_desc,\n",
    "                       ke.ec\n",
    "                FROM kescience_fitnessbrowser.keggmember km\n",
    "                LEFT JOIN kescience_fitnessbrowser.kgroupdesc kd\n",
    "                    ON km.kgroup = kd.kgroup\n",
    "                LEFT JOIN kescience_fitnessbrowser.kgroupec ke\n",
    "                    ON km.kgroup = ke.kgroup\n",
    "                WHERE km.orgId = '{org_id}'\n",
    "            \"\"\").toPandas()\n",
    "            kegg.to_csv(kegg_file, index=False)\n",
    "            print(f\"KEGG: {org_id} — {len(kegg)} annotations\")\n",
    "        else:\n",
    "            print(f\"CACHED: {org_id} KEGG\")\n",
    "\n",
    "        # SEED annotations\n",
    "        seed_file = ANNOT_DIR / f'{org_id}_seed.csv'\n",
    "        if not (seed_file.exists() and seed_file.stat().st_size > 0):\n",
    "            seed = spark.sql(f\"\"\"\n",
    "                SELECT sa.locusId, sa.seed_desc,\n",
    "                       sc.subsystem, sc.category1, sc.category2, sc.category3\n",
    "                FROM kescience_fitnessbrowser.seedannotation sa\n",
    "                LEFT JOIN kescience_fitnessbrowser.seedclass sc\n",
    "                    ON sa.seed_desc = sc.seed_desc\n",
    "                WHERE sa.orgId = '{org_id}'\n",
    "            \"\"\").toPandas()\n",
    "            seed.to_csv(seed_file, index=False)\n",
    "            print(f\"SEED: {org_id} — {len(seed)} annotations\")\n",
    "        else:\n",
    "            print(f\"CACHED: {org_id} SEED\")\n",
    "\n",
    "        # Domain annotations\n",
    "        domain_file = ANNOT_DIR / f'{org_id}_domains.csv'\n",
    "        if not (domain_file.exists() and domain_file.stat().st_size > 0):\n",
    "            domains = spark.sql(f\"\"\"\n",
    "                SELECT locusId, domainDb, domainId, domainName,\n",
    "                       definition, geneSymbol, ec\n",
    "                FROM kescience_fitnessbrowser.genedomain\n",
    "                WHERE orgId = '{org_id}'\n",
    "            \"\"\").toPandas()\n",
    "            domains.to_csv(domain_file, index=False)\n",
    "            print(f\"Domains: {org_id} — {len(domains)} annotations\")\n",
    "        else:\n",
    "            print(f\"CACHED: {org_id} domains\")\n",
    "\n",
    "        # Specific phenotypes\n",
    "        pheno_file = ANNOT_DIR / f'{org_id}_specific_phenotypes.csv'\n",
    "        if not (pheno_file.exists() and pheno_file.stat().st_size > 0):\n",
    "            pheno = spark.sql(f\"\"\"\n",
    "                SELECT sp.locusId, sp.expName,\n",
    "                       e.expDesc, e.expGroup, e.condition_1\n",
    "                FROM kescience_fitnessbrowser.specificphenotype sp\n",
    "                JOIN kescience_fitnessbrowser.experiment e\n",
    "                    ON sp.orgId = e.orgId AND sp.expName = e.expName\n",
    "                WHERE sp.orgId = '{org_id}'\n",
    "            \"\"\").toPandas()\n",
    "            pheno.to_csv(pheno_file, index=False)\n",
    "            print(f\"Phenotypes: {org_id} — {len(pheno)} entries\")\n",
    "        else:\n",
    "            print(f\"CACHED: {org_id} phenotypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Enrichment Analysis\n",
    "\n",
    "Fisher exact test for each annotation term vs module membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_analysis(module_genes, all_genes, annotation_map, min_annotated=3):\n",
    "    \"\"\"Fisher exact test enrichment for a single module.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    module_genes : set\n",
    "        Genes in the module.\n",
    "    all_genes : set\n",
    "        All genes in the organism.\n",
    "    annotation_map : dict\n",
    "        {term: set_of_genes} mapping.\n",
    "    min_annotated : int\n",
    "        Minimum annotated genes in module for testing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : list of dict\n",
    "        Enrichment results per term.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n_total = len(all_genes)\n",
    "    n_module = len(module_genes)\n",
    "    \n",
    "    for term, term_genes in annotation_map.items():\n",
    "        term_genes = term_genes & all_genes  # intersect with valid genes\n",
    "        overlap = module_genes & term_genes\n",
    "        \n",
    "        if len(overlap) < min_annotated:\n",
    "            continue\n",
    "        \n",
    "        # 2x2 contingency table\n",
    "        a = len(overlap)                          # in module AND annotated\n",
    "        b = len(module_genes - term_genes)         # in module NOT annotated\n",
    "        c = len(term_genes - module_genes)          # NOT in module but annotated\n",
    "        d = n_total - len(module_genes | term_genes)  # neither\n",
    "        \n",
    "        odds_ratio, p_value = scipy_stats.fisher_exact([[a, b], [c, d]],\n",
    "                                                        alternative='greater')\n",
    "        results.append({\n",
    "            'term': term,\n",
    "            'n_overlap': a,\n",
    "            'n_module': n_module,\n",
    "            'n_term': len(term_genes),\n",
    "            'odds_ratio': odds_ratio,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for org_id in pilot_ids:\n",
    "    out_file = MODULE_DIR / f'{org_id}_module_annotations.csv'\n",
    "    cond_file = MODULE_DIR / f'{org_id}_module_conditions.csv'\n",
    "    \n",
    "    if out_file.exists() and out_file.stat().st_size > 0:\n",
    "        print(f\"CACHED: {org_id} annotations\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nAnnotating {org_id} modules...\")\n",
    "    \n",
    "    # Load membership\n",
    "    membership = pd.read_csv(MODULE_DIR / f'{org_id}_gene_membership.csv', index_col=0)\n",
    "    all_genes = set(membership.index.astype(str))\n",
    "    module_names = membership.columns.tolist()\n",
    "    \n",
    "    # Load annotations and build term->gene maps\n",
    "    annotation_maps = {}\n",
    "    \n",
    "    # KEGG\n",
    "    kegg_file = ANNOT_DIR / f'{org_id}_kegg.csv'\n",
    "    if kegg_file.exists():\n",
    "        kegg = pd.read_csv(kegg_file)\n",
    "        kegg_map = kegg.groupby('kgroup')['locusId'].apply(lambda x: set(x.astype(str))).to_dict()\n",
    "        annotation_maps['KEGG'] = kegg_map\n",
    "    \n",
    "    # SEED\n",
    "    seed_file = ANNOT_DIR / f'{org_id}_seed.csv'\n",
    "    if seed_file.exists():\n",
    "        seed = pd.read_csv(seed_file)\n",
    "        if 'subsystem' in seed.columns:\n",
    "            seed_map = seed.dropna(subset=['subsystem']).groupby('subsystem')['locusId'].apply(\n",
    "                lambda x: set(x.astype(str))).to_dict()\n",
    "            annotation_maps['SEED'] = seed_map\n",
    "    \n",
    "    # Domains (TIGRFam)\n",
    "    domain_file = ANNOT_DIR / f'{org_id}_domains.csv'\n",
    "    if domain_file.exists():\n",
    "        domains = pd.read_csv(domain_file)\n",
    "        tigr = domains[domains['domainDb'] == 'TIGRFam']\n",
    "        if len(tigr) > 0:\n",
    "            tigr_map = tigr.groupby('domainId')['locusId'].apply(\n",
    "                lambda x: set(x.astype(str))).to_dict()\n",
    "            annotation_maps['TIGRFam'] = tigr_map\n",
    "    \n",
    "    # Run enrichment for each module\n",
    "    all_results = []\n",
    "    for mod in module_names:\n",
    "        mod_genes = set(membership.index[membership[mod] == 1].astype(str))\n",
    "        if len(mod_genes) == 0:\n",
    "            continue\n",
    "        \n",
    "        for db_name, term_map in annotation_maps.items():\n",
    "            results = enrichment_analysis(mod_genes, all_genes, term_map)\n",
    "            for r in results:\n",
    "                r['module'] = mod\n",
    "                r['database'] = db_name\n",
    "            all_results.extend(results)\n",
    "    \n",
    "    if all_results:\n",
    "        enrich_df = pd.DataFrame(all_results)\n",
    "        # FDR correction\n",
    "        reject, fdr, _, _ = multipletests(enrich_df['p_value'], method='fdr_bh')\n",
    "        enrich_df['fdr'] = fdr\n",
    "        enrich_df['significant'] = reject\n",
    "        enrich_df = enrich_df.sort_values(['module', 'fdr'])\n",
    "        enrich_df.to_csv(out_file, index=False)\n",
    "        \n",
    "        n_sig = enrich_df['significant'].sum()\n",
    "        n_modules_annotated = enrich_df[enrich_df['significant']]['module'].nunique()\n",
    "        print(f\"  {n_sig} significant enrichments across {n_modules_annotated} modules\")\n",
    "    else:\n",
    "        print(f\"  No enrichments found\")\n",
    "    \n",
    "    # Map module activity to experiment conditions\n",
    "    profiles = pd.read_csv(MODULE_DIR / f'{org_id}_module_profiles.csv', index_col=0)\n",
    "    exp_meta = pd.read_csv(ANNOT_DIR / f'{org_id}_experiments.csv')\n",
    "    \n",
    "    condition_results = []\n",
    "    for mod in profiles.index:\n",
    "        activity = profiles.loc[mod]\n",
    "        # Top 5 most activated experiments\n",
    "        top_activated = activity.abs().nlargest(5)\n",
    "        for exp_name, act_value in top_activated.items():\n",
    "            exp_info = exp_meta[exp_meta['expName'] == exp_name]\n",
    "            if len(exp_info) > 0:\n",
    "                condition_results.append({\n",
    "                    'module': mod,\n",
    "                    'expName': exp_name,\n",
    "                    'activity': float(activity[exp_name]),\n",
    "                    'abs_activity': float(act_value),\n",
    "                    'expDesc': exp_info.iloc[0].get('expDesc', ''),\n",
    "                    'expGroup': exp_info.iloc[0].get('expGroup', ''),\n",
    "                    'condition_1': exp_info.iloc[0].get('condition_1', '')\n",
    "                })\n",
    "    \n",
    "    if condition_results:\n",
    "        cond_df = pd.DataFrame(condition_results)\n",
    "        cond_df.to_csv(cond_file, index=False)\n",
    "        print(f\"  Saved condition mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: top enrichments per organism\n",
    "for org_id in pilot_ids:\n",
    "    ann_file = MODULE_DIR / f'{org_id}_module_annotations.csv'\n",
    "    if not ann_file.exists():\n",
    "        continue\n",
    "    ann = pd.read_csv(ann_file)\n",
    "    sig = ann[ann['significant']]\n",
    "    print(f\"\\n{org_id}: {len(sig)} significant enrichments\")\n",
    "    # Show top enrichment per module\n",
    "    top = sig.groupby('module').first().reset_index()\n",
    "    if len(top) > 0:\n",
    "        print(top[['module', 'database', 'term', 'n_overlap', 'odds_ratio', 'fdr']].head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
