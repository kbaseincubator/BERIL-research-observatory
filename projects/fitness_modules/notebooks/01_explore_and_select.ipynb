{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 01: Explore Fitness Browser & Select Pilot Organisms\n",
    "\n",
    "Survey all 48 organisms in the Fitness Browser to select ~5 pilot organisms\n",
    "for ICA module decomposition. Selection based on:\n",
    "- Number of experiments (primary)\n",
    "- Number of genes\n",
    "- Ortholog connectivity\n",
    "- Data quality (cor12, mad12)\n",
    "\n",
    "**Run on BERDL JupyterHub** for Spark access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark_session()\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Organism Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all organisms\n",
    "organisms = spark.sql(\"\"\"\n",
    "    SELECT orgId, division, genus, species, strain, taxonomyId\n",
    "    FROM kescience_fitnessbrowser.organism\n",
    "    ORDER BY genus, species\n",
    "\"\"\").toPandas()\n",
    "print(f\"Total organisms: {len(organisms)}\")\n",
    "organisms.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Counts per Organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count experiments per organism\n",
    "exp_counts = spark.sql(\"\"\"\n",
    "    SELECT orgId,\n",
    "           COUNT(*) as n_experiments,\n",
    "           COUNT(DISTINCT expGroup) as n_exp_groups,\n",
    "           COUNT(DISTINCT condition_1) as n_conditions\n",
    "    FROM kescience_fitnessbrowser.experiment\n",
    "    GROUP BY orgId\n",
    "    ORDER BY n_experiments DESC\n",
    "\"\"\").toPandas()\n",
    "print(f\"Organisms with experiments: {len(exp_counts)}\")\n",
    "exp_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gene Counts per Organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count genes per organism\n",
    "gene_counts = spark.sql(\"\"\"\n",
    "    SELECT orgId,\n",
    "           COUNT(*) as n_genes,\n",
    "           SUM(CASE WHEN desc LIKE '%hypothetical%' OR desc LIKE '%uncharacterized%'\n",
    "               THEN 1 ELSE 0 END) as n_hypothetical\n",
    "    FROM kescience_fitnessbrowser.gene\n",
    "    GROUP BY orgId\n",
    "    ORDER BY n_genes DESC\n",
    "\"\"\").toPandas()\n",
    "gene_counts['pct_hypothetical'] = (gene_counts['n_hypothetical'] / gene_counts['n_genes'] * 100).round(1)\n",
    "print(f\"Organisms with genes: {len(gene_counts)}\")\n",
    "gene_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC metrics per organism\n",
    "qc_metrics = spark.sql(\"\"\"\n",
    "    SELECT orgId,\n",
    "           AVG(CAST(cor12 AS FLOAT)) as mean_cor12,\n",
    "           AVG(CAST(mad12 AS FLOAT)) as mean_mad12,\n",
    "           MIN(CAST(cor12 AS FLOAT)) as min_cor12,\n",
    "           SUM(CASE WHEN CAST(cor12 AS FLOAT) >= 0.1 THEN 1 ELSE 0 END) as n_good_experiments\n",
    "    FROM kescience_fitnessbrowser.experiment\n",
    "    WHERE cor12 IS NOT NULL\n",
    "    GROUP BY orgId\n",
    "    ORDER BY mean_cor12 DESC\n",
    "\"\"\").toPandas()\n",
    "print(f\"Organisms with QC data: {len(qc_metrics)}\")\n",
    "qc_metrics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ortholog Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ortholog connectivity: how many other organisms does each organism connect to?\n",
    "ortholog_conn = spark.sql(\"\"\"\n",
    "    SELECT orgId1,\n",
    "           COUNT(DISTINCT orgId2) as n_ortholog_partners,\n",
    "           COUNT(*) as n_ortholog_pairs\n",
    "    FROM kescience_fitnessbrowser.ortholog\n",
    "    GROUP BY orgId1\n",
    "    ORDER BY n_ortholog_partners DESC\n",
    "\"\"\").toPandas()\n",
    "ortholog_conn.columns = ['orgId', 'n_ortholog_partners', 'n_ortholog_pairs']\n",
    "print(f\"Organisms with orthologs: {len(ortholog_conn)}\")\n",
    "ortholog_conn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Probe fitbyexp Table Schema\n",
    "\n",
    "Check the structure of pre-pivoted fitness tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fitbyexp tables\n",
    "tables = spark.sql(\"SHOW TABLES IN kescience_fitnessbrowser\").toPandas()\n",
    "fitbyexp_tables = tables[tables['tableName'].str.startswith('fitbyexp_')]\n",
    "print(f\"fitbyexp tables: {len(fitbyexp_tables)}\")\n",
    "print(fitbyexp_tables['tableName'].tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe one fitbyexp table schema (using the first one found)\n",
    "if len(fitbyexp_tables) > 0:\n",
    "    sample_table = fitbyexp_tables['tableName'].iloc[0]\n",
    "    schema = spark.sql(f\"DESCRIBE kescience_fitnessbrowser.{sample_table}\").toPandas()\n",
    "    print(f\"Schema for {sample_table}:\")\n",
    "    print(f\"  Total columns: {len(schema)}\")\n",
    "    print(f\"  First 5 columns: {schema['col_name'].head().tolist()}\")\n",
    "    print(f\"  Last 5 columns: {schema['col_name'].tail().tolist()}\")\n",
    "    \n",
    "    # Sample a few rows\n",
    "    sample = spark.sql(f\"SELECT * FROM kescience_fitnessbrowser.{sample_table} LIMIT 3\").toPandas()\n",
    "    print(f\"\\nSample rows shape: {sample.shape}\")\n",
    "    print(sample.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Combined Statistics & Select Pilots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all statistics\n",
    "stats = organisms.merge(exp_counts, on='orgId', how='left')\n",
    "stats = stats.merge(gene_counts, on='orgId', how='left')\n",
    "stats = stats.merge(qc_metrics, on='orgId', how='left')\n",
    "stats = stats.merge(ortholog_conn, on='orgId', how='left')\n",
    "\n",
    "# Fill NaN for organisms missing data\n",
    "stats = stats.fillna(0)\n",
    "\n",
    "# Composite score for pilot selection\n",
    "# Normalize each metric to [0, 1] and weight\n",
    "for col in ['n_experiments', 'n_genes', 'n_ortholog_partners', 'mean_cor12']:\n",
    "    col_max = stats[col].max()\n",
    "    if col_max > 0:\n",
    "        stats[f'{col}_norm'] = stats[col] / col_max\n",
    "    else:\n",
    "        stats[f'{col}_norm'] = 0\n",
    "\n",
    "# Weighted composite: experiments most important\n",
    "stats['composite_score'] = (\n",
    "    0.40 * stats['n_experiments_norm'] +\n",
    "    0.20 * stats['n_genes_norm'] +\n",
    "    0.20 * stats['n_ortholog_partners_norm'] +\n",
    "    0.20 * stats['mean_cor12_norm']\n",
    ")\n",
    "\n",
    "stats = stats.sort_values('composite_score', ascending=False)\n",
    "print(\"\\nTop 10 organisms by composite score:\")\n",
    "display_cols = ['orgId', 'genus', 'species', 'strain', 'n_experiments',\n",
    "                'n_genes', 'n_ortholog_partners', 'mean_cor12', 'composite_score']\n",
    "stats[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 as pilot organisms\n",
    "n_pilots = 5\n",
    "pilots = stats.head(n_pilots).copy()\n",
    "print(f\"\\nSelected {n_pilots} pilot organisms:\")\n",
    "for _, row in pilots.iterrows():\n",
    "    print(f\"  {row['orgId']:20s} {row['genus']} {row['species']} {row['strain']}\")\n",
    "    print(f\"    Experiments: {int(row['n_experiments'])}, Genes: {int(row['n_genes'])}, \"\n",
    "          f\"Ortholog partners: {int(row['n_ortholog_partners'])}, \"\n",
    "          f\"Mean cor12: {row['mean_cor12']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save organism statistics\n",
    "out_stats = DATA_DIR / 'organism_stats.csv'\n",
    "stats.to_csv(out_stats, index=False)\n",
    "print(f\"Saved: {out_stats} ({len(stats)} organisms)\")\n",
    "\n",
    "# Save pilot organism list\n",
    "out_pilots = DATA_DIR / 'pilot_organisms.csv'\n",
    "pilots.to_csv(out_pilots, index=False)\n",
    "print(f\"Saved: {out_pilots} ({len(pilots)} pilots)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total organisms: {len(stats)}\")\n",
    "print(f\"Total experiments: {int(stats['n_experiments'].sum())}\")\n",
    "print(f\"Total genes: {int(stats['n_genes'].sum())}\")\n",
    "print(f\"Pilot organisms: {pilots['orgId'].tolist()}\")\n",
    "print(f\"Pilot experiment range: {int(pilots['n_experiments'].min())}-{int(pilots['n_experiments'].max())}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
