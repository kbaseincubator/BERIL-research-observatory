---
reviewer: BERIL Automated Review
date: 2026-02-16
project: enigma_contamination_functional_potential
---

# Review: Contamination Gradient vs Functional Potential in ENIGMA Communities

## Summary
This project is well-scoped, reproducible, and generally methodologically careful: the research question is explicit, notebook flow is coherent, outputs are saved, and conclusions in `REPORT.md` match the generated result tables and figures. The strongest findings are appropriately framed as sensitivity-model dependent rather than definitive. Main improvement areas are statistical inference rigor for multiple comparisons and clearer handling/quantification of mapping uncertainty from large unmapped genus fractions.

## Methodology
The question and hypotheses are clearly stated in `README.md` and `RESEARCH_PLAN.md`, and data sources are documented with specific ENIGMA and pangenome tables. The notebook progression is logical: extraction/QC (`notebooks/01_enigma_extraction_qc.ipynb`), taxonomy bridge + feature construction (`notebooks/02_taxonomy_bridge_functional_features.ipynb`), then modeling (`notebooks/03_contamination_functional_models.ipynb`).

Reproducibility is strong: the README has a dedicated `## Reproduction` section with execution order, Spark-vs-local guidance, dependencies, and expected artifacts. All three notebooks contain executed code with saved outputs (NB03 includes two intentionally comment-only code cells with no outputs). Data and figures expected by the README/REPORT are present and consistent with notebook logs.

Methodologically, strict-vs-relaxed mapping is now implemented independently in NB02 (strict clade selection vs all clades), and downstream mode-specific modeling in NB03 uses those separate features. The main design limitation remains biological resolution and mapping coverage: 862/1392 genera are unmapped in `data/taxon_bridge.tsv`, so inference is conditional on mapped taxa and coverage-weighted sensitivity analyses.

## Code Quality
Code quality is solid for notebook-style analysis. NB01 keeps heavy aggregation in Spark before `.toPandas()`, reducing driver-memory risk. Numeric casting is explicit where needed (consistent with ENIGMA string-typed field pitfalls). NB02 uses the documented join key (`gene_cluster.gene_cluster_id` to `eggnog_mapper_annotations.query_name`), avoiding a common BERDL pitfall. NB03 includes defensive checks for insufficient sample size/constant outcomes and records status fields in `data/model_results.tsv`.

No clear runtime or logic bugs were found in the executed paths. One analytical quality risk is inference multiplicity: many p-values are reported across outcomes, mapping modes, and sensitivity models, but there is no explicit multiple-testing correction or pre-specified primary endpoint hierarchy in notebook outputs.

## Findings Assessment
`REPORT.md` is consistent with generated artifacts. Claims about null primary univariate associations, significant coverage-adjusted defense associations, high-coverage subset signals, and sample/row counts match `data/model_results.tsv`, `data/site_functional_scores.tsv`, and notebook outputs. Figures in `figures/` are present and aligned with report descriptions.

Interpretation is appropriately cautious and limitations are explicitly acknowledged (genus-level abstraction, coarse COG proxies, incomplete mapping, and site-structure simplification). This is a credible and transparent presentation of conditional evidence rather than over-claiming causality.

## Suggestions
1. [High] Add multiple-testing control (for example Benjamini-Hochberg FDR) across the family of outcome/mode/sensitivity tests, and report both raw and adjusted p-values in `data/model_results.tsv` and `REPORT.md`.
2. [High] Pre-specify and label confirmatory vs exploratory analyses in NB03 (for example, designate primary endpoint/model), so significance claims are less vulnerable to model-selection bias.
3. [High] Quantify mapping uncertainty more directly: add analyses that model effect size as a function of `mapped_abundance_fraction` or report partial dependence/interaction with contamination, not only thresholded high-coverage subsets.
4. [Medium] Add uncertainty intervals (for example bootstrap CIs) for key contamination coefficients/correlations in the report tables to complement p-values.
5. [Medium] Extend site-structure modeling beyond `location_prefix` where feasible (for example mixed effects with location-level random intercepts) to better capture clustered sampling.

## Review Metadata
- **Reviewer**: BERIL Automated Review
- **Date**: 2026-02-16
- **Scope**: README.md, 3 notebooks, 7 data files, 3 figures
- **Note**: This review was generated by an AI system. It should be treated as advisory input, not a definitive assessment.
