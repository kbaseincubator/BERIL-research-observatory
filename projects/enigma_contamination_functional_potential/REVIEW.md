---
reviewer: BERIL Automated Review
date: 2026-02-16
project: enigma_contamination_functional_potential
---

# Review: Contamination Gradient vs Functional Potential in ENIGMA Communities

## Summary
This project is well organized and reproducible end-to-end, with clear research framing, complete saved notebook outputs, explicit data artifacts, and a cautious interpretation of mostly null associations. The biggest limitation is methodological: the planned strict-vs-relaxed mapping sensitivity is not independently implemented in the current rerun because relaxed-mode functional features are copied from strict mode in NB02, making downstream mode-level comparisons non-informative.

## Methodology
The research question and hypotheses are clearly stated in `README.md` and `RESEARCH_PLAN.md`, and data sources are explicitly identified across ENIGMA and pangenome tables. The notebook sequence is coherent (`01` extraction/QC, `02` bridge/features, `03` modeling), and the README includes a practical reproduction section with Spark-vs-local execution guidance and dependency specification (`requirements.txt`). Model construction in `notebooks/03_contamination_functional_models.ipynb` includes both univariate tests and an adjusted OLS term set (`depth_meter`, `latitude_degree`, `longitude_degree`), which aligns with the stated need for confounder control at a basic level.

The main methodology gap is that mapping-mode sensitivity cannot currently answer its intended question: `notebooks/02_taxonomy_bridge_functional_features.ipynb` explicitly sets relaxed features by copying strict features (`feats_relaxed = feats_strict.copy()`), so the two mapping modes are analytically identical in downstream outputs.

## Code Quality
Notebook code is generally clean and logically staged. In NB01, heavy aggregation is correctly kept in Spark before collection, and numeric parsing/casting is explicit for potentially string-typed values (consistent with `docs/pitfalls.md`). In NB02, the annotation join uses the documented key (`gene_cluster_id` to `query_name`), avoiding a common BERDL pitfall. In NB03, checks for low-sample and low-variance outcomes are present and prevent invalid inference paths.

No direct syntax/runtime bugs are evident in the reviewed executed paths. The principal quality risk is analytical rather than mechanical: mode-comparison logic is present, but feature construction currently bypasses true relaxed-mode computation.

## Findings Assessment
`REPORT.md` is consistent with generated outputs (`data/model_results.tsv`, `data/site_functional_scores.tsv`) and does not overstate significance. The null/weak associations are reported transparently, and key limitations are acknowledged (mapping coverage, genus-level abstraction, coarse COG proxies). Figure artifacts listed in the report are present in `figures/` and align with the described diagnostics.

Notebooks are reproducible from an output-availability perspective: all code cells in NB01 and NB02 have saved outputs, and NB03 has outputs on substantive execution cells (with two intentionally empty comment-only code cells).

## Suggestions
1. [Critical] Implement independent relaxed-mode feature construction in `notebooks/02_taxonomy_bridge_functional_features.ipynb` instead of copying strict-mode features, then rerun NB03 so strict-vs-relaxed comparisons are meaningful.
2. [High] Add a direct sensitivity analysis in NB03 that conditions on `mapped_abundance_fraction` (already computed) or restricts to high-coverage samples, to quantify robustness to unmapped taxa.
3. [High] Expand adjusted modeling beyond coordinates/depth to better represent site structure (for example, clustered or categorical site effects using `sdt_location_name`/region where appropriate).
4. [Medium] Add concise markdown rationale around key assumptions in notebooks (feature definitions, contamination index construction, handling of unmapped taxa) to make auditability stronger without reading full source code.
5. [Medium] Add expected runtime ranges per notebook in the README reproduction section to improve planning for reruns.

## Review Metadata
- **Reviewer**: BERIL Automated Review
- **Date**: 2026-02-16
- **Scope**: README.md, 3 notebooks, 7 data files, 3 figures
- **Note**: This review was generated by an AI system. It should be treated as advisory input, not a definitive assessment.
