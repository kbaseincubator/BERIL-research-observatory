{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Exploration & Characterization\n",
    "\n",
    "This notebook explores the available data for analyzing relationships between:\n",
    "- Pangenome openness/closedness\n",
    "- Metabolic pathway completeness (GapMind)\n",
    "- Phylogenetic/structural distances (AlphaEarth, phylogenetic tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import libraries\n# Note: Spark session is pre-initialized in JupyterHub kernel\n# Do NOT use: from get_spark_session import get_spark_session\n# See docs/pitfalls.md for details on JupyterHub environment\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(\"Libraries imported. Spark session is pre-initialized in the JupyterHub kernel.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pangenome Statistics Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic statistics on pangenome table\n",
    "pangenome_stats = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_species,\n",
    "  AVG(no_genomes) as avg_genomes_per_species,\n",
    "  MIN(no_genomes) as min_genomes,\n",
    "  MAX(no_genomes) as max_genomes,\n",
    "  AVG(no_core) as avg_core_genes,\n",
    "  AVG(no_aux_genome) as avg_aux_genes,\n",
    "  AVG(no_singleton_gene_clusters) as avg_singletons,\n",
    "  AVG(no_gene_clusters) as avg_total_clusters\n",
    "FROM kbase_ke_pangenome.pangenome\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"Pangenome Statistics:\")\n",
    "print(pangenome_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Pangenome Openness Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate openness metric for all species\n",
    "pangenome_openness = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  p.gtdb_species_clade_id,\n",
    "  s.GTDB_species,\n",
    "  p.no_genomes,\n",
    "  p.no_core,\n",
    "  p.no_aux_genome,\n",
    "  p.no_singleton_gene_clusters,\n",
    "  p.no_gene_clusters,\n",
    "  (p.no_aux_genome + p.no_singleton_gene_clusters) / p.no_gene_clusters AS openness_score,\n",
    "  1.0 - ((p.no_aux_genome + p.no_singleton_gene_clusters) / p.no_gene_clusters) AS closedness_score,\n",
    "  p.no_core / p.no_gene_clusters AS core_fraction\n",
    "FROM kbase_ke_pangenome.pangenome p\n",
    "JOIN kbase_ke_pangenome.gtdb_species_clade s\n",
    "  ON p.gtdb_species_clade_id = s.gtdb_species_clade_id\n",
    "ORDER BY openness_score DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Calculated openness scores for {len(pangenome_openness)} species\")\n",
    "print(\"\\nOpenness Score Summary:\")\n",
    "print(pangenome_openness[['openness_score', 'closedness_score', 'core_fraction']].describe())\n",
    "print(\"\\nTop 10 Most Open Pangenomes:\")\n",
    "print(pangenome_openness[['GTDB_species', 'no_genomes', 'openness_score', 'core_fraction']].head(10).to_string())\n",
    "print(\"\\nTop 10 Most Closed Pangenomes:\")\n",
    "print(pangenome_openness[['GTDB_species', 'no_genomes', 'openness_score', 'core_fraction']].tail(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GapMind Pathways Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GapMind pathways availability and structure\n",
    "pathways_sample = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_records,\n",
    "  COUNT(DISTINCT genome_id) as genomes_with_pathways,\n",
    "  COUNT(DISTINCT pathway) as unique_pathways\n",
    "FROM kbase_ke_pangenome.gapmind_pathways\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"GapMind Pathways Overview:\")\n",
    "print(pathways_sample.to_string())\n",
    "\n",
    "# Sample of pathways\n",
    "sample_pathways = spark.sql(\"\"\"\n",
    "SELECT DISTINCT pathway\n",
    "FROM kbase_ke_pangenome.gapmind_pathways\n",
    "LIMIT 20\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"\\nSample Pathways:\")\n",
    "for p in sample_pathways['pathway'].values:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pathway Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathway score distribution\n",
    "score_dist = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  score_simplified,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percent\n",
    "FROM kbase_ke_pangenome.gapmind_pathways\n",
    "GROUP BY score_simplified\n",
    "ORDER BY score_simplified\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"\\nPathway Score Distribution:\")\n",
    "print(score_dist.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AlphaEarth Embeddings Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check AlphaEarth embeddings coverage\n# Note: The table contains embedding vectors (A00, A01, A02, ...) not separate year columns\nembeddings_coverage = spark.sql(\"\"\"\nSELECT\n  COUNT(DISTINCT genome_id) as genomes_with_embeddings\nFROM kbase_ke_pangenome.alphaearth_embeddings_all_years\n\"\"\").toPandas()\n\ntotal_genomes = spark.sql(\"\"\"\nSELECT COUNT(*) as total_genomes FROM kbase_ke_pangenome.genome\n\"\"\").toPandas()['total_genomes'].values[0]\n\ncoverage_pct = 100.0 * embeddings_coverage['genomes_with_embeddings'].values[0] / total_genomes\n\nprint(f\"AlphaEarth Embeddings Coverage:\")\nprint(f\"  Total genomes: {total_genomes:,}\")\nprint(f\"  Genomes with embeddings: {embeddings_coverage['genomes_with_embeddings'].values[0]:,}\")\nprint(f\"  Coverage: {coverage_pct:.1f}%\")\nprint(f\"\\nNote: Table contains AlphaEarth embedding vector components (A00, A01, A02, ...)\")\nprint(f\"      representing structural similarity features across all years combined.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Select Target Species for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select species for detailed analysis\n# Criteria: sufficient genomes for meaningful analysis\n# Note: We'll filter by data availability in downstream analysis\n\ntarget_species = spark.sql(\"\"\"\nSELECT\n  p.gtdb_species_clade_id,\n  s.GTDB_species,\n  p.no_genomes,\n  (p.no_aux_genome + p.no_singleton_gene_clusters) / p.no_gene_clusters AS openness_score\nFROM kbase_ke_pangenome.pangenome p\nJOIN kbase_ke_pangenome.gtdb_species_clade s\n  ON p.gtdb_species_clade_id = s.gtdb_species_clade_id\nWHERE p.no_genomes >= 5  -- At least 5 genomes for meaningful analysis\nORDER BY openness_score DESC\n\"\"\").toPandas()\n\n# Now separately check pathway and embedding coverage\ngenomes_with_pathways = spark.sql(\"\"\"\nSELECT DISTINCT g.gtdb_species_clade_id\nFROM kbase_ke_pangenome.genome g\nWHERE g.genome_id IN (SELECT DISTINCT genome_id FROM kbase_ke_pangenome.gapmind_pathways)\n\"\"\").toPandas()\n\ngenomes_with_embeddings = spark.sql(\"\"\"\nSELECT DISTINCT g.gtdb_species_clade_id\nFROM kbase_ke_pangenome.genome g\nWHERE g.genome_id IN (SELECT DISTINCT genome_id FROM kbase_ke_pangenome.alphaearth_embeddings_all_years)\n\"\"\").toPandas()\n\n# Mark which species have data\npathway_species = set(genomes_with_pathways['gtdb_species_clade_id'])\nembedding_species = set(genomes_with_embeddings['gtdb_species_clade_id'])\n\ntarget_species['has_pathways'] = target_species['gtdb_species_clade_id'].isin(pathway_species)\ntarget_species['has_embeddings'] = target_species['gtdb_species_clade_id'].isin(embedding_species)\n\nprint(f\"\\nSelected {len(target_species)} target species for analysis\")\nprint(f\"Species with pathway data: {target_species['has_pathways'].sum()}\")\nprint(f\"Species with embedding data: {target_species['has_embeddings'].sum()}\")\nprint(\"\\nTarget Species Summary:\")\nprint(target_species[['GTDB_species', 'no_genomes', 'openness_score', 'has_pathways', 'has_embeddings']].head(20).to_string())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Initial Data Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pangenome openness scores for all species\n",
    "pangenome_openness.to_csv(\n",
    "    '../data/species_pangenome_openness.csv',\n",
    "    index=False\n",
    ")\nprint(\"Saved: species_pangenome_openness.csv\")\n",
    "\n",
    "# Save target species list\n",
    "target_species.to_csv(\n",
    "    '../data/target_species_for_analysis.csv',\n",
    "    index=False\n",
    ")\nprint(\"Saved: target_species_for_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Pangenome Openness Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram of openness scores\n",
    "axes[0, 0].hist(pangenome_openness['openness_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Pangenome Openness Score')\n",
    "axes[0, 0].set_ylabel('Number of Species')\n",
    "axes[0, 0].set_title('Distribution of Pangenome Openness Across Species')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Scatter: Genomes vs Openness\n",
    "axes[0, 1].scatter(pangenome_openness['no_genomes'], pangenome_openness['openness_score'], alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Number of Genomes')\n",
    "axes[0, 1].set_ylabel('Openness Score')\n",
    "axes[0, 1].set_title('Pangenome Openness vs. Genome Count')\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Scatter: Core Fraction vs Openness\n",
    "axes[1, 0].scatter(pangenome_openness['core_fraction'], pangenome_openness['openness_score'], alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Core Gene Fraction')\n",
    "axes[1, 0].set_ylabel('Openness Score')\n",
    "axes[1, 0].set_title('Core Gene Content vs. Openness')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot by openness quartile\n",
    "pangenome_openness['openness_quartile'] = pd.qcut(pangenome_openness['openness_score'], q=4, labels=['Q1_Closed', 'Q2', 'Q3', 'Q4_Open'])\n",
    "quartile_data = [pangenome_openness[pangenome_openness['openness_quartile'] == q]['no_genomes'] for q in ['Q1_Closed', 'Q2', 'Q3', 'Q4_Open']]\n",
    "axes[1, 1].boxplot(quartile_data, labels=['Q1_Closed', 'Q2', 'Q3', 'Q4_Open'])\n",
    "axes[1, 1].set_ylabel('Number of Genomes')\n",
    "axes[1, 1].set_title('Genome Count by Openness Quartile')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/01_pangenome_openness_overview.png', dpi=300, bbox_inches='tight')\nprint(\"Saved: 01_pangenome_openness_overview.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data Exploration\n",
    "\n",
    "Key findings from this exploration:\n",
    "1. **Pangenome Openness**: Varies widely across species (0-1 range)\n",
    "2. **GapMind Pathways**: Available for most genomes with score categories\n",
    "3. **AlphaEarth Embeddings**: ~28% coverage of all genomes (as expected)\n",
    "4. **Target Species**: Selected species with good coverage across all data types\n",
    "\n",
    "Next steps: Move to Phase 2 (02_pangenome_openness.ipynb) for detailed correlation analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}