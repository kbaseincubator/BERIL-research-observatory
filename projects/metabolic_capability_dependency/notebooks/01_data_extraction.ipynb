{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB01: Data Extraction & Assembly\n",
    "\n",
    "Extract all Spark-dependent data for the Metabolic Capability vs Dependency analysis.\n",
    "\n",
    "**Requires BERDL JupyterHub** — `get_spark_session()` must be available.\n",
    "\n",
    "### Outputs\n",
    "- `data/organism_mapping.csv` — FB organism → GTDB clade mapping\n",
    "- `data/fb_gapmind_scores.csv` — GapMind pathway scores for FB organisms' reference genomes\n",
    "- `data/fb_eggnog_annotations.csv` — eggNOG functional annotations (EC, KEGG) for FB-linked gene clusters\n",
    "- `data/fb_fitness_stats.csv` — Per-gene fitness summary statistics for FB organisms\n",
    "- `data/fb_essential_genes.csv` — Putative essential genes (in gene table but absent from genefitness)\n",
    "- `data/species_pathway_summary.csv` — Species-level GapMind aggregates for all 27K species\n",
    "\n",
    "### Key pitfalls\n",
    "- GapMind has multiple rows per genome-pathway pair → must MAX aggregate\n",
    "- FB fitness values are strings → must CAST to FLOAT\n",
    "- GapMind genome_id format may differ from pangenome genome table → check and reconcile\n",
    "- Gene cluster IDs are species-specific → use EC/KEGG for cross-species comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark_session()\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Fitness Browser Organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_orgs = spark.sql(\"\"\"\n",
    "    SELECT orgId, genus, species, strain, taxonomyId, division\n",
    "    FROM kescience_fitnessbrowser.organism\n",
    "    ORDER BY genus, species\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Total FB organisms: {len(fb_orgs)}\")\n",
    "fb_orgs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Match FB Organisms to GTDB Species Clades\n",
    "\n",
    "Use NCBI taxonomy IDs to link FB organisms to GTDB pangenome clades.\n",
    "This is a simplified version of the full DIAMOND-based mapping from\n",
    "`conservation_vs_fitness`; it covers the majority of organisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect unique taxonomy IDs from FB organisms\n",
    "tax_ids = fb_orgs['taxonomyId'].dropna().astype(int).unique().tolist()\n",
    "tax_id_str = ','.join([str(t) for t in tax_ids])\n",
    "print(f\"Unique FB taxonomy IDs: {len(tax_ids)}\")\n",
    "\n",
    "# Match against GTDB metadata\n",
    "taxid_matches = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        CAST(m.ncbi_species_taxid AS INT) as ncbi_species_taxid,\n",
    "        CAST(m.ncbi_taxid AS INT) as ncbi_taxid,\n",
    "        m.accession as genome_id,\n",
    "        g.gtdb_species_clade_id\n",
    "    FROM kbase_ke_pangenome.gtdb_metadata m\n",
    "    JOIN kbase_ke_pangenome.genome g ON m.accession = g.genome_id\n",
    "    WHERE CAST(m.ncbi_species_taxid AS INT) IN ({tax_id_str})\n",
    "       OR CAST(m.ncbi_taxid AS INT) IN ({tax_id_str})\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Taxid matches: {len(taxid_matches)} genome-clade pairs\")\n",
    "print(f\"Unique clades: {taxid_matches['gtdb_species_clade_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map FB organisms to clades\n",
    "mapping_rows = []\n",
    "for _, org in fb_orgs.iterrows():\n",
    "    tid = org['taxonomyId']\n",
    "    if pd.isna(tid):\n",
    "        continue\n",
    "    tid = int(tid)\n",
    "    hits = taxid_matches[\n",
    "        (taxid_matches['ncbi_species_taxid'] == tid) |\n",
    "        (taxid_matches['ncbi_taxid'] == tid)\n",
    "    ]\n",
    "    for clade in hits['gtdb_species_clade_id'].unique():\n",
    "        clade_genomes = hits[hits['gtdb_species_clade_id'] == clade]\n",
    "        mapping_rows.append({\n",
    "            'orgId': org['orgId'],\n",
    "            'genus': org['genus'],\n",
    "            'species': org['species'],\n",
    "            'strain': org['strain'],\n",
    "            'taxonomyId': tid,\n",
    "            'gtdb_species_clade_id': clade,\n",
    "            'representative_genome_id': clade_genomes['genome_id'].iloc[0],\n",
    "            'n_clade_genomes': len(clade_genomes)\n",
    "        })\n",
    "\n",
    "org_mapping = pd.DataFrame(mapping_rows)\n",
    "print(f\"Mapped {org_mapping['orgId'].nunique()} FB organisms to {org_mapping['gtdb_species_clade_id'].nunique()} clades\")\n",
    "print(f\"\\nUnmatched organisms:\")\n",
    "unmatched = set(fb_orgs['orgId']) - set(org_mapping['orgId'])\n",
    "for oid in sorted(unmatched):\n",
    "    row = fb_orgs[fb_orgs['orgId'] == oid].iloc[0]\n",
    "    print(f\"  {oid}: {row['genus']} {row['species']} (taxid={row['taxonomyId']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve multi-clade organisms: pick clade with most genomes\n",
    "# (proxy for best-studied, most representative clade)\n",
    "clades_per_org = org_mapping.groupby('orgId')['gtdb_species_clade_id'].nunique()\n",
    "multi_clade = clades_per_org[clades_per_org > 1]\n",
    "\n",
    "if len(multi_clade) > 0:\n",
    "    print(f\"Resolving {len(multi_clade)} multi-clade organisms:\")\n",
    "    resolved = []\n",
    "    for orgId in org_mapping['orgId'].unique():\n",
    "        org_rows = org_mapping[org_mapping['orgId'] == orgId]\n",
    "        if len(org_rows) == 1:\n",
    "            resolved.append(org_rows.iloc[0])\n",
    "        else:\n",
    "            # Pick clade with most genomes\n",
    "            best = org_rows.sort_values('n_clade_genomes', ascending=False).iloc[0]\n",
    "            print(f\"  {orgId}: {len(org_rows)} clades -> chose {best['gtdb_species_clade_id']} ({best['n_clade_genomes']} genomes)\")\n",
    "            resolved.append(best)\n",
    "    org_mapping_resolved = pd.DataFrame(resolved)\n",
    "else:\n",
    "    org_mapping_resolved = org_mapping.copy()\n",
    "\n",
    "print(f\"\\nFinal mapping: {len(org_mapping_resolved)} organisms -> {org_mapping_resolved['gtdb_species_clade_id'].nunique()} clades\")\n",
    "org_mapping_resolved[['orgId', 'genus', 'species', 'gtdb_species_clade_id', 'representative_genome_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GapMind genome_id Format\n",
    "\n",
    "The GapMind table may use bare NCBI accessions (e.g., `GCF_000005845.2`)\n",
    "while the pangenome genome table uses GTDB-prefixed IDs (e.g., `RS_GCF_000005845.2`).\n",
    "We need to reconcile these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GapMind genome_id format with a sample\n",
    "gapmind_sample = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT genome_id\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways\n",
    "    LIMIT 20\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"Sample GapMind genome_ids:\")\n",
    "for gid in gapmind_sample['genome_id'].tolist():\n",
    "    print(f\"  {gid}\")\n",
    "\n",
    "# Check if they have GTDB prefix\n",
    "has_prefix = gapmind_sample['genome_id'].str.startswith(('RS_', 'GB_')).any()\n",
    "print(f\"\\nHas GTDB prefix (RS_/GB_): {has_prefix}\")\n",
    "\n",
    "# Check overlap with pangenome genome table\n",
    "sample_ids = \"','\".join(gapmind_sample['genome_id'].tolist()[:5])\n",
    "genome_check = spark.sql(f\"\"\"\n",
    "    SELECT genome_id FROM kbase_ke_pangenome.genome\n",
    "    WHERE genome_id IN ('{sample_ids}')\n",
    "\"\"\").toPandas()\n",
    "print(f\"\\nDirect match with genome table: {len(genome_check)}/5\")\n",
    "\n",
    "if len(genome_check) == 0:\n",
    "    # Try stripping prefix from genome table IDs\n",
    "    print(\"Checking if GapMind uses bare accessions...\")\n",
    "    bare_check = spark.sql(f\"\"\"\n",
    "        SELECT genome_id,\n",
    "               CASE\n",
    "                   WHEN genome_id LIKE 'RS_%' THEN SUBSTRING(genome_id, 4)\n",
    "                   WHEN genome_id LIKE 'GB_%' THEN SUBSTRING(genome_id, 4)\n",
    "                   ELSE genome_id\n",
    "               END as bare_id\n",
    "        FROM kbase_ke_pangenome.genome\n",
    "        LIMIT 5\n",
    "    \"\"\").toPandas()\n",
    "    print(\"Genome table IDs vs bare:\")\n",
    "    print(bare_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build genome_id lookup based on format detection\n",
    "# If GapMind uses bare accessions, we need to strip GTDB prefix from our mapping\n",
    "target_genomes = org_mapping_resolved['representative_genome_id'].tolist()\n",
    "\n",
    "if not has_prefix:\n",
    "    # Strip RS_/GB_ prefix for GapMind queries\n",
    "    def strip_prefix(gid):\n",
    "        if gid.startswith(('RS_', 'GB_')):\n",
    "            return gid[3:]\n",
    "        return gid\n",
    "    gapmind_genome_ids = [strip_prefix(g) for g in target_genomes]\n",
    "    genome_id_map = dict(zip(gapmind_genome_ids, target_genomes))\n",
    "    print(f\"Using bare accessions for GapMind queries\")\n",
    "else:\n",
    "    gapmind_genome_ids = target_genomes\n",
    "    genome_id_map = {g: g for g in target_genomes}\n",
    "    print(f\"GapMind uses GTDB-prefixed IDs (same as genome table)\")\n",
    "\n",
    "print(f\"Target genomes for GapMind extraction: {len(gapmind_genome_ids)}\")\n",
    "print(f\"Sample: {gapmind_genome_ids[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract GapMind Pathway Scores for FB Organisms\n",
    "\n",
    "For each FB organism's reference genome, extract the best GapMind score per pathway.\n",
    "GapMind has multiple rows per genome-pathway pair (one per step), so we take MAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build IN clause for GapMind query\n",
    "genome_in = \"','\".join(gapmind_genome_ids)\n",
    "\n",
    "# Extract best pathway score per genome-pathway pair\n",
    "gapmind_fb = spark.sql(f\"\"\"\n",
    "    WITH scored AS (\n",
    "        SELECT\n",
    "            genome_id,\n",
    "            pathway,\n",
    "            metabolic_category,\n",
    "            clade_name,\n",
    "            score_category,\n",
    "            CAST(score AS FLOAT) as score,\n",
    "            CAST(nHi AS INT) as nHi,\n",
    "            CAST(nMed AS INT) as nMed,\n",
    "            CAST(nLo AS INT) as nLo,\n",
    "            CASE score_category\n",
    "                WHEN 'complete' THEN 5\n",
    "                WHEN 'likely_complete' THEN 4\n",
    "                WHEN 'steps_missing_low' THEN 3\n",
    "                WHEN 'steps_missing_medium' THEN 2\n",
    "                WHEN 'not_present' THEN 1\n",
    "                ELSE 0\n",
    "            END as score_rank\n",
    "        FROM kbase_ke_pangenome.gapmind_pathways\n",
    "        WHERE genome_id IN ('{genome_in}')\n",
    "    )\n",
    "    SELECT\n",
    "        genome_id,\n",
    "        pathway,\n",
    "        metabolic_category,\n",
    "        clade_name,\n",
    "        MAX(score_rank) as best_score_rank,\n",
    "        MAX(score) as best_score,\n",
    "        MAX(nHi) as max_nHi,\n",
    "        MAX(nMed) as max_nMed,\n",
    "        MAX(nLo) as max_nLo,\n",
    "        FIRST(score_category) as best_score_category\n",
    "    FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER (\n",
    "            PARTITION BY genome_id, pathway\n",
    "            ORDER BY score_rank DESC, score DESC\n",
    "        ) as rn\n",
    "        FROM scored\n",
    "    )\n",
    "    WHERE rn = 1\n",
    "    GROUP BY genome_id, pathway, metabolic_category, clade_name\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"GapMind scores extracted: {len(gapmind_fb)} genome-pathway pairs\")\n",
    "print(f\"Genomes: {gapmind_fb['genome_id'].nunique()}\")\n",
    "print(f\"Pathways: {gapmind_fb['pathway'].nunique()}\")\n",
    "print(f\"\\nScore category distribution:\")\n",
    "print(gapmind_fb['best_score_category'].value_counts())\n",
    "print(f\"\\nMetabolic category:\")\n",
    "print(gapmind_fb['metabolic_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map GapMind genome_ids back to GTDB-prefixed IDs and add orgId\n",
    "gapmind_fb['gtdb_genome_id'] = gapmind_fb['genome_id'].map(genome_id_map)\n",
    "\n",
    "# Create genome -> orgId lookup from mapping\n",
    "genome_to_org = dict(zip(\n",
    "    org_mapping_resolved['representative_genome_id'],\n",
    "    org_mapping_resolved['orgId']\n",
    "))\n",
    "gapmind_fb['orgId'] = gapmind_fb['gtdb_genome_id'].map(genome_to_org)\n",
    "\n",
    "# Check for unmapped\n",
    "unmapped = gapmind_fb['orgId'].isna().sum()\n",
    "if unmapped > 0:\n",
    "    print(f\"WARNING: {unmapped} rows without orgId mapping\")\n",
    "    print(\"Unmapped genome_ids:\")\n",
    "    print(gapmind_fb[gapmind_fb['orgId'].isna()]['genome_id'].unique())\n",
    "else:\n",
    "    print(f\"All {len(gapmind_fb)} rows mapped to FB organisms\")\n",
    "\n",
    "# Summary per organism\n",
    "org_summary = gapmind_fb.groupby('orgId').agg(\n",
    "    n_pathways=('pathway', 'nunique'),\n",
    "    n_complete=('best_score_rank', lambda x: (x >= 4).sum()),\n",
    "    n_absent=('best_score_rank', lambda x: (x <= 1).sum())\n",
    ").reset_index()\n",
    "org_summary['pct_complete'] = (org_summary['n_complete'] / org_summary['n_pathways'] * 100).round(1)\n",
    "print(f\"\\nPer-organism pathway completeness:\")\n",
    "print(org_summary.sort_values('pct_complete', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract eggNOG Annotations for FB-Linked Clades\n",
    "\n",
    "Get EC numbers, KEGG orthologs, and KEGG pathway assignments for gene clusters\n",
    "in the FB-linked species clades. These will be used to map genes to metabolic pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique clade IDs for our mapped organisms\n",
    "target_clades = org_mapping_resolved['gtdb_species_clade_id'].unique().tolist()\n",
    "clade_in = \"','\".join(target_clades)\n",
    "print(f\"Extracting eggNOG annotations for {len(target_clades)} clades...\")\n",
    "\n",
    "eggnog = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        gc.gene_cluster_id,\n",
    "        gc.gtdb_species_clade_id,\n",
    "        gc.is_core,\n",
    "        gc.is_auxiliary,\n",
    "        gc.is_singleton,\n",
    "        e.EC,\n",
    "        e.KEGG_ko,\n",
    "        e.KEGG_Pathway,\n",
    "        e.COG_category,\n",
    "        e.Description\n",
    "    FROM kbase_ke_pangenome.gene_cluster gc\n",
    "    LEFT JOIN kbase_ke_pangenome.eggnog_mapper_annotations e\n",
    "        ON gc.gene_cluster_id = e.query_name\n",
    "    WHERE gc.gtdb_species_clade_id IN ('{clade_in}')\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Gene clusters extracted: {len(eggnog):,}\")\n",
    "print(f\"With EC annotation: {eggnog['EC'].notna().sum():,} ({eggnog['EC'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"With KEGG_ko: {eggnog['KEGG_ko'].notna().sum():,} ({eggnog['KEGG_ko'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"With KEGG_Pathway: {eggnog['KEGG_Pathway'].notna().sum():,} ({eggnog['KEGG_Pathway'].notna().mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Fitness Data for FB Organisms\n",
    "\n",
    "Get per-gene fitness summary statistics. We aggregate across all experimental conditions:\n",
    "- Mean absolute fitness (overall importance)\n",
    "- Number of conditions with significant fitness effect (|fit| > 1, |t| > 4)\n",
    "- Min/max fitness (extreme effects)\n",
    "\n",
    "Also identify putative essential genes (protein-coding genes absent from genefitness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mapped orgIds\n",
    "target_orgIds = org_mapping_resolved['orgId'].tolist()\n",
    "orgId_in = \"','\".join(target_orgIds)\n",
    "print(f\"Extracting fitness data for {len(target_orgIds)} organisms...\")\n",
    "\n",
    "# Aggregate fitness per gene across all conditions\n",
    "fitness_stats = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        orgId,\n",
    "        locusId,\n",
    "        COUNT(*) as n_experiments,\n",
    "        AVG(CAST(fit AS FLOAT)) as mean_fit,\n",
    "        AVG(ABS(CAST(fit AS FLOAT))) as mean_abs_fit,\n",
    "        MIN(CAST(fit AS FLOAT)) as min_fit,\n",
    "        MAX(CAST(fit AS FLOAT)) as max_fit,\n",
    "        SUM(CASE WHEN ABS(CAST(fit AS FLOAT)) > 1 AND ABS(CAST(t AS FLOAT)) > 4 THEN 1 ELSE 0 END) as n_sig_important,\n",
    "        SUM(CASE WHEN CAST(fit AS FLOAT) < -1 AND ABS(CAST(t AS FLOAT)) > 4 THEN 1 ELSE 0 END) as n_sig_sick,\n",
    "        SUM(CASE WHEN CAST(fit AS FLOAT) > 1 AND ABS(CAST(t AS FLOAT)) > 4 THEN 1 ELSE 0 END) as n_sig_benefit\n",
    "    FROM kescience_fitnessbrowser.genefitness\n",
    "    WHERE orgId IN ('{orgId_in}')\n",
    "    GROUP BY orgId, locusId\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Fitness stats: {len(fitness_stats):,} gene entries\")\n",
    "print(f\"Organisms: {fitness_stats['orgId'].nunique()}\")\n",
    "print(f\"\\nPer-organism gene counts:\")\n",
    "print(fitness_stats.groupby('orgId').size().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify putative essential genes: in gene table (type=1, CDS) but NOT in genefitness\n",
    "# These genes had no viable transposon insertions -> likely essential\n",
    "essential_genes = spark.sql(f\"\"\"\n",
    "    SELECT g.orgId, g.locusId, g.type, g.scaffoldId, g.begin, g.end\n",
    "    FROM kescience_fitnessbrowser.gene g\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT orgId, locusId\n",
    "        FROM kescience_fitnessbrowser.genefitness\n",
    "        WHERE orgId IN ('{orgId_in}')\n",
    "    ) gf ON g.orgId = gf.orgId AND g.locusId = gf.locusId\n",
    "    WHERE g.orgId IN ('{orgId_in}')\n",
    "      AND g.type = '1'  -- CDS only\n",
    "      AND gf.locusId IS NULL\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Putative essential genes: {len(essential_genes):,}\")\n",
    "print(f\"Organisms: {essential_genes['orgId'].nunique()}\")\n",
    "\n",
    "# Per-organism essentiality rate\n",
    "total_cds = spark.sql(f\"\"\"\n",
    "    SELECT orgId, COUNT(*) as n_cds\n",
    "    FROM kescience_fitnessbrowser.gene\n",
    "    WHERE orgId IN ('{orgId_in}') AND type = '1'\n",
    "    GROUP BY orgId\n",
    "\"\"\").toPandas()\n",
    "\n",
    "ess_counts = essential_genes.groupby('orgId').size().reset_index(name='n_essential')\n",
    "ess_summary = total_cds.merge(ess_counts, on='orgId', how='left').fillna(0)\n",
    "ess_summary['n_essential'] = ess_summary['n_essential'].astype(int)\n",
    "ess_summary['pct_essential'] = (ess_summary['n_essential'] / ess_summary['n_cds'] * 100).round(1)\n",
    "print(f\"\\nEssentiality rates:\")\n",
    "print(f\"  Median: {ess_summary['pct_essential'].median():.1f}%\")\n",
    "print(f\"  Range: {ess_summary['pct_essential'].min():.1f}% - {ess_summary['pct_essential'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Species-Level GapMind Summary (All 27K Species)\n",
    "\n",
    "For the cross-species analysis (NB04), we need pathway completeness\n",
    "aggregated to the species level for all 27,690 species. This is a\n",
    "large aggregation over 305M rows — expected runtime ~10-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Two-stage aggregation for performance (see performance.md)\n",
    "species_pathway_summary = spark.sql(\"\"\"\n",
    "    WITH best_scores AS (\n",
    "        SELECT\n",
    "            clade_name,\n",
    "            genome_id,\n",
    "            pathway,\n",
    "            metabolic_category,\n",
    "            MAX(CASE score_category\n",
    "                WHEN 'complete' THEN 5\n",
    "                WHEN 'likely_complete' THEN 4\n",
    "                WHEN 'steps_missing_low' THEN 3\n",
    "                WHEN 'steps_missing_medium' THEN 2\n",
    "                WHEN 'not_present' THEN 1\n",
    "                ELSE 0\n",
    "            END) as best_score\n",
    "        FROM kbase_ke_pangenome.gapmind_pathways\n",
    "        GROUP BY clade_name, genome_id, pathway, metabolic_category\n",
    "    ),\n",
    "    genome_stats AS (\n",
    "        SELECT\n",
    "            clade_name,\n",
    "            genome_id,\n",
    "            COUNT(DISTINCT pathway) as n_pathways,\n",
    "            SUM(CASE WHEN best_score >= 5 THEN 1 ELSE 0 END) as n_complete,\n",
    "            SUM(CASE WHEN best_score >= 4 THEN 1 ELSE 0 END) as n_likely_complete,\n",
    "            SUM(CASE WHEN best_score <= 1 THEN 1 ELSE 0 END) as n_absent\n",
    "        FROM best_scores\n",
    "        GROUP BY clade_name, genome_id\n",
    "    )\n",
    "    SELECT\n",
    "        clade_name,\n",
    "        COUNT(DISTINCT genome_id) as n_genomes,\n",
    "        AVG(n_pathways) as mean_n_pathways,\n",
    "        AVG(n_complete) as mean_complete,\n",
    "        STDDEV(n_complete) as std_complete,\n",
    "        AVG(n_likely_complete) as mean_likely_complete,\n",
    "        STDDEV(n_likely_complete) as std_likely_complete,\n",
    "        AVG(n_absent) as mean_absent,\n",
    "        MIN(n_complete) as min_complete,\n",
    "        MAX(n_complete) as max_complete\n",
    "    FROM genome_stats\n",
    "    GROUP BY clade_name\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Species pathway summary: {len(species_pathway_summary):,} species\")\n",
    "print(f\"\\nDistribution of mean complete pathways:\")\n",
    "print(species_pathway_summary['mean_complete'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get pangenome openness metrics for all species\n",
    "pangenome_stats = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        gtdb_species_clade_id,\n",
    "        CAST(no_genomes AS INT) as no_genomes,\n",
    "        CAST(no_gene_clusters AS INT) as no_gene_clusters,\n",
    "        CAST(no_core AS INT) as no_core,\n",
    "        CAST(no_aux_genome AS INT) as no_aux,\n",
    "        CAST(no_singleton_gene_clusters AS INT) as no_singleton\n",
    "    FROM kbase_ke_pangenome.pangenome\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Compute openness metrics\n",
    "pangenome_stats['pct_core'] = (pangenome_stats['no_core'] / pangenome_stats['no_gene_clusters'] * 100).round(2)\n",
    "pangenome_stats['pct_singleton'] = (pangenome_stats['no_singleton'] / pangenome_stats['no_gene_clusters'] * 100).round(2)\n",
    "pangenome_stats['openness'] = (pangenome_stats['no_aux'] / pangenome_stats['no_gene_clusters']).round(4)\n",
    "\n",
    "print(f\"Pangenome stats: {len(pangenome_stats):,} species\")\n",
    "print(pangenome_stats[['no_genomes', 'no_gene_clusters', 'pct_core', 'pct_singleton', 'openness']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save organism mapping\n",
    "org_mapping_resolved.to_csv(DATA_DIR / 'organism_mapping.csv', index=False)\n",
    "print(f\"Saved: organism_mapping.csv ({len(org_mapping_resolved)} rows)\")\n",
    "\n",
    "# Save GapMind scores for FB organisms\n",
    "gapmind_fb.to_csv(DATA_DIR / 'fb_gapmind_scores.csv', index=False)\n",
    "print(f\"Saved: fb_gapmind_scores.csv ({len(gapmind_fb)} rows)\")\n",
    "\n",
    "# Save eggNOG annotations\n",
    "eggnog.to_csv(DATA_DIR / 'fb_eggnog_annotations.csv', index=False)\n",
    "print(f\"Saved: fb_eggnog_annotations.csv ({len(eggnog):,} rows)\")\n",
    "\n",
    "# Save fitness stats\n",
    "fitness_stats.to_csv(DATA_DIR / 'fb_fitness_stats.csv', index=False)\n",
    "print(f\"Saved: fb_fitness_stats.csv ({len(fitness_stats):,} rows)\")\n",
    "\n",
    "# Save essential genes\n",
    "essential_genes.to_csv(DATA_DIR / 'fb_essential_genes.csv', index=False)\n",
    "print(f\"Saved: fb_essential_genes.csv ({len(essential_genes):,} rows)\")\n",
    "\n",
    "# Save species-level pathway summary\n",
    "species_pathway_summary.to_csv(DATA_DIR / 'species_pathway_summary.csv', index=False)\n",
    "print(f\"Saved: species_pathway_summary.csv ({len(species_pathway_summary):,} rows)\")\n",
    "\n",
    "# Save pangenome stats\n",
    "pangenome_stats.to_csv(DATA_DIR / 'pangenome_stats.csv', index=False)\n",
    "print(f\"Saved: pangenome_stats.csv ({len(pangenome_stats):,} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NB01 DATA EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"FB organisms mapped: {org_mapping_resolved['orgId'].nunique()}/{len(fb_orgs)}\")\n",
    "print(f\"GTDB clades: {org_mapping_resolved['gtdb_species_clade_id'].nunique()}\")\n",
    "print(f\"GapMind scores: {len(gapmind_fb)} genome-pathway pairs\")\n",
    "print(f\"  Complete pathways: {(gapmind_fb['best_score_rank'] >= 5).sum()}\")\n",
    "print(f\"  Likely complete: {(gapmind_fb['best_score_rank'] == 4).sum()}\")\n",
    "print(f\"  Absent: {(gapmind_fb['best_score_rank'] <= 1).sum()}\")\n",
    "print(f\"eggNOG annotations: {len(eggnog):,} gene clusters\")\n",
    "print(f\"  With EC numbers: {eggnog['EC'].notna().sum():,}\")\n",
    "print(f\"Fitness stats: {len(fitness_stats):,} genes\")\n",
    "print(f\"Essential genes: {len(essential_genes):,}\")\n",
    "print(f\"Species pathway summary: {len(species_pathway_summary):,} species\")\n",
    "print(f\"Pangenome stats: {len(pangenome_stats):,} species\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAll outputs saved to {DATA_DIR}/\")\n",
    "print(\"Next: Run NB02 (pathway-gene linking) on JupyterHub\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}