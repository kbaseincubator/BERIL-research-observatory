{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d38621",
   "metadata": {
    "papermill": {
     "duration": 0.003474,
     "end_time": "2026-02-20T19:20:30.658824",
     "exception": false,
     "start_time": "2026-02-20T19:20:30.655350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NB03: Module Co-occurrence Validation\n",
    "\n",
    "**Project**: Prophage Ecology Across Bacterial Phylogeny and Environmental Gradients\n",
    "\n",
    "**Goal**: Test H1c — do genes within each predefined prophage module co-occur across genomes significantly more than random gene groupings of equal size? Also test contig co-localization.\n",
    "\n",
    "**Dependencies**: NB01 outputs (`data/prophage_gene_clusters.tsv`, `data/species_module_summary.tsv`)\n",
    "\n",
    "**Environment**: Requires BERDL JupyterHub (Spark SQL) for genome-level extraction\n",
    "\n",
    "**Outputs**:\n",
    "- `data/module_cooccurrence_stats.tsv` — co-occurrence statistics per module per species\n",
    "- `data/contig_colocation.tsv` — contig co-localization statistics\n",
    "- `figures/module_cooccurrence_heatmap.png`\n",
    "\n",
    "## Design Decisions (v2 revision)\n",
    "\n",
    "The original approach (v1) attempted 50 species with full genome sets, joining the\n",
    "billion-row `gene` and `gene_genecluster_junction` tables 50 times and computing\n",
    "pairwise Jaccard in pure Python. This was intractable — K. pneumoniae alone (14,240\n",
    "genomes, 9,067 clusters) stalled the notebook.\n",
    "\n",
    "**Changes in v2:**\n",
    "| Parameter | v1 | v2 | Rationale |\n",
    "|-----------|----|----|-----------|\n",
    "| Species count | 50 | 15 | Validation across phyla, not exhaustive survey |\n",
    "| Genome cap | None (up to 14K) | 300 | Jaccard stabilizes well below 300; avoids `maxResultSize` errors |\n",
    "| Query strategy | Per-species join on 1B-row tables | BROADCAST both genome and cluster ID temp views | Lets Spark push filters before the expensive join |\n",
    "| Jaccard computation | Python nested loop O(n²) | `scipy.spatial.distance.pdist` (vectorized C) | Orders of magnitude faster |\n",
    "| Null permutations | 500 | 200 | Ample for z-score estimation at ~half the cost |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ad009a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:30:33.132120Z",
     "iopub.status.busy": "2026-02-21T16:30:33.131855Z",
     "iopub.status.idle": "2026-02-21T16:30:50.930665Z",
     "shell.execute_reply": "2026-02-21T16:30:50.929681Z"
    },
    "papermill": {
     "duration": 12.367675,
     "end_time": "2026-02-20T19:20:43.029550",
     "exception": false,
     "start_time": "2026-02-20T19:20:30.661875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophage clusters: 4,005,537\n",
      "Species with prophage: 27,702\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "spark = get_spark_session()\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from prophage_utils import MODULES\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "# Load NB01 outputs\n",
    "prophage_clusters = pd.read_csv('../data/prophage_gene_clusters.tsv', sep='\\t')\n",
    "species_summary = pd.read_csv('../data/species_module_summary.tsv', sep='\\t')\n",
    "\n",
    "# Fix boolean columns from TSV read (may be string \"True\"/\"False\")\n",
    "for module_id in MODULES.keys():\n",
    "    col = f'has_{module_id}'\n",
    "    if col in prophage_clusters.columns:\n",
    "        prophage_clusters[col] = prophage_clusters[col].astype(str).str.lower() == 'true'\n",
    "\n",
    "print(f'Prophage clusters: {len(prophage_clusters):,}')\n",
    "print(f'Species with prophage: {len(species_summary):,}')\n",
    "\n",
    "# Constants\n",
    "MAX_GENOMES = 300       # Cap genomes per species to stabilize Jaccard & avoid maxResultSize\n",
    "N_SPECIES = 15          # Enough for cross-phylum validation\n",
    "N_NULL = 200            # Null permutations for z-score\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708bb01",
   "metadata": {
    "papermill": {
     "duration": 0.002542,
     "end_time": "2026-02-20T19:20:43.035638",
     "exception": false,
     "start_time": "2026-02-20T19:20:43.033096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Select Representative Species\n",
    "\n",
    "Choose ~15 species spanning phylogenetic diversity with >=20 genomes each and\n",
    "multiple prophage modules present. Stratified sampling across phyla ensures we\n",
    "validate co-occurrence broadly, not just in well-studied clades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502bf7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:30:50.933054Z",
     "iopub.status.busy": "2026-02-21T16:30:50.932908Z",
     "iopub.status.idle": "2026-02-21T16:30:55.288072Z",
     "shell.execute_reply": "2026-02-21T16:30:55.287035Z"
    },
    "papermill": {
     "duration": 4.783992,
     "end_time": "2026-02-20T19:20:47.822185",
     "exception": false,
     "start_time": "2026-02-20T19:20:43.038193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxonomy rows: 27,690\n",
      "Candidate species (>=20 genomes, >=5 modules, >=10 clusters): 1,182\n",
      "Phyla represented in candidates: 23\n",
      "\n",
      "Selected 15 species across 15 phyla:\n",
      "  p__Acidobacteriota: s__Geothrix_sp903913215--GB_GCA_903913215.1 (29 genomes, 255 prophage clusters, 7 modules)\n",
      "  p__Actinomycetota: s__Streptomyces_albidoflavus--RS_GCF_000719955.1 (117 genomes, 1189 prophage clusters, 7 modules)\n",
      "  p__Bacillota: s__Bacillus_A_wiedmannii--RS_GCF_001583695.1 (235 genomes, 2298 prophage clusters, 7 modules)\n",
      "  p__Bacillota_A: s__Blautia_A_wexlerae--GB_GCA_025148125.1 (175 genomes, 2559 prophage clusters, 7 modules)\n",
      "  p__Bacillota_C: s__Megamonas_funiformis--RS_GCF_010669225.1 (44 genomes, 671 prophage clusters, 7 modules)\n",
      "  p__Bacteroidota: s__Bacteroides_uniformis--GB_GCA_025147485.1 (401 genomes, 2677 prophage clusters, 7 modules)\n",
      "  p__Campylobacterota: s__Helicobacter_pylori_BU--RS_GCF_900120335.1 (370 genomes, 195 prophage clusters, 7 modules)\n",
      "  p__Chlamydiota: s__Chlamydophila_psittaci--RS_GCF_000204255.1 (64 genomes, 60 prophage clusters, 5 modules)\n",
      "  p__Chloroflexota: s__UBA12225_sp002347925--GB_GCA_002347925.1 (21 genomes, 155 prophage clusters, 7 modules)\n",
      "  p__Cyanobacteriota: s__Microcystis_panniformis--RS_GCF_014698335.1 (46 genomes, 323 prophage clusters, 7 modules)\n",
      "  p__Deinococcota: s__Thermus_scotoductus--RS_GCF_000381045.1 (47 genomes, 244 prophage clusters, 7 modules)\n",
      "  p__Desulfobacterota: s__Bilophila_wadsworthia--RS_GCF_000701705.1 (32 genomes, 680 prophage clusters, 7 modules)\n",
      "  p__Desulfobacterota_F: s__JACRCG01_sp903852495--GB_GCA_903852495.1 (26 genomes, 362 prophage clusters, 6 modules)\n",
      "  p__Fusobacteriota: s__Fusobacterium_C_necrophorum--RS_GCF_004006635.1 (49 genomes, 411 prophage clusters, 7 modules)\n",
      "  p__Halobacteriota: s__Methanothrix_soehngenii--RS_GCF_000204415.1 (21 genomes, 120 prophage clusters, 7 modules)\n"
     ]
    }
   ],
   "source": [
    "# Get taxonomy for species selection\n",
    "# NOTE: Must join on genome_id, NOT gtdb_taxonomy_id.\n",
    "# The genome table truncates gtdb_taxonomy_id at genus level while the\n",
    "# taxonomy table includes species — so they never match via =.\n",
    "taxonomy = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT g.gtdb_species_clade_id, t.phylum, t.class, t.order, t.family\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.gtdb_taxonomy_r214v1 t ON g.genome_id = t.genome_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Taxonomy rows: {len(taxonomy):,}')\n",
    "\n",
    "# Merge with species summary\n",
    "candidates = species_summary.merge(taxonomy, on='gtdb_species_clade_id', how='left')\n",
    "\n",
    "# Filter: >=20 genomes, >=5 modules present, >=10 prophage clusters\n",
    "candidates = candidates[\n",
    "    (candidates['no_genomes'] >= 20) &\n",
    "    (candidates['n_modules_present'] >= 5) &\n",
    "    (candidates['n_prophage_clusters'] >= 10)\n",
    "]\n",
    "\n",
    "print(f'Candidate species (>=20 genomes, >=5 modules, >=10 clusters): {len(candidates):,}')\n",
    "print(f'Phyla represented in candidates: {candidates[\"phylum\"].nunique()}')\n",
    "\n",
    "# Stratified sampling: 1-2 species per phylum, preferring species with\n",
    "# moderate genome counts (20-500) to avoid very large species that dominate runtime\n",
    "candidates['genome_bin'] = pd.cut(candidates['no_genomes'], \n",
    "                                   bins=[0, 100, 500, 1000, 100000],\n",
    "                                   labels=['small', 'medium', 'large', 'very_large'])\n",
    "\n",
    "# Prefer medium-sized species (100-500 genomes) for balanced representation\n",
    "selected_rows = []\n",
    "phyla = candidates['phylum'].dropna().unique()\n",
    "for phylum in sorted(phyla):\n",
    "    phylum_cands = candidates[candidates['phylum'] == phylum]\n",
    "    # Prefer medium, then small, then large\n",
    "    for preferred_bin in ['medium', 'small', 'large', 'very_large']:\n",
    "        bin_cands = phylum_cands[phylum_cands['genome_bin'] == preferred_bin]\n",
    "        if len(bin_cands) > 0:\n",
    "            best = bin_cands.nlargest(1, ['n_modules_present', 'n_prophage_clusters'])\n",
    "            selected_rows.append(best.iloc[0])\n",
    "            break\n",
    "    if len(selected_rows) >= N_SPECIES:\n",
    "        break\n",
    "\n",
    "selected = pd.DataFrame(selected_rows)\n",
    "\n",
    "# If we have fewer than N_SPECIES, fill from remaining candidates\n",
    "if len(selected) < N_SPECIES:\n",
    "    already_selected = set(selected['gtdb_species_clade_id']) if len(selected) > 0 else set()\n",
    "    remaining = candidates[~candidates['gtdb_species_clade_id'].isin(already_selected)]\n",
    "    extra = remaining.nlargest(N_SPECIES - len(selected), 'n_prophage_clusters')\n",
    "    selected = pd.concat([selected, extra])\n",
    "\n",
    "selected = selected.head(N_SPECIES)\n",
    "\n",
    "print(f'\\nSelected {len(selected)} species across {selected[\"phylum\"].nunique()} phyla:')\n",
    "for _, row in selected.iterrows():\n",
    "    print(f'  {row[\"phylum\"]}: {row[\"gtdb_species_clade_id\"]} '\n",
    "          f'({row[\"no_genomes\"]} genomes, {row[\"n_prophage_clusters\"]} prophage clusters, '\n",
    "          f'{row[\"n_modules_present\"]} modules)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede60e0",
   "metadata": {
    "papermill": {
     "duration": 0.002662,
     "end_time": "2026-02-20T19:20:47.828418",
     "exception": false,
     "start_time": "2026-02-20T19:20:47.825756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Extract Genome × Cluster Presence Matrices\n",
    "\n",
    "**Key optimization (v2b):** Instead of 15 separate Spark queries (each scanning the\n",
    "billion-row tables), we do ONE query with all genome IDs and all cluster IDs\n",
    "across all species. This means one scan of `gene` and `gene_genecluster_junction`\n",
    "instead of 15, reducing wall-clock time from ~60+ min to ~15-20 min.\n",
    "\n",
    "We BROADCAST both temp views (up to 4,500 genome IDs and ~30,000 cluster IDs),\n",
    "which Spark can handle efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed18ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:30:55.290545Z",
     "iopub.status.busy": "2026-02-21T16:30:55.290426Z",
     "iopub.status.idle": "2026-02-21T16:30:55.294020Z",
     "shell.execute_reply": "2026-02-21T16:30:55.293334Z"
    },
    "papermill": {
     "duration": 0.011157,
     "end_time": "2026-02-20T19:20:47.842251",
     "exception": false,
     "start_time": "2026-02-20T19:20:47.831094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined (vectorized Jaccard via scipy.spatial.distance.pdist).\n"
     ]
    }
   ],
   "source": [
    "def mean_pairwise_jaccard(binary_matrix):\n",
    "    \"\"\"Compute mean pairwise Jaccard similarity between columns of a binary matrix.\n",
    "    \n",
    "    Uses scipy.spatial.distance.pdist for vectorized computation (C-level speed).\n",
    "    pdist returns Jaccard *distance* (1 - similarity), so we convert.\n",
    "    \"\"\"\n",
    "    # pdist expects rows=observations, cols=features\n",
    "    # We want pairwise between clusters (columns), so transpose\n",
    "    mat = binary_matrix.values.T.astype(bool)\n",
    "    if mat.shape[0] < 2:\n",
    "        return 0.0\n",
    "    # pdist 'jaccard' = fraction of positions where vectors differ (among positions\n",
    "    # where at least one is nonzero). This is 1 - Jaccard similarity.\n",
    "    distances = pdist(mat, metric='jaccard')\n",
    "    # Handle NaN from all-zero vectors\n",
    "    distances = np.nan_to_num(distances, nan=1.0)\n",
    "    similarities = 1.0 - distances\n",
    "    return float(np.mean(similarities))\n",
    "\n",
    "print('Helper function defined (vectorized Jaccard via scipy.spatial.distance.pdist).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e89fe4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:30:55.295739Z",
     "iopub.status.busy": "2026-02-21T16:30:55.295632Z",
     "iopub.status.idle": "2026-02-21T16:36:27.550887Z",
     "shell.execute_reply": "2026-02-21T16:36:27.549623Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2026-02-20T19:20:47.845140",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s__Bacteroides_uniformis--GB_GCA_025147485.1: sampled 300/401 genomes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s__Helicobacter_pylori_BU--RS_GCF_900120335.1: sampled 300/370 genomes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 15 species, 1506 unique genomes, 12199 unique prophage clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered temp views. Running single join query...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single query completed in 319.8s\n",
      "Total rows: 182,093\n",
      "Unique genomes: 1506, Unique clusters: 11908\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# === Phase 1: Collect genome IDs and cluster IDs for ALL species ===\n",
    "all_genome_ids_by_species = {}\n",
    "all_cluster_ids_by_species = {}\n",
    "all_genomes_flat = []\n",
    "all_clusters_flat = []\n",
    "\n",
    "for _, species_row in selected.iterrows():\n",
    "    species_id = species_row['gtdb_species_clade_id']\n",
    "    \n",
    "    # Get prophage cluster IDs\n",
    "    sp_clusters = prophage_clusters[\n",
    "        prophage_clusters['gtdb_species_clade_id'] == species_id\n",
    "    ]\n",
    "    if len(sp_clusters) < 5:\n",
    "        continue\n",
    "    cluster_ids = sp_clusters['gene_cluster_id'].tolist()\n",
    "    all_cluster_ids_by_species[species_id] = cluster_ids\n",
    "    all_clusters_flat.extend(cluster_ids)\n",
    "    \n",
    "    # Get genome IDs, cap at MAX_GENOMES\n",
    "    genome_rows = spark.sql(f\"\"\"\n",
    "        SELECT genome_id FROM kbase_ke_pangenome.genome\n",
    "        WHERE gtdb_species_clade_id = '{species_id}'\n",
    "    \"\"\").collect()\n",
    "    gids = [r.genome_id for r in genome_rows]\n",
    "    \n",
    "    if len(gids) > MAX_GENOMES:\n",
    "        gids = [str(g) for g in np.random.choice(gids, MAX_GENOMES, replace=False)]\n",
    "        print(f'{species_id}: sampled {MAX_GENOMES}/{len(genome_rows)} genomes')\n",
    "    \n",
    "    all_genome_ids_by_species[species_id] = gids\n",
    "    all_genomes_flat.extend(gids)\n",
    "\n",
    "# Deduplicate (in case of overlap — unlikely but safe)\n",
    "all_genomes_flat = list(set(all_genomes_flat))\n",
    "all_clusters_flat = list(set(all_clusters_flat))\n",
    "\n",
    "print(f'\\nTotal: {len(all_genome_ids_by_species)} species, '\n",
    "      f'{len(all_genomes_flat)} unique genomes, '\n",
    "      f'{len(all_clusters_flat)} unique prophage clusters')\n",
    "\n",
    "# === Phase 2: Single Spark query for ALL species ===\n",
    "t0 = time.time()\n",
    "\n",
    "spark.createDataFrame(\n",
    "    [(str(c),) for c in all_clusters_flat], ['gene_cluster_id']\n",
    ").createOrReplaceTempView('all_target_clusters')\n",
    "\n",
    "spark.createDataFrame(\n",
    "    [(str(g),) for g in all_genomes_flat], ['genome_id']\n",
    ").createOrReplaceTempView('all_target_genomes')\n",
    "\n",
    "print('Registered temp views. Running single join query...')\n",
    "\n",
    "all_presence_df = spark.sql(\"\"\"\n",
    "    SELECT /*+ BROADCAST(tc), BROADCAST(tg) */\n",
    "        g.genome_id, j.gene_cluster_id, g.gene_id\n",
    "    FROM kbase_ke_pangenome.gene g\n",
    "    JOIN all_target_genomes tg ON g.genome_id = tg.genome_id\n",
    "    JOIN kbase_ke_pangenome.gene_genecluster_junction j ON g.gene_id = j.gene_id\n",
    "    JOIN all_target_clusters tc ON j.gene_cluster_id = tc.gene_cluster_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "elapsed_query = time.time() - t0\n",
    "print(f'Single query completed in {elapsed_query:.1f}s')\n",
    "print(f'Total rows: {len(all_presence_df):,}')\n",
    "print(f'Unique genomes: {all_presence_df[\"genome_id\"].nunique()}, '\n",
    "      f'Unique clusters: {all_presence_df[\"gene_cluster_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12fe43",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Per-Species Co-occurrence and Co-localization Tests\n",
    "\n",
    "Now that we have all presence data in a single pandas DataFrame, we split by species\n",
    "and run the statistical tests locally — this is fast because it's all vectorized\n",
    "numpy/scipy on small matrices (≤300 genomes × ≤few thousand clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7465635f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:36:27.554451Z",
     "iopub.status.busy": "2026-02-21T16:36:27.554138Z",
     "iopub.status.idle": "2026-02-21T16:40:54.305174Z",
     "shell.execute_reply": "2026-02-21T16:40:54.304501Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s__Geothrix_sp903913215--GB_GCA_903913215.1: 2,289 pairs, 29 genomes, 255 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 1.3s\n",
      "s__Streptomyces_albidoflavus--RS_GCF_000719955.1: 23,640 pairs, 117 genomes, 1189 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 13.9s\n",
      "s__Bacillus_A_wiedmannii--RS_GCF_001583695.1: 48,250 pairs, 235 genomes, 2298 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 54.0s\n",
      "s__Blautia_A_wexlerae--GB_GCA_025148125.1: 27,026 pairs, 175 genomes, 2559 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 67.5s\n",
      "s__Megamonas_funiformis--RS_GCF_010669225.1: 4,059 pairs, 44 genomes, 671 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 2.5s\n",
      "s__Bacteroides_uniformis--GB_GCA_025147485.1: 38,299 pairs, 300 genomes, 2402 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 109.9s\n",
      "s__Helicobacter_pylori_BU--RS_GCF_900120335.1: 14,044 pairs, 300 genomes, 179 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 6 module tests in 5.8s\n",
      "s__Chlamydophila_psittaci--RS_GCF_000204255.1: 2,358 pairs, 64 genomes, 60 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 5 module tests in 1.4s\n",
      "s__UBA12225_sp002347925--GB_GCA_002347925.1: 1,211 pairs, 21 genomes, 155 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 1.1s\n",
      "s__Microcystis_panniformis--RS_GCF_014698335.1: 5,043 pairs, 46 genomes, 323 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 5 module tests in 1.6s\n",
      "s__Thermus_scotoductus--RS_GCF_000381045.1: 3,691 pairs, 47 genomes, 244 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 6 module tests in 1.5s\n",
      "s__Bilophila_wadsworthia--RS_GCF_000701705.1: 4,521 pairs, 32 genomes, 680 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 2.1s\n",
      "s__JACRCG01_sp903852495--GB_GCA_903852495.1: 2,787 pairs, 26 genomes, 362 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 5 module tests in 1.2s\n",
      "s__Fusobacterium_C_necrophorum--RS_GCF_004006635.1: 4,169 pairs, 49 genomes, 411 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 7 module tests in 2.1s\n",
      "s__Methanothrix_soehngenii--RS_GCF_000204415.1: 706 pairs, 21 genomes, 120 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 5 module tests in 0.8s\n",
      "\n",
      "Done. Co-occurrence results: 95, Co-localization results: 95\n"
     ]
    }
   ],
   "source": [
    "# Build genome→species lookup\n",
    "genome_to_species = {}\n",
    "for species_id, gids in all_genome_ids_by_species.items():\n",
    "    for g in gids:\n",
    "        genome_to_species[g] = species_id\n",
    "\n",
    "# Map each row to its species\n",
    "all_presence_df['species'] = all_presence_df['genome_id'].map(genome_to_species)\n",
    "\n",
    "all_cooccurrence_results = []\n",
    "all_colocation_results = []\n",
    "\n",
    "for species_id in all_genome_ids_by_species:\n",
    "    t0 = time.time()\n",
    "    sp_presence = all_presence_df[all_presence_df['species'] == species_id]\n",
    "    \n",
    "    if len(sp_presence) == 0:\n",
    "        print(f'{species_id}: no data')\n",
    "        continue\n",
    "    \n",
    "    sp_clusters_df = prophage_clusters[\n",
    "        prophage_clusters['gtdb_species_clade_id'] == species_id\n",
    "    ]\n",
    "    prophage_cluster_ids = sp_clusters_df['gene_cluster_id'].tolist()\n",
    "    \n",
    "    n_genomes = sp_presence['genome_id'].nunique()\n",
    "    n_clusters_found = sp_presence['gene_cluster_id'].nunique()\n",
    "    print(f'{species_id}: {len(sp_presence):,} pairs, '\n",
    "          f'{n_genomes} genomes, {n_clusters_found} clusters')\n",
    "    \n",
    "    # Build binary presence/absence matrix\n",
    "    presence_binary = sp_presence.groupby(\n",
    "        ['genome_id', 'gene_cluster_id']\n",
    "    ).size().unstack(fill_value=0)\n",
    "    presence_binary = (presence_binary > 0).astype(int)\n",
    "    \n",
    "    # === MODULE CO-OCCURRENCE TEST ===\n",
    "    all_available = [c for c in prophage_cluster_ids if c in presence_binary.columns]\n",
    "    \n",
    "    for module_id in MODULES.keys():\n",
    "        module_clusters = [\n",
    "            c for c in sp_clusters_df.loc[sp_clusters_df[f'has_{module_id}'], 'gene_cluster_id']\n",
    "            if c in presence_binary.columns\n",
    "        ]\n",
    "        if len(module_clusters) < 2:\n",
    "            continue\n",
    "        \n",
    "        observed_jaccard = mean_pairwise_jaccard(presence_binary[module_clusters])\n",
    "        \n",
    "        if len(all_available) < len(module_clusters):\n",
    "            continue\n",
    "        null_jaccards = []\n",
    "        for _ in range(N_NULL):\n",
    "            random_set = list(np.random.choice(all_available, size=len(module_clusters), replace=False))\n",
    "            null_jaccards.append(mean_pairwise_jaccard(presence_binary[random_set]))\n",
    "        \n",
    "        null_mean = np.mean(null_jaccards)\n",
    "        null_std = np.std(null_jaccards)\n",
    "        z_score = (observed_jaccard - null_mean) / null_std if null_std > 0 else 0\n",
    "        p_value = 1 - stats.norm.cdf(z_score)\n",
    "        \n",
    "        all_cooccurrence_results.append({\n",
    "            'gtdb_species_clade_id': species_id,\n",
    "            'module': module_id,\n",
    "            'n_clusters': len(module_clusters),\n",
    "            'n_genomes': n_genomes,\n",
    "            'observed_jaccard': observed_jaccard,\n",
    "            'null_mean': null_mean,\n",
    "            'null_std': null_std,\n",
    "            'z_score': z_score,\n",
    "            'p_value': p_value,\n",
    "        })\n",
    "    \n",
    "    # === CONTIG CO-LOCALIZATION TEST ===\n",
    "    sp_presence_local = sp_presence.copy()\n",
    "    sp_presence_local['contig'] = sp_presence_local['gene_id'].apply(\n",
    "        lambda x: '_'.join(x.rsplit('_', 1)[:-1]) if '_' in x else x\n",
    "    )\n",
    "    \n",
    "    for module_id in MODULES.keys():\n",
    "        module_clusters = set(\n",
    "            sp_clusters_df.loc[sp_clusters_df[f'has_{module_id}'], 'gene_cluster_id']\n",
    "        )\n",
    "        if len(module_clusters) < 2:\n",
    "            continue\n",
    "        \n",
    "        module_genes = sp_presence_local[\n",
    "            sp_presence_local['gene_cluster_id'].isin(module_clusters)\n",
    "        ]\n",
    "        n_genomes_with_module = 0\n",
    "        n_colocalized = 0\n",
    "        for genome_id, ggrp in module_genes.groupby('genome_id'):\n",
    "            if ggrp['gene_cluster_id'].nunique() >= 2:\n",
    "                n_genomes_with_module += 1\n",
    "                contig_counts = ggrp.groupby('contig')['gene_cluster_id'].nunique()\n",
    "                if contig_counts.max() >= 2:\n",
    "                    n_colocalized += 1\n",
    "        \n",
    "        coloc_frac = n_colocalized / n_genomes_with_module if n_genomes_with_module > 0 else 0\n",
    "        all_colocation_results.append({\n",
    "            'gtdb_species_clade_id': species_id,\n",
    "            'module': module_id,\n",
    "            'n_genomes_with_module': n_genomes_with_module,\n",
    "            'n_colocalized': n_colocalized,\n",
    "            'colocation_fraction': coloc_frac,\n",
    "        })\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    n_tests = len([r for r in all_cooccurrence_results if r['gtdb_species_clade_id'] == species_id])\n",
    "    print(f'  -> {n_tests} module tests in {elapsed:.1f}s')\n",
    "\n",
    "print(f'\\nDone. Co-occurrence results: {len(all_cooccurrence_results)}, '\n",
    "      f'Co-localization results: {len(all_colocation_results)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "0939068d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 4. Save and Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wts3zjpmvz",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:40:54.307496Z",
     "iopub.status.busy": "2026-02-21T16:40:54.307376Z",
     "iopub.status.idle": "2026-02-21T16:40:54.322195Z",
     "shell.execute_reply": "2026-02-21T16:40:54.321557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/module_cooccurrence_stats.tsv: 95 rows\n",
      "Saved data/contig_colocation.tsv: 95 rows\n",
      "\n",
      "--- Co-occurrence Summary by Module ---\n",
      "  A_packaging: 11/15 significant (p<0.05), mean z=3.40, obs Jaccard=0.186 vs null=0.104\n",
      "  B_head_morphogenesis: 1/12 significant (p<0.05), mean z=0.20, obs Jaccard=0.069 vs null=0.106\n",
      "  C_tail: 5/12 significant (p<0.05), mean z=1.43, obs Jaccard=0.150 vs null=0.082\n",
      "  D_lysis: 13/15 significant (p<0.05), mean z=4.45, obs Jaccard=0.192 vs null=0.104\n",
      "  E_integration: 1/15 significant (p<0.05), mean z=-1.93, obs Jaccard=0.059 vs null=0.104\n",
      "  F_lysogenic_regulation: 10/15 significant (p<0.05), mean z=2.16, obs Jaccard=0.132 vs null=0.104\n",
      "  G_anti_defense: 3/11 significant (p<0.05), mean z=1.50, obs Jaccard=0.052 vs null=0.077\n",
      "\n",
      "--- Contig Co-localization Summary by Module ---\n",
      "  A_packaging: mean co-localization fraction = 0.986 (15 species tested)\n",
      "  B_head_morphogenesis: mean co-localization fraction = 0.654 (12 species tested)\n",
      "  C_tail: mean co-localization fraction = 0.752 (12 species tested)\n",
      "  D_lysis: mean co-localization fraction = 0.901 (15 species tested)\n",
      "  E_integration: mean co-localization fraction = 0.652 (15 species tested)\n",
      "  F_lysogenic_regulation: mean co-localization fraction = 1.000 (15 species tested)\n",
      "  G_anti_defense: mean co-localization fraction = 0.281 (11 species tested)\n"
     ]
    }
   ],
   "source": [
    "cooc_df = pd.DataFrame(all_cooccurrence_results)\n",
    "coloc_df = pd.DataFrame(all_colocation_results)\n",
    "\n",
    "# Save\n",
    "cooc_df.to_csv('../data/module_cooccurrence_stats.tsv', sep='\\t', index=False)\n",
    "coloc_df.to_csv('../data/contig_colocation.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/module_cooccurrence_stats.tsv: {len(cooc_df):,} rows')\n",
    "print(f'Saved data/contig_colocation.tsv: {len(coloc_df):,} rows')\n",
    "\n",
    "# Summarize\n",
    "print(f'\\n--- Co-occurrence Summary by Module ---')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    mod_data = cooc_df[cooc_df['module'] == module_id]\n",
    "    if len(mod_data) == 0:\n",
    "        continue\n",
    "    n_sig = (mod_data['p_value'] < 0.05).sum()\n",
    "    mean_z = mod_data['z_score'].mean()\n",
    "    mean_obs = mod_data['observed_jaccard'].mean()\n",
    "    mean_null = mod_data['null_mean'].mean()\n",
    "    print(f'  {module_id}: {n_sig}/{len(mod_data)} significant (p<0.05), '\n",
    "          f'mean z={mean_z:.2f}, obs Jaccard={mean_obs:.3f} vs null={mean_null:.3f}')\n",
    "\n",
    "print(f'\\n--- Contig Co-localization Summary by Module ---')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    mod_data = coloc_df[coloc_df['module'] == module_id]\n",
    "    if len(mod_data) == 0:\n",
    "        continue\n",
    "    mean_frac = mod_data['colocation_fraction'].mean()\n",
    "    print(f'  {module_id}: mean co-localization fraction = {mean_frac:.3f} '\n",
    "          f'({len(mod_data)} species tested)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae91581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:40:54.324222Z",
     "iopub.status.busy": "2026-02-21T16:40:54.324113Z",
     "iopub.status.idle": "2026-02-21T16:40:55.152613Z",
     "shell.execute_reply": "2026-02-21T16:40:55.151738Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures/module_cooccurrence_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "module_order = sorted(MODULES.keys())\n",
    "\n",
    "# Panel 1: Z-scores by module (box plot)\n",
    "plot_data = cooc_df[cooc_df['module'].isin(module_order)].copy()\n",
    "plot_data['module_name'] = plot_data['module'].map(\n",
    "    {m: MODULES[m]['full_name'] for m in module_order}\n",
    ")\n",
    "\n",
    "sns.boxplot(data=plot_data, y='module_name', x='z_score', ax=axes[0],\n",
    "            orient='h', color='steelblue')\n",
    "axes[0].axvline(x=1.96, color='red', linestyle='--', alpha=0.5, label='z=1.96 (p<0.05)')\n",
    "axes[0].set_xlabel('Z-score (observed vs null co-occurrence)')\n",
    "axes[0].set_ylabel('')\n",
    "axes[0].set_title('Module Co-occurrence Significance')\n",
    "axes[0].legend()\n",
    "\n",
    "# Panel 2: Co-localization fraction by module\n",
    "coloc_plot = coloc_df[coloc_df['module'].isin(module_order)].copy()\n",
    "coloc_plot['module_name'] = coloc_plot['module'].map(\n",
    "    {m: MODULES[m]['full_name'] for m in module_order}\n",
    ")\n",
    "\n",
    "sns.boxplot(data=coloc_plot, y='module_name', x='colocation_fraction', ax=axes[1],\n",
    "            orient='h', color='darkorange')\n",
    "axes[1].set_xlabel('Contig Co-localization Fraction')\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].set_title('Module Genes on Same Contig')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/module_cooccurrence_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/module_cooccurrence_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d534a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T16:40:55.154959Z",
     "iopub.status.busy": "2026-02-21T16:40:55.154702Z",
     "iopub.status.idle": "2026-02-21T16:40:55.159010Z",
     "shell.execute_reply": "2026-02-21T16:40:55.158413Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NB03 SUMMARY\n",
      "============================================================\n",
      "Species tested: 15\n",
      "Module × species tests: 95\n",
      "Significant co-occurrence (p<0.05): 44/95 (46.3%)\n",
      "Mean co-localization fraction: 0.769\n",
      "\n",
      "Design: 15 species, max 300 genomes/species, 200 null permutations, seed=42\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('NB03 SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Species tested: {cooc_df[\"gtdb_species_clade_id\"].nunique()}')\n",
    "print(f'Module × species tests: {len(cooc_df)}')\n",
    "n_sig = (cooc_df['p_value'] < 0.05).sum()\n",
    "print(f'Significant co-occurrence (p<0.05): {n_sig}/{len(cooc_df)} ({n_sig/len(cooc_df)*100:.1f}%)')\n",
    "print(f'Mean co-localization fraction: {coloc_df[\"colocation_fraction\"].mean():.3f}')\n",
    "print(f'\\nDesign: {N_SPECIES} species, max {MAX_GENOMES} genomes/species, '\n",
    "      f'{N_NULL} null permutations, seed={RANDOM_SEED}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "03_module_cooccurrence.ipynb",
   "output_path": "03_module_cooccurrence.ipynb",
   "parameters": {},
   "start_time": "2026-02-20T19:20:26.056397",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
