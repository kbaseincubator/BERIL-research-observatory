{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB06: Environment-Enriched Modules & Lineages\n",
    "\n",
    "**Project**: Prophage Ecology Across Bacterial Phylogeny and Environmental Gradients\n",
    "\n",
    "**Goal**: Identify specific prophage modules and TerL-defined lineages whose environmental enrichment exceeds phylogenetic expectation. Use null models with constrained permutations preserving host family composition and genome size distribution.\n",
    "\n",
    "**Dependencies**: NB04 (`data/species_prophage_environment.tsv`), NB05 (`data/nmdc_prophage_prevalence.tsv`, `data/nmdc_module_by_environment.tsv`), NB02 (`data/terL_lineages.tsv`)\n",
    "\n",
    "**Environment**: Local (all data cached from previous notebooks)\n",
    "\n",
    "**Outputs**:\n",
    "- `data/enriched_modules.tsv` — modules with environment enrichment exceeding phylogenetic expectation\n",
    "- `data/enriched_lineages.tsv` — TerL lineages with environment enrichment\n",
    "- `figures/module_environment_enrichment.png`\n",
    "- `figures/lineage_environment_heatmap.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from prophage_utils import MODULES\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "# Load NB04 merged species data\n",
    "species_all = pd.read_csv('../data/species_prophage_environment.tsv', sep='\\t')\n",
    "print(f'Species with prophage + environment: {len(species_all):,}')\n",
    "\n",
    "# Load NB02 lineage data\n",
    "try:\n",
    "    lineages = pd.read_csv('../data/terL_lineages.tsv', sep='\\t')\n",
    "    print(f'TerL lineage assignments: {len(lineages):,}')\n",
    "    print(f'Unique lineages: {lineages[\"lineage_id\"].nunique():,}')\n",
    "except FileNotFoundError:\n",
    "    lineages = None\n",
    "    print('NB02 outputs not found — lineage enrichment will be skipped')\n",
    "\n",
    "# Load NB05 NMDC results for cross-validation\n",
    "try:\n",
    "    nmdc_module_corr = pd.read_csv('../data/nmdc_module_by_environment.tsv', sep='\\t')\n",
    "    print(f'NMDC module-abiotic correlations: {len(nmdc_module_corr):,}')\n",
    "except FileNotFoundError:\n",
    "    nmdc_module_corr = None\n",
    "    print('NB05 outputs not found — NMDC cross-validation will be skipped')\n",
    "\n",
    "module_ids = sorted(MODULES.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Module × Environment Enrichment with Null Models\n",
    "\n",
    "For each module × environment combination:\n",
    "1. Compute observed odds ratio (OR) of module presence in that environment vs others\n",
    "2. Generate null distribution by permuting environment labels 1000× while preserving:\n",
    "   - Host family-level composition (permute only within families)\n",
    "   - Genome size distribution (permute within genome size quartiles)\n",
    "3. Z-score = (observed OR - mean null OR) / std null OR\n",
    "4. FDR correction across all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: filter to species with known environment, family, and genome size\n",
    "analysis_df = species_all[\n",
    "    species_all['primary_env'].notna() &\n",
    "    (species_all['primary_env'] != 'other_unknown') &\n",
    "    species_all['family'].notna() &\n",
    "    species_all['genome_size_Mbp'].notna()\n",
    "].copy()\n",
    "\n",
    "# Create genome size quartiles for stratification\n",
    "analysis_df['size_quartile'] = pd.qcut(\n",
    "    analysis_df['genome_size_Mbp'], 4,\n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    ")\n",
    "\n",
    "# Create stratification variable: family × size_quartile\n",
    "analysis_df['stratum'] = analysis_df['family'] + '_' + analysis_df['size_quartile'].astype(str)\n",
    "\n",
    "# Filter environments with enough species\n",
    "env_counts = analysis_df['primary_env'].value_counts()\n",
    "valid_envs = env_counts[env_counts >= 30].index.tolist()\n",
    "analysis_df = analysis_df[analysis_df['primary_env'].isin(valid_envs)]\n",
    "\n",
    "print(f'Species for enrichment analysis: {len(analysis_df):,}')\n",
    "print(f'Families: {analysis_df[\"family\"].nunique()}')\n",
    "print(f'Environments: {analysis_df[\"primary_env\"].nunique()}')\n",
    "print(f'Strata (family × size_quartile): {analysis_df[\"stratum\"].nunique()}')\n",
    "print(f'\\nEnvironment distribution:')\n",
    "print(analysis_df['primary_env'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_odds_ratio(df, module_col, env_col, target_env):\n",
    "    \"\"\"Compute odds ratio: module presence in target_env vs all others.\"\"\"\n",
    "    in_env = df[env_col] == target_env\n",
    "    has_module = df[module_col] == True\n",
    "    \n",
    "    a = (in_env & has_module).sum()       # in env + has module\n",
    "    b = (in_env & ~has_module).sum()      # in env + no module\n",
    "    c = (~in_env & has_module).sum()      # not in env + has module\n",
    "    d = (~in_env & ~has_module).sum()     # not in env + no module\n",
    "    \n",
    "    # Add 0.5 Haldane correction to avoid division by zero\n",
    "    odds_ratio = ((a + 0.5) * (d + 0.5)) / ((b + 0.5) * (c + 0.5))\n",
    "    return np.log2(odds_ratio), a, b, c, d\n",
    "\n",
    "\n",
    "def constrained_permutation(df, env_col, strata_col):\n",
    "    \"\"\"Permute environment labels within strata (family × genome_size_quartile).\"\"\"\n",
    "    permuted = df[env_col].copy()\n",
    "    for stratum, idx in df.groupby(strata_col).groups.items():\n",
    "        if len(idx) > 1:\n",
    "            permuted.iloc[idx] = np.random.permutation(permuted.iloc[idx].values)\n",
    "    return permuted\n",
    "\n",
    "\n",
    "print('Functions defined for null model testing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run null model enrichment tests for each module × environment combination\n",
    "N_PERMUTATIONS = 1000\n",
    "np.random.seed(42)\n",
    "\n",
    "enrichment_results = []\n",
    "\n",
    "for module_id in module_ids:\n",
    "    has_col = f'has_{module_id}'\n",
    "    if has_col not in analysis_df.columns:\n",
    "        continue\n",
    "    \n",
    "    for target_env in valid_envs:\n",
    "        # Observed odds ratio (log2)\n",
    "        obs_log_or, a, b, c, d = compute_odds_ratio(\n",
    "            analysis_df, has_col, 'primary_env', target_env\n",
    "        )\n",
    "        \n",
    "        # Null distribution: permute environment labels within strata\n",
    "        null_log_ors = []\n",
    "        for _ in range(N_PERMUTATIONS):\n",
    "            perm_env = constrained_permutation(analysis_df, 'primary_env', 'stratum')\n",
    "            perm_df = analysis_df.copy()\n",
    "            perm_df['perm_env'] = perm_env\n",
    "            null_or, _, _, _, _ = compute_odds_ratio(\n",
    "                perm_df, has_col, 'perm_env', target_env\n",
    "            )\n",
    "            null_log_ors.append(null_or)\n",
    "        \n",
    "        null_mean = np.mean(null_log_ors)\n",
    "        null_std = np.std(null_log_ors)\n",
    "        z_score = (obs_log_or - null_mean) / null_std if null_std > 0 else 0\n",
    "        \n",
    "        # Empirical p-value (two-sided)\n",
    "        n_extreme = sum(1 for x in null_log_ors if abs(x) >= abs(obs_log_or))\n",
    "        p_empirical = (n_extreme + 1) / (N_PERMUTATIONS + 1)\n",
    "        \n",
    "        enrichment_results.append({\n",
    "            'module': module_id,\n",
    "            'module_name': MODULES[module_id]['full_name'],\n",
    "            'environment': target_env,\n",
    "            'observed_log2_OR': obs_log_or,\n",
    "            'null_mean_log2_OR': null_mean,\n",
    "            'null_std_log2_OR': null_std,\n",
    "            'z_score': z_score,\n",
    "            'p_empirical': p_empirical,\n",
    "            'n_env_module': a,\n",
    "            'n_env_no_module': b,\n",
    "            'n_other_module': c,\n",
    "            'n_other_no_module': d,\n",
    "        })\n",
    "    \n",
    "    print(f'  Completed {module_id}')\n",
    "\n",
    "enrichment_df = pd.DataFrame(enrichment_results)\n",
    "print(f'\\nTotal module × environment tests: {len(enrichment_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR correction\n",
    "if len(enrichment_df) > 0:\n",
    "    reject, pvals_corrected, _, _ = multipletests(\n",
    "        enrichment_df['p_empirical'], method='fdr_bh'\n",
    "    )\n",
    "    enrichment_df['p_fdr'] = pvals_corrected\n",
    "    enrichment_df['significant_fdr'] = reject\n",
    "\n",
    "# Show significant enrichments\n",
    "sig_enrichments = enrichment_df[\n",
    "    enrichment_df['significant_fdr'] == True\n",
    "].sort_values('z_score', ascending=False)\n",
    "\n",
    "print(f'Significant module × environment enrichments (FDR < 0.05): {len(sig_enrichments)}')\n",
    "if len(sig_enrichments) > 0:\n",
    "    print('\\nTop enrichments (highest z-score):')\n",
    "    display_cols = ['module_name', 'environment', 'observed_log2_OR', 'z_score', 'p_fdr']\n",
    "    print(sig_enrichments[display_cols].head(20).to_string(index=False))\n",
    "\n",
    "# Show significant depletions\n",
    "sig_depletions = enrichment_df[\n",
    "    (enrichment_df['significant_fdr'] == True) &\n",
    "    (enrichment_df['z_score'] < 0)\n",
    "].sort_values('z_score')\n",
    "\n",
    "if len(sig_depletions) > 0:\n",
    "    print('\\nTop depletions (most negative z-score):')\n",
    "    print(sig_depletions[display_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Lineage × Environment Enrichment\n",
    "\n",
    "Test which TerL-defined lineages are enriched in specific environments beyond phylogenetic expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_enrichment_results = []\n",
    "\n",
    "if lineages is not None:\n",
    "    # Merge lineage data with species environment info\n",
    "    lineage_species = lineages.merge(\n",
    "        analysis_df[['gtdb_species_clade_id', 'primary_env', 'family',\n",
    "                      'genome_size_Mbp', 'stratum']],\n",
    "        on='gtdb_species_clade_id', how='inner'\n",
    "    )\n",
    "    \n",
    "    # Get lineages with sufficient representation (>= 10 species)\n",
    "    lineage_counts = lineage_species['lineage_id'].value_counts()\n",
    "    major_lineages = lineage_counts[lineage_counts >= 10].index.tolist()\n",
    "    print(f'Lineages with >= 10 species in analysis set: {len(major_lineages)}')\n",
    "    \n",
    "    # Create binary lineage presence per species\n",
    "    species_lineage = lineage_species.groupby(\n",
    "        ['gtdb_species_clade_id', 'lineage_id']\n",
    "    ).size().reset_index(name='count')\n",
    "    \n",
    "    for lineage_id in major_lineages[:50]:  # cap at 50 lineages to keep runtime manageable\n",
    "        # Which species have this lineage?\n",
    "        species_with_lineage = set(\n",
    "            species_lineage[species_lineage['lineage_id'] == lineage_id]['gtdb_species_clade_id']\n",
    "        )\n",
    "        analysis_df_copy = analysis_df.copy()\n",
    "        analysis_df_copy['has_lineage'] = analysis_df_copy['gtdb_species_clade_id'].isin(species_with_lineage)\n",
    "        \n",
    "        for target_env in valid_envs:\n",
    "            obs_log_or, a, b, c, d = compute_odds_ratio(\n",
    "                analysis_df_copy, 'has_lineage', 'primary_env', target_env\n",
    "            )\n",
    "            \n",
    "            # Constrained permutation null\n",
    "            null_log_ors = []\n",
    "            for _ in range(500):  # fewer permutations for lineages (more tests)\n",
    "                perm_env = constrained_permutation(analysis_df_copy, 'primary_env', 'stratum')\n",
    "                perm_df = analysis_df_copy.copy()\n",
    "                perm_df['perm_env'] = perm_env\n",
    "                null_or, _, _, _, _ = compute_odds_ratio(\n",
    "                    perm_df, 'has_lineage', 'perm_env', target_env\n",
    "                )\n",
    "                null_log_ors.append(null_or)\n",
    "            \n",
    "            null_mean = np.mean(null_log_ors)\n",
    "            null_std = np.std(null_log_ors)\n",
    "            z_score = (obs_log_or - null_mean) / null_std if null_std > 0 else 0\n",
    "            n_extreme = sum(1 for x in null_log_ors if abs(x) >= abs(obs_log_or))\n",
    "            p_empirical = (n_extreme + 1) / (501)\n",
    "            \n",
    "            lineage_enrichment_results.append({\n",
    "                'lineage_id': lineage_id,\n",
    "                'environment': target_env,\n",
    "                'n_species_with_lineage': len(species_with_lineage),\n",
    "                'observed_log2_OR': obs_log_or,\n",
    "                'z_score': z_score,\n",
    "                'p_empirical': p_empirical,\n",
    "            })\n",
    "        \n",
    "        if major_lineages.index(lineage_id) % 10 == 0:\n",
    "            print(f'  Completed {major_lineages.index(lineage_id)+1}/{min(50, len(major_lineages))} lineages')\n",
    "\n",
    "lineage_enrich_df = pd.DataFrame(lineage_enrichment_results)\n",
    "\n",
    "if len(lineage_enrich_df) > 0:\n",
    "    reject, pvals_corrected, _, _ = multipletests(\n",
    "        lineage_enrich_df['p_empirical'], method='fdr_bh'\n",
    "    )\n",
    "    lineage_enrich_df['p_fdr'] = pvals_corrected\n",
    "    lineage_enrich_df['significant_fdr'] = reject\n",
    "    \n",
    "    sig_lineages = lineage_enrich_df[lineage_enrich_df['significant_fdr'] == True]\n",
    "    print(f'\\nSignificant lineage × environment enrichments (FDR < 0.05): {len(sig_lineages)}')\n",
    "    if len(sig_lineages) > 0:\n",
    "        print(sig_lineages.sort_values('z_score', ascending=False).head(15).to_string(index=False))\n",
    "else:\n",
    "    print('No lineage enrichment tests were performed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Specialist vs Generalist Lineages\n",
    "\n",
    "Classify lineages as environment-specialists (concentrated in 1-2 environments) vs generalists (broadly distributed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lineages is not None and len(lineage_species) > 0:\n",
    "    # Compute environmental breadth per lineage\n",
    "    lineage_env_dist = lineage_species.groupby('lineage_id')['primary_env'].value_counts(\n",
    "        normalize=True\n",
    "    ).unstack(fill_value=0)\n",
    "    \n",
    "    # Shannon entropy as environmental breadth metric\n",
    "    def shannon_entropy(row):\n",
    "        probs = row[row > 0].values\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "    \n",
    "    lineage_env_dist['shannon'] = lineage_env_dist.apply(shannon_entropy, axis=1)\n",
    "    lineage_env_dist['n_species'] = lineage_species.groupby('lineage_id')['gtdb_species_clade_id'].nunique()\n",
    "    lineage_env_dist['dominant_env'] = lineage_env_dist.drop(\n",
    "        columns=['shannon', 'n_species']\n",
    "    ).idxmax(axis=1)\n",
    "    lineage_env_dist['dominant_pct'] = lineage_env_dist.drop(\n",
    "        columns=['shannon', 'n_species', 'dominant_env']\n",
    "    ).max(axis=1) * 100\n",
    "    \n",
    "    # Filter to lineages with >= 5 species for meaningful breadth\n",
    "    lineage_breadth = lineage_env_dist[\n",
    "        lineage_env_dist['n_species'] >= 5\n",
    "    ][['shannon', 'n_species', 'dominant_env', 'dominant_pct']].reset_index()\n",
    "    \n",
    "    # Classify: specialist (shannon < 1.0 or dominant_pct > 80%) vs generalist\n",
    "    lineage_breadth['category'] = 'generalist'\n",
    "    lineage_breadth.loc[\n",
    "        (lineage_breadth['shannon'] < 1.0) | (lineage_breadth['dominant_pct'] > 80),\n",
    "        'category'\n",
    "    ] = 'specialist'\n",
    "    \n",
    "    print(f'Lineages with >= 5 species: {len(lineage_breadth):,}')\n",
    "    print(f'\\nSpecialist vs Generalist:')\n",
    "    print(lineage_breadth['category'].value_counts())\n",
    "    \n",
    "    print(f'\\nTop specialist lineages (lowest Shannon entropy):')\n",
    "    top_specialists = lineage_breadth.nsmallest(10, 'shannon')\n",
    "    print(top_specialists[['lineage_id', 'n_species', 'dominant_env',\n",
    "                           'dominant_pct', 'shannon']].to_string(index=False))\n",
    "    \n",
    "    print(f'\\nTop generalist lineages (highest Shannon entropy):')\n",
    "    top_generalists = lineage_breadth.nlargest(10, 'shannon')\n",
    "    print(top_generalists[['lineage_id', 'n_species', 'dominant_env',\n",
    "                           'dominant_pct', 'shannon']].to_string(index=False))\n",
    "else:\n",
    "    lineage_breadth = None\n",
    "    print('No lineage data available for specialist/generalist classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation with NMDC Data\n",
    "\n",
    "Check whether pangenome-enriched module × environment patterns match the NMDC signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nmdc_module_corr is not None and len(enrichment_df) > 0:\n",
    "    # The pangenome tells us which modules are enriched in which environments\n",
    "    # NMDC tells us which modules correlate with which abiotic variables\n",
    "    # Cross-validation: do soil-enriched modules (pangenome) also correlate with\n",
    "    # soil-related abiotic variables (NMDC) like pH, organic carbon, etc.?\n",
    "    \n",
    "    print('=== Cross-validation: Pangenome enrichment vs NMDC abiotic correlations ===')\n",
    "    \n",
    "    # Pangenome: significant module × environment enrichments\n",
    "    print('\\nPangenome: significant enrichments')\n",
    "    if len(sig_enrichments) > 0:\n",
    "        for _, row in sig_enrichments.head(10).iterrows():\n",
    "            print(f'  {row[\"module_name\"]} in {row[\"environment\"]}: '\n",
    "                  f'log2(OR)={row[\"observed_log2_OR\"]:.2f}, z={row[\"z_score\"]:.2f}')\n",
    "    else:\n",
    "        print('  No significant enrichments found')\n",
    "    \n",
    "    # NMDC: significant module × abiotic correlations\n",
    "    nmdc_sig = nmdc_module_corr[nmdc_module_corr.get('significant_fdr', False) == True]\n",
    "    print(f'\\nNMDC: significant module-abiotic correlations: {len(nmdc_sig)}')\n",
    "    if len(nmdc_sig) > 0:\n",
    "        for _, row in nmdc_sig.head(10).iterrows():\n",
    "            clean = row['abiotic_variable'].replace('annotations_', '').replace('_has_numeric_value', '')\n",
    "            print(f'  {row[\"module_name\"]} ~ {clean}: rho={row[\"spearman_rho\"]:.3f}')\n",
    "    \n",
    "    # Module-level concordance: do the same modules show up in both?\n",
    "    if len(sig_enrichments) > 0 and len(nmdc_sig) > 0:\n",
    "        pangenome_modules = set(sig_enrichments['module'].unique())\n",
    "        nmdc_modules = set(nmdc_sig['module'].unique())\n",
    "        overlap = pangenome_modules & nmdc_modules\n",
    "        print(f'\\nModules significant in both pangenome and NMDC: {overlap}')\n",
    "        print(f'Pangenome-only: {pangenome_modules - nmdc_modules}')\n",
    "        print(f'NMDC-only: {nmdc_modules - pangenome_modules}')\n",
    "else:\n",
    "    print('NMDC cross-validation data not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save module enrichment results\n",
    "enrichment_df.to_csv('../data/enriched_modules.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/enriched_modules.tsv: {len(enrichment_df):,} rows')\n",
    "\n",
    "# Save lineage enrichment results\n",
    "if len(lineage_enrich_df) > 0:\n",
    "    lineage_enrich_df.to_csv('../data/enriched_lineages.tsv', sep='\\t', index=False)\n",
    "    print(f'Saved data/enriched_lineages.tsv: {len(lineage_enrich_df):,} rows')\n",
    "else:\n",
    "    print('No lineage enrichment data to save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Figure 1: Module × environment enrichment heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel A: Z-scores\n",
    "ax = axes[0]\n",
    "if len(enrichment_df) > 0:\n",
    "    pivot_z = enrichment_df.pivot_table(\n",
    "        index='module_name', columns='environment', values='z_score'\n",
    "    )\n",
    "    sns.heatmap(pivot_z, cmap='RdBu_r', center=0, annot=True, fmt='.1f', ax=ax,\n",
    "                cbar_kws={'label': 'Z-score (vs null model)'})\n",
    "    ax.set_title('Module × Environment Enrichment\\n(Z-score vs constrained null)')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "# Panel B: log2 OR (observed)\n",
    "ax = axes[1]\n",
    "if len(enrichment_df) > 0:\n",
    "    pivot_or = enrichment_df.pivot_table(\n",
    "        index='module_name', columns='environment', values='observed_log2_OR'\n",
    "    )\n",
    "    # Mark significance with asterisks\n",
    "    annot_matrix = pivot_or.copy().round(1).astype(str)\n",
    "    for idx in enrichment_df.index:\n",
    "        row = enrichment_df.loc[idx]\n",
    "        if row.get('significant_fdr', False):\n",
    "            annot_matrix.loc[row['module_name'], row['environment']] += '*'\n",
    "    \n",
    "    sns.heatmap(pivot_or, cmap='RdBu_r', center=0, annot=annot_matrix.values,\n",
    "                fmt='', ax=ax, cbar_kws={'label': 'log2(Odds Ratio)'})\n",
    "    ax.set_title('Module × Environment Observed Enrichment\\n(* = FDR < 0.05)')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/module_environment_enrichment.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/module_environment_enrichment.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Lineage environment breadth and specialist/generalist\n",
    "if lineage_breadth is not None and len(lineage_breadth) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Panel A: Shannon entropy distribution\n",
    "    ax = axes[0]\n",
    "    specialist_mask = lineage_breadth['category'] == 'specialist'\n",
    "    ax.hist(lineage_breadth.loc[specialist_mask, 'shannon'], bins=30,\n",
    "            alpha=0.7, color='#E91E63', label='Specialist')\n",
    "    ax.hist(lineage_breadth.loc[~specialist_mask, 'shannon'], bins=30,\n",
    "            alpha=0.7, color='#2196F3', label='Generalist')\n",
    "    ax.set_xlabel('Shannon entropy (environmental breadth)')\n",
    "    ax.set_ylabel('Number of lineages')\n",
    "    ax.set_title('Lineage Environmental Breadth')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Panel B: Dominant environment distribution for specialists\n",
    "    ax = axes[1]\n",
    "    specialists = lineage_breadth[specialist_mask]\n",
    "    if len(specialists) > 0:\n",
    "        env_counts = specialists['dominant_env'].value_counts()\n",
    "        ax.barh(env_counts.index, env_counts.values, color='#E91E63', alpha=0.8)\n",
    "        ax.set_xlabel('Number of specialist lineages')\n",
    "        ax.set_title('Dominant Environment of Specialist Lineages')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/lineage_environment_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved figures/lineage_environment_heatmap.png')\n",
    "else:\n",
    "    print('No lineage data for figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('='*60)\n",
    "print('NB06 SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Species analyzed: {len(analysis_df):,}')\n",
    "print(f'Module × environment tests: {len(enrichment_df)}')\n",
    "n_sig_mod = len(sig_enrichments) if len(enrichment_df) > 0 else 0\n",
    "print(f'Significant module enrichments (FDR<0.05): {n_sig_mod}')\n",
    "\n",
    "if len(lineage_enrich_df) > 0:\n",
    "    n_sig_lin = lineage_enrich_df['significant_fdr'].sum() if 'significant_fdr' in lineage_enrich_df else 0\n",
    "    print(f'Lineage × environment tests: {len(lineage_enrich_df)}')\n",
    "    print(f'Significant lineage enrichments (FDR<0.05): {n_sig_lin}')\n",
    "\n",
    "if lineage_breadth is not None:\n",
    "    n_spec = (lineage_breadth['category'] == 'specialist').sum()\n",
    "    n_gen = (lineage_breadth['category'] == 'generalist').sum()\n",
    "    print(f'Lineage classification: {n_spec} specialists, {n_gen} generalists')\n",
    "\n",
    "print(f'\\nFiles saved:')\n",
    "print(f'  data/enriched_modules.tsv')\n",
    "if len(lineage_enrich_df) > 0:\n",
    "    print(f'  data/enriched_lineages.tsv')\n",
    "print(f'  figures/module_environment_enrichment.png')\n",
    "if lineage_breadth is not None:\n",
    "    print(f'  figures/lineage_environment_heatmap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}