{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB04: Phylogenetic Distribution & Variance Partitioning\n",
    "\n",
    "**Project**: Prophage Ecology Across Bacterial Phylogeny and Environmental Gradients\n",
    "\n",
    "**Goal**: Map prophage module prevalence across GTDB taxonomy; partition variance into phylogeny vs environment components; control for genome size and assembly completeness.\n",
    "\n",
    "**Dependencies**: NB01 outputs (`data/prophage_gene_clusters.tsv`, `data/species_module_summary.tsv`), NB02 (`data/terL_lineages.tsv`), NB03 (`data/module_cooccurrence_stats.tsv`)\n",
    "\n",
    "**Environment**: Requires BERDL JupyterHub (Spark SQL) for environment metadata extraction; statistical analysis runs locally.\n",
    "\n",
    "**Outputs**:\n",
    "- `data/species_prophage_environment.tsv` — merged species × module × environment × genome size\n",
    "- `data/variance_partitioning_results.tsv` — PERMANOVA results\n",
    "- `data/species_genome_size.tsv` — genome size data\n",
    "- `figures/prophage_prevalence_by_phylum.png`\n",
    "- `figures/variance_partitioning.png`\n",
    "- `figures/genome_size_confound.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "spark = get_spark_session()\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from prophage_utils import MODULES\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "# Load NB01 outputs\n",
    "species_summary = pd.read_csv('../data/species_module_summary.tsv', sep='\\t')\n",
    "prophage_clusters = pd.read_csv('../data/prophage_gene_clusters.tsv', sep='\\t')\n",
    "\n",
    "# Load NB02 lineage data if available\n",
    "try:\n",
    "    lineages = pd.read_csv('../data/terL_lineages.tsv', sep='\\t')\n",
    "    lineage_summary = pd.read_csv('../data/lineage_summary.tsv', sep='\\t')\n",
    "    print(f'TerL lineages: {lineages[\"lineage_id\"].nunique():,}')\n",
    "except FileNotFoundError:\n",
    "    lineages = None\n",
    "    lineage_summary = None\n",
    "    print('NB02 outputs not found — lineage analysis will be skipped')\n",
    "\n",
    "print(f'Species with prophage: {len(species_summary):,}')\n",
    "print(f'Prophage clusters: {len(prophage_clusters):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. GTDB Taxonomy & Prophage Prevalence by Phylum\n",
    "\n",
    "Map prophage module presence across GTDB taxonomy tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full GTDB taxonomy for all species\n",
    "taxonomy = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT g.gtdb_species_clade_id,\n",
    "           t.phylum, t.class, t.order, t.family, t.genus\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.gtdb_taxonomy_r214v1 t ON g.gtdb_taxonomy_id = t.gtdb_taxonomy_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Get total species count per phylum (denominator for prevalence)\n",
    "total_species = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT g.gtdb_species_clade_id) as n\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "\"\"\").toPandas()['n'].iloc[0]\n",
    "\n",
    "print(f'Taxonomy entries: {len(taxonomy):,}')\n",
    "print(f'Total species in pangenome: {total_species:,}')\n",
    "print(f'Phyla: {taxonomy[\"phylum\"].nunique()}')\n",
    "\n",
    "# Merge with species module summary\n",
    "species_tax = species_summary.merge(taxonomy, on='gtdb_species_clade_id', how='left')\n",
    "print(f'\\nSpecies with taxonomy + prophage: {len(species_tax):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophage prevalence by phylum\n",
    "phylum_stats = []\n",
    "all_phylum_species = taxonomy.groupby('phylum')['gtdb_species_clade_id'].nunique()\n",
    "\n",
    "for phylum, grp in species_tax.groupby('phylum'):\n",
    "    total_in_phylum = all_phylum_species.get(phylum, 0)\n",
    "    row = {\n",
    "        'phylum': phylum,\n",
    "        'n_species_total': total_in_phylum,\n",
    "        'n_species_prophage': len(grp),\n",
    "        'pct_with_prophage': len(grp) / total_in_phylum * 100 if total_in_phylum > 0 else 0,\n",
    "        'mean_modules': grp['n_modules_present'].mean(),\n",
    "        'mean_prophage_clusters': grp['n_prophage_clusters'].mean(),\n",
    "    }\n",
    "    for module_id in MODULES.keys():\n",
    "        row[f'pct_{module_id}'] = grp[f'has_{module_id}'].mean() * 100\n",
    "    phylum_stats.append(row)\n",
    "\n",
    "phylum_df = pd.DataFrame(phylum_stats).sort_values('n_species_prophage', ascending=False)\n",
    "\n",
    "print('Top 20 phyla by prophage-carrying species:')\n",
    "display_cols = ['phylum', 'n_species_total', 'n_species_prophage', 'pct_with_prophage', 'mean_modules']\n",
    "print(phylum_df[display_cols].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module prevalence by phylum (top 15 phyla with most prophage-carrying species)\n",
    "top_phyla = phylum_df.head(15)['phylum'].tolist()\n",
    "module_cols = [f'pct_{m}' for m in sorted(MODULES.keys())]\n",
    "module_names = [MODULES[m]['full_name'] for m in sorted(MODULES.keys())]\n",
    "\n",
    "print('Module prevalence (% of species) by phylum:')\n",
    "phylum_module_df = phylum_df[phylum_df['phylum'].isin(top_phyla)][['phylum'] + module_cols].copy()\n",
    "phylum_module_df.columns = ['phylum'] + module_names\n",
    "print(phylum_module_df.round(1).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Environment Metadata\n",
    "\n",
    "Extract environment classifications from `ncbi_env` (EAV format) following the established pattern from PHB NB03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract environment metadata for all genomes (pivot from EAV)\n",
    "env_data = spark.sql(\"\"\"\n",
    "    SELECT g.genome_id, g.gtdb_species_clade_id,\n",
    "           MAX(CASE WHEN ne.harmonized_name = 'isolation_source' THEN ne.content END) as isolation_source,\n",
    "           MAX(CASE WHEN ne.harmonized_name = 'env_broad_scale' THEN ne.content END) as env_broad_scale,\n",
    "           MAX(CASE WHEN ne.harmonized_name = 'env_local_scale' THEN ne.content END) as env_local_scale,\n",
    "           MAX(CASE WHEN ne.harmonized_name = 'env_medium' THEN ne.content END) as env_medium,\n",
    "           MAX(CASE WHEN ne.harmonized_name = 'host' THEN ne.content END) as host\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.ncbi_env ne ON g.ncbi_biosample_id = ne.accession\n",
    "    GROUP BY g.genome_id, g.gtdb_species_clade_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Genomes with environment metadata: {len(env_data):,}')\n",
    "print(f'Species represented: {env_data[\"gtdb_species_clade_id\"].nunique():,}')\n",
    "print(f'\\nField coverage:')\n",
    "for col in ['isolation_source', 'env_broad_scale', 'env_local_scale', 'host']:\n",
    "    n = env_data[col].notna().sum()\n",
    "    print(f'  {col}: {n:,} ({n/len(env_data)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify environments into broad categories\n",
    "def classify_environment(row):\n",
    "    \"\"\"Classify genome environment from NCBI metadata.\"\"\"\n",
    "    source = str(row.get('isolation_source', '')).lower()\n",
    "    host = str(row.get('host', '')).lower()\n",
    "    env_broad = str(row.get('env_broad_scale', '')).lower()\n",
    "    \n",
    "    if any(kw in source for kw in ['blood', 'sputum', 'urine', 'wound', 'clinical',\n",
    "                                     'patient', 'hospital', 'human']):\n",
    "        return 'human_clinical'\n",
    "    if 'homo sapiens' in host or 'human' in host:\n",
    "        return 'human_associated'\n",
    "    if any(kw in source for kw in ['animal', 'bovine', 'chicken', 'pig', 'cattle',\n",
    "                                     'poultry', 'feces', 'gut', 'intestin']):\n",
    "        return 'animal_associated'\n",
    "    if any(kw in source for kw in ['soil', 'rhizosphere', 'root', 'compost', 'peat']):\n",
    "        return 'soil'\n",
    "    if any(kw in source for kw in ['plant', 'leaf', 'stem', 'flower', 'seed', 'phyllosphere']):\n",
    "        return 'plant_associated'\n",
    "    if any(kw in source for kw in ['freshwater', 'lake', 'river', 'pond', 'stream',\n",
    "                                     'groundwater', 'spring']):\n",
    "        return 'freshwater'\n",
    "    if any(kw in source for kw in ['marine', 'ocean', 'sea', 'seawater', 'coastal',\n",
    "                                     'estuarine', 'estuary', 'tidal', 'coral']):\n",
    "        return 'marine'\n",
    "    if any(kw in source for kw in ['wastewater', 'sewage', 'activated sludge', 'bioreactor',\n",
    "                                     'ferment']):\n",
    "        return 'wastewater_engineered'\n",
    "    if any(kw in source for kw in ['sediment', 'mud', 'silt']):\n",
    "        return 'sediment'\n",
    "    if any(kw in source for kw in ['food', 'milk', 'cheese', 'meat', 'fish']):\n",
    "        return 'food'\n",
    "    return 'other_unknown'\n",
    "\n",
    "env_data['env_category'] = env_data.apply(classify_environment, axis=1)\n",
    "print('Environment classification:')\n",
    "print(env_data['env_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate environment to species level (most common env category)\n",
    "species_env = env_data.groupby('gtdb_species_clade_id').agg(\n",
    "    n_genomes_with_env=('genome_id', 'count'),\n",
    "    primary_env=('env_category', lambda x: x.value_counts().index[0]),\n",
    "    n_env_categories=('env_category', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "print(f'Species with environment data: {len(species_env):,}')\n",
    "print(f'\\nPrimary environment distribution:')\n",
    "print(species_env['primary_env'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. Genome Size & Assembly Completeness\n",
    "\n",
    "Extract genome size and CheckM completeness to use as covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get species-level genome size and completeness from gtdb_metadata\n",
    "genome_meta = spark.sql(\"\"\"\n",
    "    SELECT g.gtdb_species_clade_id,\n",
    "           COUNT(*) as n_genomes,\n",
    "           AVG(CAST(m.genome_size AS DOUBLE)) as mean_genome_size_bp,\n",
    "           PERCENTILE_APPROX(CAST(m.genome_size AS DOUBLE), 0.5) as median_genome_size_bp,\n",
    "           AVG(CAST(m.protein_count AS DOUBLE)) as mean_protein_count,\n",
    "           AVG(CAST(m.checkm_completeness AS DOUBLE)) as mean_completeness,\n",
    "           AVG(CAST(m.checkm_contamination AS DOUBLE)) as mean_contamination\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.gtdb_metadata m ON g.genome_id = m.accession\n",
    "    WHERE m.genome_size IS NOT NULL\n",
    "    GROUP BY g.gtdb_species_clade_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "genome_meta['genome_size_Mbp'] = genome_meta['mean_genome_size_bp'] / 1e6\n",
    "\n",
    "print(f'Species with genome metadata: {len(genome_meta):,}')\n",
    "print(f'\\nGenome size (Mbp):')\n",
    "print(genome_meta['genome_size_Mbp'].describe())\n",
    "print(f'\\nCompleteness:')\n",
    "print(genome_meta['mean_completeness'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genome size vs prophage module count\n",
    "species_size = genome_meta.merge(\n",
    "    species_summary[['gtdb_species_clade_id', 'n_prophage_clusters', 'n_modules_present']],\n",
    "    on='gtdb_species_clade_id', how='left'\n",
    ")\n",
    "species_size['n_prophage_clusters'] = species_size['n_prophage_clusters'].fillna(0)\n",
    "species_size['n_modules_present'] = species_size['n_modules_present'].fillna(0)\n",
    "species_size['has_prophage'] = species_size['n_prophage_clusters'] > 0\n",
    "\n",
    "# Correlation: genome size vs prophage count\n",
    "rho_size_count, p_size_count = stats.spearmanr(\n",
    "    species_size['genome_size_Mbp'], species_size['n_prophage_clusters'])\n",
    "\n",
    "# Genome size: prophage+ vs prophage-\n",
    "prophage_pos_size = species_size[species_size['has_prophage']]['genome_size_Mbp']\n",
    "prophage_neg_size = species_size[~species_size['has_prophage']]['genome_size_Mbp']\n",
    "u_stat, p_size_mw = stats.mannwhitneyu(prophage_pos_size, prophage_neg_size, alternative='two-sided')\n",
    "\n",
    "print(f'Genome size vs prophage cluster count: rho={rho_size_count:.3f}, p={p_size_count:.2e}')\n",
    "print(f'\\nGenome size (Mbp):')\n",
    "print(f'  Prophage+: median={prophage_pos_size.median():.2f}, n={len(prophage_pos_size):,}')\n",
    "print(f'  Prophage-: median={prophage_neg_size.median():.2f}, n={len(prophage_neg_size):,}')\n",
    "print(f'  Mann-Whitney p={p_size_mw:.2e}')\n",
    "print(f'  Difference: {prophage_pos_size.median() - prophage_neg_size.median():.2f} Mbp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Merge All Data & Prophage by Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge species summary + taxonomy + environment + genome size\n",
    "species_all = species_summary.merge(taxonomy, on='gtdb_species_clade_id', how='left')\n",
    "species_all = species_all.merge(species_env, on='gtdb_species_clade_id', how='left')\n",
    "species_all = species_all.merge(\n",
    "    genome_meta[['gtdb_species_clade_id', 'genome_size_Mbp', 'mean_protein_count',\n",
    "                  'mean_completeness', 'mean_contamination']],\n",
    "    on='gtdb_species_clade_id', how='left'\n",
    ")\n",
    "\n",
    "# Add lineage count per species if available\n",
    "if lineages is not None:\n",
    "    lineage_per_species = lineages.groupby('gtdb_species_clade_id')['lineage_id'].nunique().reset_index()\n",
    "    lineage_per_species.columns = ['gtdb_species_clade_id', 'n_lineages']\n",
    "    species_all = species_all.merge(lineage_per_species, on='gtdb_species_clade_id', how='left')\n",
    "    species_all['n_lineages'] = species_all['n_lineages'].fillna(0).astype(int)\n",
    "\n",
    "print(f'Species with all data merged: {len(species_all):,}')\n",
    "print(f'With environment: {species_all[\"primary_env\"].notna().sum():,}')\n",
    "print(f'With genome size: {species_all[\"genome_size_Mbp\"].notna().sum():,}')\n",
    "\n",
    "# Prophage module prevalence by environment\n",
    "env_mask = species_all['primary_env'].notna() & (species_all['primary_env'] != 'other_unknown')\n",
    "species_known_env = species_all[env_mask]\n",
    "\n",
    "print(f'\\nProphage module prevalence by environment:')\n",
    "for env_cat, egrp in species_known_env.groupby('primary_env'):\n",
    "    n = len(egrp)\n",
    "    if n < 10:\n",
    "        continue\n",
    "    modules_str = '  '.join(\n",
    "        f'{m[:3]}={egrp[f\"has_{m}\"].mean()*100:.0f}%' for m in sorted(MODULES.keys())\n",
    "    )\n",
    "    print(f'  {env_cat:25s} (n={n:5d}): {modules_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Variance Partitioning: PERMANOVA\n",
    "\n",
    "Use PERMANOVA (Anderson 2001) to partition variance in prophage module composition into:\n",
    "- Phylogeny (GTDB family)\n",
    "- Environment (primary_env category)\n",
    "- Genome size (quartiles)\n",
    "\n",
    "We use family-level taxonomy as the phylogenetic grouping variable since it provides a balance between resolution and group sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.distance import permanova\n",
    "from skbio import DistanceMatrix\n",
    "\n",
    "# Prepare data for PERMANOVA\n",
    "# Filter to species with known environment, taxonomy, and genome size\n",
    "permanova_df = species_all[\n",
    "    species_all['primary_env'].notna() &\n",
    "    (species_all['primary_env'] != 'other_unknown') &\n",
    "    species_all['family'].notna() &\n",
    "    species_all['genome_size_Mbp'].notna()\n",
    "].copy()\n",
    "\n",
    "# Need sufficient observations per group; filter families with >= 3 species\n",
    "family_counts = permanova_df['family'].value_counts()\n",
    "valid_families = family_counts[family_counts >= 3].index\n",
    "permanova_df = permanova_df[permanova_df['family'].isin(valid_families)]\n",
    "\n",
    "# Create genome size quartiles\n",
    "permanova_df['size_quartile'] = pd.qcut(\n",
    "    permanova_df['genome_size_Mbp'], 4,\n",
    "    labels=['Q1_small', 'Q2', 'Q3', 'Q4_large']\n",
    ")\n",
    "\n",
    "print(f'Species for PERMANOVA: {len(permanova_df):,}')\n",
    "print(f'Families: {permanova_df[\"family\"].nunique()}')\n",
    "print(f'Environments: {permanova_df[\"primary_env\"].nunique()}')\n",
    "print(f'\\nEnvironment distribution:')\n",
    "print(permanova_df['primary_env'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prophage module composition matrix (species × 7 modules)\n",
    "module_ids = sorted(MODULES.keys())\n",
    "module_count_cols = [f'n_{m}' for m in module_ids]\n",
    "\n",
    "# Use count-based composition (how many clusters per module per species)\n",
    "X = permanova_df[module_count_cols].fillna(0).values\n",
    "\n",
    "# Compute Bray-Curtis distance matrix\n",
    "bc_dists = pdist(X, metric='braycurtis')\n",
    "# Handle NaN distances (species with all-zero module counts)\n",
    "bc_dists = np.nan_to_num(bc_dists, nan=1.0)\n",
    "\n",
    "dm = DistanceMatrix(bc_dists, ids=permanova_df['gtdb_species_clade_id'].tolist())\n",
    "\n",
    "print(f'Distance matrix: {dm.shape[0]} × {dm.shape[1]}')\n",
    "print(f'Mean Bray-Curtis distance: {np.mean(bc_dists):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERMANOVA tests\n",
    "# If dataset is too large for full PERMANOVA (>10K species), subsample\n",
    "MAX_PERMANOVA = 10000\n",
    "if len(permanova_df) > MAX_PERMANOVA:\n",
    "    print(f'Subsampling from {len(permanova_df):,} to {MAX_PERMANOVA:,} for PERMANOVA...')\n",
    "    subsample_idx = np.random.choice(len(permanova_df), MAX_PERMANOVA, replace=False)\n",
    "    perm_sub = permanova_df.iloc[subsample_idx].copy().reset_index(drop=True)\n",
    "    X_sub = X[subsample_idx]\n",
    "    bc_sub = pdist(X_sub, metric='braycurtis')\n",
    "    bc_sub = np.nan_to_num(bc_sub, nan=1.0)\n",
    "    dm_sub = DistanceMatrix(bc_sub, ids=perm_sub['gtdb_species_clade_id'].tolist())\n",
    "else:\n",
    "    perm_sub = permanova_df.copy()\n",
    "    dm_sub = dm\n",
    "\n",
    "# Recompute valid families for the subsample\n",
    "fam_counts_sub = perm_sub['family'].value_counts()\n",
    "valid_fam_sub = fam_counts_sub[fam_counts_sub >= 2].index\n",
    "fam_mask = perm_sub['family'].isin(valid_fam_sub)\n",
    "\n",
    "if fam_mask.sum() < len(perm_sub):\n",
    "    perm_sub_filt = perm_sub[fam_mask].reset_index(drop=True)\n",
    "    ids_filt = perm_sub_filt['gtdb_species_clade_id'].tolist()\n",
    "    dm_filt = dm_sub.filter(ids_filt)\n",
    "else:\n",
    "    perm_sub_filt = perm_sub\n",
    "    dm_filt = dm_sub\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test 1: Phylogeny (family)\n",
    "print('Running PERMANOVA: prophage composition ~ phylogeny (family)...')\n",
    "try:\n",
    "    res_phylo = permanova(dm_filt, perm_sub_filt['family'], permutations=999)\n",
    "    results.append({\n",
    "        'predictor': 'phylogeny_family',\n",
    "        'test_statistic': res_phylo['test statistic'],\n",
    "        'p_value': res_phylo['p-value'],\n",
    "        'n_groups': perm_sub_filt['family'].nunique(),\n",
    "        'n_samples': len(perm_sub_filt),\n",
    "    })\n",
    "    print(f'  F={res_phylo[\"test statistic\"]:.2f}, p={res_phylo[\"p-value\"]}')\n",
    "except Exception as e:\n",
    "    print(f'  Error: {e}')\n",
    "\n",
    "# Test 2: Environment\n",
    "print('Running PERMANOVA: prophage composition ~ environment...')\n",
    "try:\n",
    "    res_env = permanova(dm_filt, perm_sub_filt['primary_env'], permutations=999)\n",
    "    results.append({\n",
    "        'predictor': 'environment',\n",
    "        'test_statistic': res_env['test statistic'],\n",
    "        'p_value': res_env['p-value'],\n",
    "        'n_groups': perm_sub_filt['primary_env'].nunique(),\n",
    "        'n_samples': len(perm_sub_filt),\n",
    "    })\n",
    "    print(f'  F={res_env[\"test statistic\"]:.2f}, p={res_env[\"p-value\"]}')\n",
    "except Exception as e:\n",
    "    print(f'  Error: {e}')\n",
    "\n",
    "# Test 3: Genome size quartile\n",
    "print('Running PERMANOVA: prophage composition ~ genome size quartile...')\n",
    "try:\n",
    "    res_size = permanova(dm_filt, perm_sub_filt['size_quartile'].astype(str), permutations=999)\n",
    "    results.append({\n",
    "        'predictor': 'genome_size_quartile',\n",
    "        'test_statistic': res_size['test statistic'],\n",
    "        'p_value': res_size['p-value'],\n",
    "        'n_groups': 4,\n",
    "        'n_samples': len(perm_sub_filt),\n",
    "    })\n",
    "    print(f'  F={res_size[\"test statistic\"]:.2f}, p={res_size[\"p-value\"]}')\n",
    "except Exception as e:\n",
    "    print(f'  Error: {e}')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\n=== PERMANOVA Summary ===')\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Per-Module Environment Enrichment\n",
    "\n",
    "Test whether each module is enriched or depleted in specific environments, using chi-squared tests per module × environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-module chi-squared: is module prevalence different across environments?\n",
    "module_env_results = []\n",
    "\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    has_col = f'has_{module_id}'\n",
    "    ct = pd.crosstab(species_known_env['primary_env'], species_known_env[has_col])\n",
    "    if ct.shape[1] < 2:\n",
    "        continue\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(ct)\n",
    "    \n",
    "    # Compute per-environment prevalence\n",
    "    env_prev = species_known_env.groupby('primary_env')[has_col].mean()\n",
    "    overall_prev = species_known_env[has_col].mean()\n",
    "    \n",
    "    module_env_results.append({\n",
    "        'module': module_id,\n",
    "        'module_name': MODULES[module_id]['full_name'],\n",
    "        'chi2': chi2,\n",
    "        'p_value': p,\n",
    "        'dof': dof,\n",
    "        'overall_prevalence': overall_prev,\n",
    "        'max_env': env_prev.idxmax(),\n",
    "        'max_env_prev': env_prev.max(),\n",
    "        'min_env': env_prev.idxmin(),\n",
    "        'min_env_prev': env_prev.min(),\n",
    "    })\n",
    "    print(f'{module_id}: chi2={chi2:.1f}, p={p:.2e}')\n",
    "    print(f'  Overall: {overall_prev*100:.1f}%')\n",
    "    print(f'  Highest: {env_prev.idxmax()} ({env_prev.max()*100:.1f}%)')\n",
    "    print(f'  Lowest:  {env_prev.idxmin()} ({env_prev.min()*100:.1f}%)')\n",
    "\n",
    "module_env_df = pd.DataFrame(module_env_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Genome Size Confound Analysis\n",
    "\n",
    "Test whether prophage-environment associations hold after controlling for genome size (same stratification approach as PHB NB03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genome size stratified analysis\n",
    "# Does prophage module count vary by environment within each genome size quartile?\n",
    "species_with_size = species_all[\n",
    "    species_all['genome_size_Mbp'].notna() &\n",
    "    species_all['primary_env'].notna() &\n",
    "    (species_all['primary_env'] != 'other_unknown')\n",
    "].copy()\n",
    "\n",
    "species_with_size['size_quartile'] = pd.qcut(\n",
    "    species_with_size['genome_size_Mbp'], 4,\n",
    "    labels=['Q1 (small)', 'Q2', 'Q3', 'Q4 (large)']\n",
    ")\n",
    "\n",
    "print('Mean prophage module count by genome size quartile and environment:\\n')\n",
    "\n",
    "# Select environments with enough species\n",
    "env_counts = species_with_size['primary_env'].value_counts()\n",
    "major_envs = env_counts[env_counts >= 50].index.tolist()\n",
    "\n",
    "for q in ['Q1 (small)', 'Q2', 'Q3', 'Q4 (large)']:\n",
    "    q_sub = species_with_size[species_with_size['size_quartile'] == q]\n",
    "    size_range = f'{q_sub[\"genome_size_Mbp\"].min():.1f}-{q_sub[\"genome_size_Mbp\"].max():.1f} Mbp'\n",
    "    print(f'\\n{q} ({size_range}, n={len(q_sub):,}):')\n",
    "    \n",
    "    for env in sorted(major_envs):\n",
    "        e_sub = q_sub[q_sub['primary_env'] == env]\n",
    "        if len(e_sub) >= 5:\n",
    "            mean_modules = e_sub['n_modules_present'].mean()\n",
    "            pct_prophage = (e_sub['n_prophage_clusters'] > 0).mean() * 100\n",
    "            print(f'  {env:25s}: {pct_prophage:.0f}% with prophage, '\n",
    "                  f'mean {mean_modules:.1f} modules (n={len(e_sub)})')\n",
    "\n",
    "# Kruskal-Wallis per quartile: does module count differ by environment?\n",
    "print('\\n--- Kruskal-Wallis: module count ~ environment within each size quartile ---')\n",
    "for q in ['Q1 (small)', 'Q2', 'Q3', 'Q4 (large)']:\n",
    "    q_sub = species_with_size[species_with_size['size_quartile'] == q]\n",
    "    groups = [g['n_modules_present'].values for _, g in q_sub.groupby('primary_env') if len(g) >= 5]\n",
    "    if len(groups) >= 2:\n",
    "        h_stat, p_kw = stats.kruskal(*groups)\n",
    "        print(f'  {q}: H={h_stat:.1f}, p={p_kw:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Spearman: prophage burden ~ environment controlling for genome size\n",
    "# Encode environment as numeric (mean prophage rank to test gradient)\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def partial_spearman(x, y, z):\n",
    "    \"\"\"Partial Spearman correlation between x and y, controlling for z.\"\"\"\n",
    "    rx = rankdata(x)\n",
    "    ry = rankdata(y)\n",
    "    rz = rankdata(z)\n",
    "    cx = np.polyfit(rz, rx, 1)\n",
    "    cy = np.polyfit(rz, ry, 1)\n",
    "    res_x = rx - np.polyval(cx, rz)\n",
    "    res_y = ry - np.polyval(cy, rz)\n",
    "    return stats.spearmanr(res_x, res_y)\n",
    "\n",
    "# Test: prophage cluster count ~ genome size\n",
    "valid = species_with_size['n_prophage_clusters'].notna() & species_with_size['genome_size_Mbp'].notna()\n",
    "rho_raw, p_raw = stats.spearmanr(\n",
    "    species_with_size.loc[valid, 'n_prophage_clusters'],\n",
    "    species_with_size.loc[valid, 'genome_size_Mbp']\n",
    ")\n",
    "print(f'Prophage count ~ genome size: rho={rho_raw:.3f}, p={p_raw:.2e}')\n",
    "\n",
    "# For each module, test: module presence ~ environment (encoded) | genome size\n",
    "# Use soil as proxy for 'enriched' environment based on lysogeny literature\n",
    "species_with_size['is_soil'] = (species_with_size['primary_env'] == 'soil').astype(int)\n",
    "\n",
    "print('\\nPartial Spearman (module ~ soil | genome_size):')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    has_col = f'has_{module_id}'\n",
    "    valid = species_with_size[has_col].notna() & species_with_size['genome_size_Mbp'].notna()\n",
    "    if valid.sum() < 100:\n",
    "        continue\n",
    "    \n",
    "    rho_partial, p_partial = partial_spearman(\n",
    "        species_with_size.loc[valid, has_col].astype(float).values,\n",
    "        species_with_size.loc[valid, 'is_soil'].values,\n",
    "        species_with_size.loc[valid, 'genome_size_Mbp'].values\n",
    "    )\n",
    "    rho_unadj, p_unadj = stats.spearmanr(\n",
    "        species_with_size.loc[valid, has_col].astype(float),\n",
    "        species_with_size.loc[valid, 'is_soil']\n",
    "    )\n",
    "    print(f'  {module_id}: raw rho={rho_unadj:.3f}, partial rho={rho_partial:.3f} (p={p_partial:.2e})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 8. AlphaEarth Embedding Analysis\n",
    "\n",
    "Use 64-dim environmental embeddings (28% genome coverage) for continuous environmental gradient analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract AlphaEarth embeddings\n",
    "emb_cols = [f'A{i:02d}' for i in range(64)]\n",
    "emb_select = ', '.join([f'ae.{c}' for c in emb_cols])\n",
    "\n",
    "embeddings = spark.sql(f\"\"\"\n",
    "    SELECT g.genome_id, g.gtdb_species_clade_id,\n",
    "           {emb_select}\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.alphaearth_embeddings_all_years ae\n",
    "        ON g.genome_id = ae.genome_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f'Genomes with embeddings: {len(embeddings):,}')\n",
    "print(f'Species with embeddings: {embeddings[\"gtdb_species_clade_id\"].nunique():,}')\n",
    "\n",
    "# Filter NaN embeddings\n",
    "valid_mask = ~embeddings[emb_cols].isna().any(axis=1)\n",
    "embeddings = embeddings[valid_mask]\n",
    "print(f'After NaN filter: {len(embeddings):,} genomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-species embedding statistics\n",
    "species_emb = embeddings.groupby('gtdb_species_clade_id').agg(\n",
    "    n_genomes_emb=('genome_id', 'count'),\n",
    "    **{f'mean_{c}': (c, 'mean') for c in emb_cols},\n",
    "    **{f'var_{c}': (c, 'var') for c in emb_cols},\n",
    ").reset_index()\n",
    "\n",
    "var_cols = [f'var_{c}' for c in emb_cols]\n",
    "species_emb['total_emb_variance'] = species_emb[var_cols].sum(axis=1)\n",
    "\n",
    "# Filter to species with >= 5 genomes for stable estimates\n",
    "species_emb = species_emb[species_emb['n_genomes_emb'] >= 5]\n",
    "print(f'Species with >= 5 embedded genomes: {len(species_emb):,}')\n",
    "\n",
    "# Merge with prophage data\n",
    "emb_prophage = species_emb[['gtdb_species_clade_id', 'n_genomes_emb', 'total_emb_variance']].merge(\n",
    "    species_all[['gtdb_species_clade_id', 'n_prophage_clusters', 'n_modules_present',\n",
    "                  'genome_size_Mbp'] + [f'has_{m}' for m in MODULES.keys()]],\n",
    "    on='gtdb_species_clade_id', how='inner'\n",
    ")\n",
    "emb_prophage['has_prophage'] = emb_prophage['n_prophage_clusters'] > 0\n",
    "\n",
    "print(f'Species with embeddings + prophage data: {len(emb_prophage):,}')\n",
    "\n",
    "# Test: embedding variance (environmental breadth) vs prophage burden\n",
    "pos = emb_prophage[emb_prophage['has_prophage']]['total_emb_variance']\n",
    "neg = emb_prophage[~emb_prophage['has_prophage']]['total_emb_variance']\n",
    "u, p_emb = stats.mannwhitneyu(pos, neg, alternative='two-sided')\n",
    "\n",
    "print(f'\\nEmbedding variance (niche breadth):')\n",
    "print(f'  Prophage+: median={pos.median():.4f}, n={len(pos):,}')\n",
    "print(f'  Prophage-: median={neg.median():.4f}, n={len(neg):,}')\n",
    "print(f'  Mann-Whitney p={p_emb:.2e}')\n",
    "\n",
    "# Partial correlation controlling for genome size\n",
    "valid = emb_prophage['genome_size_Mbp'].notna()\n",
    "rho_partial_emb, p_partial_emb = partial_spearman(\n",
    "    emb_prophage.loc[valid, 'total_emb_variance'].values,\n",
    "    emb_prophage.loc[valid, 'n_modules_present'].values,\n",
    "    emb_prophage.loc[valid, 'genome_size_Mbp'].values\n",
    ")\n",
    "print(f'\\nPartial Spearman (emb_variance ~ modules | genome_size): rho={rho_partial_emb:.3f}, p={p_partial_emb:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 9. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged species data\n",
    "species_all.to_csv('../data/species_prophage_environment.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/species_prophage_environment.tsv: {len(species_all):,} rows')\n",
    "\n",
    "# Save PERMANOVA results\n",
    "results_df.to_csv('../data/variance_partitioning_results.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/variance_partitioning_results.tsv: {len(results_df)} rows')\n",
    "\n",
    "# Save genome size data\n",
    "species_size.to_csv('../data/species_genome_size.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/species_genome_size.tsv: {len(species_size):,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 10. Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Figure 1: Prophage module prevalence by phylum (heatmap)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Use top 15 phyla\n",
    "heatmap_data = phylum_df[phylum_df['phylum'].isin(top_phyla)].set_index('phylum')\n",
    "heatmap_cols = [f'pct_{m}' for m in sorted(MODULES.keys())]\n",
    "heatmap_labels = [MODULES[m]['full_name'] for m in sorted(MODULES.keys())]\n",
    "\n",
    "sns.heatmap(\n",
    "    heatmap_data[heatmap_cols].rename(columns=dict(zip(heatmap_cols, heatmap_labels))),\n",
    "    cmap='YlOrRd', annot=True, fmt='.0f',\n",
    "    ax=ax, cbar_kws={'label': '% species with module'}\n",
    ")\n",
    "ax.set_title('Prophage Module Prevalence by Phylum (top 15)')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/prophage_prevalence_by_phylum.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/prophage_prevalence_by_phylum.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Variance partitioning summary\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: PERMANOVA F-statistics\n",
    "ax = axes[0]\n",
    "if len(results_df) > 0:\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c'][:len(results_df)]\n",
    "    bars = ax.barh(results_df['predictor'], results_df['test_statistic'], color=colors)\n",
    "    for i, (_, row) in enumerate(results_df.iterrows()):\n",
    "        pstr = f'p={row[\"p_value\"]:.3f}' if row['p_value'] >= 0.001 else f'p<0.001'\n",
    "        ax.text(row['test_statistic'] + 0.5, i, pstr, va='center', fontsize=10)\n",
    "    ax.set_xlabel('PERMANOVA pseudo-F')\n",
    "    ax.set_title('Variance in Prophage Composition\\nExplained by Each Factor')\n",
    "\n",
    "# Panel B: Module prevalence by environment\n",
    "ax = axes[1]\n",
    "env_module_heatmap = species_known_env.groupby('primary_env')[\n",
    "    [f'has_{m}' for m in sorted(MODULES.keys())]\n",
    "].mean() * 100\n",
    "\n",
    "# Filter to environments with >= 50 species\n",
    "env_counts = species_known_env['primary_env'].value_counts()\n",
    "plot_envs = env_counts[env_counts >= 50].index\n",
    "env_module_heatmap = env_module_heatmap.loc[plot_envs]\n",
    "env_module_heatmap.columns = [MODULES[m]['full_name'] for m in sorted(MODULES.keys())]\n",
    "\n",
    "sns.heatmap(env_module_heatmap, cmap='YlOrRd', annot=True, fmt='.0f', ax=ax,\n",
    "            cbar_kws={'label': '% species'})\n",
    "ax.set_title('Module Prevalence by Environment')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/variance_partitioning.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/variance_partitioning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Genome size confound analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Panel A: Genome size distribution prophage+ vs prophage-\n",
    "ax = axes[0]\n",
    "ax.hist(prophage_neg_size, bins=50, alpha=0.6, color='#9E9E9E',\n",
    "        label=f'No prophage (n={len(prophage_neg_size):,})', density=True)\n",
    "ax.hist(prophage_pos_size, bins=50, alpha=0.6, color='#E91E63',\n",
    "        label=f'Prophage+ (n={len(prophage_pos_size):,})', density=True)\n",
    "ax.axvline(prophage_neg_size.median(), color='#616161', linestyle='--', linewidth=1.5)\n",
    "ax.axvline(prophage_pos_size.median(), color='#880E4F', linestyle='--', linewidth=1.5)\n",
    "ax.set_xlabel('Genome size (Mbp)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title(f'Genome Size: Prophage+ vs Prophage-\\n(p={p_size_mw:.2e})')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Panel B: Genome size vs prophage cluster count\n",
    "ax = axes[1]\n",
    "ax.scatter(species_size['genome_size_Mbp'], species_size['n_prophage_clusters'],\n",
    "           alpha=0.1, s=5, color='#E91E63')\n",
    "ax.set_xlabel('Genome size (Mbp)')\n",
    "ax.set_ylabel('Prophage cluster count')\n",
    "ax.set_title(f'Genome Size vs Prophage Burden\\n(rho={rho_size_count:.3f})')\n",
    "\n",
    "# Panel C: Embedding variance by prophage status\n",
    "ax = axes[2]\n",
    "emb_prophage['status'] = emb_prophage['has_prophage'].map({True: 'Prophage+', False: 'No prophage'})\n",
    "sns.boxplot(data=emb_prophage, x='status', y='total_emb_variance', ax=ax,\n",
    "            palette={'Prophage+': '#E91E63', 'No prophage': '#9E9E9E'})\n",
    "ax.set_ylabel('Total embedding variance (niche breadth)')\n",
    "ax.set_title(f'Environmental Breadth\\n(p={p_emb:.2e})')\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.suptitle('Genome Size Confound Analysis', fontsize=13, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/genome_size_confound.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/genome_size_confound.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('='*60)\n",
    "print('NB04 SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Species analyzed: {len(species_all):,}')\n",
    "print(f'Phyla represented: {species_all[\"phylum\"].nunique()}')\n",
    "print(f'Species with known environment: {species_known_env.shape[0]:,}')\n",
    "print(f'Species with genome size: {species_with_size.shape[0]:,}')\n",
    "print(f'\\nPERMANOVA results:')\n",
    "for _, row in results_df.iterrows():\n",
    "    sig = '***' if row['p_value'] < 0.001 else ('**' if row['p_value'] < 0.01 else ('*' if row['p_value'] < 0.05 else 'ns'))\n",
    "    print(f'  {row[\"predictor\"]}: F={row[\"test_statistic\"]:.2f}, p={row[\"p_value\"]} {sig}')\n",
    "print(f'\\nGenome size confound: rho={rho_size_count:.3f} (prophage count ~ genome size)')\n",
    "print(f'\\nFiles saved:')\n",
    "print(f'  data/species_prophage_environment.tsv')\n",
    "print(f'  data/variance_partitioning_results.tsv')\n",
    "print(f'  data/species_genome_size.tsv')\n",
    "print(f'  figures/prophage_prevalence_by_phylum.png')\n",
    "print(f'  figures/variance_partitioning.png')\n",
    "print(f'  figures/genome_size_confound.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}