{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB01: Prophage Gene Discovery\n",
    "\n",
    "**Project**: Prophage Ecology Across Bacterial Phylogeny and Environmental Gradients\n",
    "\n",
    "**Goal**: Identify all prophage-associated gene clusters in the BERDL pangenome using eggNOG annotations, classify into 7 operationally defined modules (A-G), and extract terminase large subunit (TerL) sequences for lineage clustering.\n",
    "\n",
    "**Environment**: Requires BERDL JupyterHub (Spark SQL)\n",
    "\n",
    "**Outputs**:\n",
    "- `data/prophage_gene_clusters.tsv` — all prophage-associated gene clusters with module assignments\n",
    "- `data/terL_sequences.fasta` — TerL protein sequences for lineage clustering\n",
    "- `data/species_module_summary.tsv` — per-species prophage module presence/absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Spark session (on BERDL JupyterHub — no import needed)\n",
    "spark = get_spark_session()\n",
    "\n",
    "# Add project src to path for prophage_utils\n",
    "sys.path.insert(0, '../src')\n",
    "from prophage_utils import MODULES, classify_gene_to_module, is_terL, build_spark_where_clause\n",
    "\n",
    "# Output directories\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "print(f'Spark session active. Modules defined: {list(MODULES.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore Prophage-Related Annotations\n",
    "\n",
    "Before running the full extraction, let's check what prophage-related annotations exist in the eggNOG table and estimate hit counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts for key prophage-related description keywords\n",
    "keywords = [\n",
    "    'terminase', 'capsid', 'portal protein', 'holin', 'endolysin',\n",
    "    'integrase', 'tail sheath', 'tail tube', 'tape measure', 'baseplate',\n",
    "    'excisionase', 'lysozyme', 'repressor', 'anti-crispr', 'anti-restriction',\n",
    "    'phage', 'prophage', 'tail fiber', 'tail spike'\n",
    "]\n",
    "\n",
    "keyword_counts = []\n",
    "for kw in keywords:\n",
    "    count_df = spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) as n\n",
    "        FROM kbase_ke_pangenome.eggnog_mapper_annotations\n",
    "        WHERE LOWER(Description) LIKE '%{kw}%'\n",
    "    \"\"\").toPandas()\n",
    "    keyword_counts.append({'keyword': kw, 'count': int(count_df['n'].iloc[0])})\n",
    "    print(f'  {kw}: {count_df[\"n\"].iloc[0]:,}')\n",
    "\n",
    "kw_df = pd.DataFrame(keyword_counts).sort_values('count', ascending=False)\n",
    "print(f'\\nTotal unique keywords checked: {len(keywords)}')\n",
    "print(kw_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PFam domain counts for phage-related domains\n",
    "pfam_keywords = [\n",
    "    'Terminase', 'Phage_portal', 'HK97', 'Phage_cap',\n",
    "    'Phage_holin', 'Phage_integrase', 'Phage_tail',\n",
    "    'Phage_sheath', 'Phage_fiber', 'Phage_lysozyme',\n",
    "    'XRE_N', 'ArdA', 'Phage_int_SAM'\n",
    "]\n",
    "\n",
    "pfam_counts = []\n",
    "for pf in pfam_keywords:\n",
    "    count_df = spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) as n\n",
    "        FROM kbase_ke_pangenome.eggnog_mapper_annotations\n",
    "        WHERE PFAMs LIKE '%{pf}%'\n",
    "    \"\"\").toPandas()\n",
    "    pfam_counts.append({'pfam_keyword': pf, 'count': int(count_df['n'].iloc[0])})\n",
    "    print(f'  {pf}: {count_df[\"n\"].iloc[0]:,}')\n",
    "\n",
    "pf_df = pd.DataFrame(pfam_counts).sort_values('count', ascending=False)\n",
    "print(f'\\nPFam keyword counts:')\n",
    "print(pf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some annotations for each key prophage marker to understand annotation patterns\n",
    "for marker in ['terminase large subunit', 'major capsid protein', 'holin', 'phage integrase', 'portal protein']:\n",
    "    print(f'\\n--- {marker.upper()} ---')\n",
    "    sample = spark.sql(f\"\"\"\n",
    "        SELECT PFAMs, Description, KEGG_ko, COG_category\n",
    "        FROM kbase_ke_pangenome.eggnog_mapper_annotations\n",
    "        WHERE LOWER(Description) LIKE '%{marker}%'\n",
    "        LIMIT 10\n",
    "    \"\"\").toPandas()\n",
    "    for _, row in sample.iterrows():\n",
    "        print(f'  PFAMs={row[\"PFAMs\"]}  Desc={row[\"Description\"][:80]}  KO={row[\"KEGG_ko\"]}  COG={row[\"COG_category\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract All Prophage Gene Clusters\n",
    "\n",
    "Use the comprehensive WHERE clause from `prophage_utils` to find all gene clusters matching any prophage module marker. Join with `gene_cluster` to get species, core/accessory status, and representative sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the full WHERE clause from our module definitions\n",
    "where_clause = build_spark_where_clause()\n",
    "print(f'WHERE clause has {where_clause.count(\"OR\")+1} conditions')\n",
    "print(f'First 500 chars: {where_clause[:500]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main extraction query: join eggnog_mapper_annotations with gene_cluster\n",
    "# This is the most expensive query — ~93M annotation rows joined with 132M cluster rows\n",
    "# Filter significantly reduces the scan via the WHERE clause\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT gc.gene_cluster_id,\n",
    "       gc.gtdb_species_clade_id,\n",
    "       gc.is_core,\n",
    "       gc.is_auxiliary,\n",
    "       gc.is_singleton,\n",
    "       gc.faa_sequence,\n",
    "       ann.PFAMs,\n",
    "       ann.Description,\n",
    "       ann.KEGG_ko,\n",
    "       ann.COG_category,\n",
    "       ann.EC\n",
    "FROM kbase_ke_pangenome.gene_cluster gc\n",
    "JOIN kbase_ke_pangenome.eggnog_mapper_annotations ann\n",
    "    ON gc.gene_cluster_id = ann.query_name\n",
    "WHERE {where_clause}\n",
    "\"\"\"\n",
    "\n",
    "print('Running prophage gene extraction query...')\n",
    "prophage_spark = spark.sql(query)\n",
    "\n",
    "# Cache in Spark for reuse\n",
    "prophage_spark.cache()\n",
    "n_total = prophage_spark.count()\n",
    "print(f'Total prophage-related gene clusters found: {n_total:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for module classification\n",
    "# This should be manageable — prophage clusters are a small fraction of the 132M total\n",
    "print('Converting to pandas...')\n",
    "prophage_df = prophage_spark.toPandas()\n",
    "print(f'DataFrame shape: {prophage_df.shape}')\n",
    "print(f'Memory: {prophage_df.memory_usage(deep=True).sum() / 1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify Gene Clusters into Modules (A-G)\n",
    "\n",
    "Apply the `classify_gene_to_module()` function from `prophage_utils` to assign each gene cluster to one or more of the 7 prophage modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each gene cluster into module(s)\n",
    "prophage_df['modules'] = prophage_df.apply(\n",
    "    lambda r: classify_gene_to_module(r['Description'], r['PFAMs'], r['KEGG_ko'], r['COG_category']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count how many clusters are assigned to each module\n",
    "from collections import Counter\n",
    "module_counter = Counter()\n",
    "for modules_list in prophage_df['modules']:\n",
    "    for m in modules_list:\n",
    "        module_counter[m] += 1\n",
    "\n",
    "print('Gene clusters per module:')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    count = module_counter.get(module_id, 0)\n",
    "    print(f'  {module_id}: {count:,} ({MODULES[module_id][\"full_name\"]})')\n",
    "\n",
    "# How many clusters have no module assignment?\n",
    "n_unassigned = sum(1 for m in prophage_df['modules'] if len(m) == 0)\n",
    "print(f'\\nUnassigned (matched WHERE but not any module): {n_unassigned:,}')\n",
    "\n",
    "# How many are assigned to multiple modules?\n",
    "n_multi = sum(1 for m in prophage_df['modules'] if len(m) > 1)\n",
    "print(f'Multi-module assignments: {n_multi:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flat representation: one row per cluster, comma-separated module list\n",
    "prophage_df['module_str'] = prophage_df['modules'].apply(lambda x: ','.join(x) if x else 'unassigned')\n",
    "\n",
    "# Also create boolean columns for each module\n",
    "for module_id in MODULES.keys():\n",
    "    prophage_df[f'has_{module_id}'] = prophage_df['modules'].apply(lambda x: module_id in x)\n",
    "\n",
    "print('Module assignment summary:')\n",
    "print(prophage_df['module_str'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify TerL clusters specifically\n",
    "prophage_df['is_terL'] = prophage_df.apply(\n",
    "    lambda r: is_terL(r['Description'], r['PFAMs'], r['KEGG_ko']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "n_terL = prophage_df['is_terL'].sum()\n",
    "n_terL_species = prophage_df.loc[prophage_df['is_terL'], 'gtdb_species_clade_id'].nunique()\n",
    "print(f'TerL clusters: {n_terL:,}')\n",
    "print(f'Species with TerL: {n_terL_species:,}')\n",
    "\n",
    "# Sample some TerL annotations\n",
    "print('\\nSample TerL annotations:')\n",
    "terL_sample = prophage_df[prophage_df['is_terL']].head(10)\n",
    "for _, r in terL_sample.iterrows():\n",
    "    print(f'  {r[\"gene_cluster_id\"][:40]}  PFAMs={r[\"PFAMs\"]}  Desc={r[\"Description\"][:60]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Core/Accessory/Singleton Status of Prophage Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze core/accessory/singleton distribution per module\n",
    "def classify_conservation(row):\n",
    "    if row['is_core'] == 1 or row['is_core'] == True:\n",
    "        return 'core'\n",
    "    elif row['is_singleton'] == 1 or row['is_singleton'] == True:\n",
    "        return 'singleton'\n",
    "    else:\n",
    "        return 'accessory'\n",
    "\n",
    "prophage_df['conservation'] = prophage_df.apply(classify_conservation, axis=1)\n",
    "\n",
    "print('Overall conservation of prophage gene clusters:')\n",
    "print(prophage_df['conservation'].value_counts())\n",
    "\n",
    "print('\\nConservation by module:')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    mask = prophage_df[f'has_{module_id}']\n",
    "    if mask.sum() > 0:\n",
    "        vc = prophage_df.loc[mask, 'conservation'].value_counts(normalize=True)\n",
    "        core_pct = vc.get('core', 0) * 100\n",
    "        acc_pct = vc.get('accessory', 0) * 100\n",
    "        sing_pct = vc.get('singleton', 0) * 100\n",
    "        print(f'  {module_id}: core={core_pct:.1f}% acc={acc_pct:.1f}% sing={sing_pct:.1f}% (n={mask.sum():,})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Species-Level Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to species level: which modules are present, how many clusters per module\n",
    "species_modules = []\n",
    "\n",
    "for species_id, grp in prophage_df.groupby('gtdb_species_clade_id'):\n",
    "    row = {'gtdb_species_clade_id': species_id, 'n_prophage_clusters': len(grp)}\n",
    "    for module_id in MODULES.keys():\n",
    "        n_mod = grp[f'has_{module_id}'].sum()\n",
    "        row[f'n_{module_id}'] = n_mod\n",
    "        row[f'has_{module_id}'] = n_mod > 0\n",
    "    row['n_terL'] = grp['is_terL'].sum()\n",
    "    row['n_modules_present'] = sum(1 for m in MODULES.keys() if row[f'has_{m}'])\n",
    "    species_modules.append(row)\n",
    "\n",
    "species_mod_df = pd.DataFrame(species_modules)\n",
    "\n",
    "# Merge with pangenome stats for context\n",
    "pangenome_stats = spark.sql(\"\"\"\n",
    "    SELECT gtdb_species_clade_id, no_genomes, no_gene_clusters, no_core, no_aux_genome\n",
    "    FROM kbase_ke_pangenome.pangenome\n",
    "\"\"\").toPandas()\n",
    "\n",
    "species_mod_df = species_mod_df.merge(pangenome_stats, on='gtdb_species_clade_id', how='left')\n",
    "\n",
    "print(f'Species with any prophage annotation: {len(species_mod_df):,}')\n",
    "print(f'Total species in pangenome: {len(pangenome_stats):,}')\n",
    "print(f'Fraction with prophage: {len(species_mod_df)/len(pangenome_stats)*100:.1f}%')\n",
    "print(f'\\nModule presence across species:')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    n = species_mod_df[f'has_{module_id}'].sum()\n",
    "    pct = n / len(pangenome_stats) * 100\n",
    "    print(f'  {module_id}: {n:,} species ({pct:.1f}%)')\n",
    "\n",
    "print(f'\\nNumber of modules present per species:')\n",
    "print(species_mod_df['n_modules_present'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prophage gene clusters (drop faa_sequence to keep file small)\n",
    "prophage_out = prophage_df.drop(columns=['faa_sequence']).copy()\n",
    "prophage_out.to_csv('../data/prophage_gene_clusters.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/prophage_gene_clusters.tsv: {len(prophage_out):,} rows')\n",
    "\n",
    "# Save species module summary\n",
    "species_mod_df.to_csv('../data/species_module_summary.tsv', sep='\\t', index=False)\n",
    "print(f'Saved data/species_module_summary.tsv: {len(species_mod_df):,} rows')\n",
    "\n",
    "# Save TerL sequences as FASTA for lineage clustering\n",
    "terL_clusters = prophage_df[prophage_df['is_terL'] & prophage_df['faa_sequence'].notna()].copy()\n",
    "n_with_seq = len(terL_clusters)\n",
    "print(f'\\nTerL clusters with protein sequence: {n_with_seq:,}')\n",
    "\n",
    "with open('../data/terL_sequences.fasta', 'w') as f:\n",
    "    for _, row in terL_clusters.iterrows():\n",
    "        seq = row['faa_sequence']\n",
    "        if seq and len(seq) > 10:\n",
    "            header = f\">{row['gene_cluster_id']}|{row['gtdb_species_clade_id']}\"\n",
    "            f.write(f\"{header}\\n{seq}\\n\")\n",
    "\n",
    "print(f'Saved data/terL_sequences.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation: Check Known Prophage-Carrying Species\n",
    "\n",
    "Verify that well-known prophage-carrying species (e.g., *E. coli* with lambda, *S. typhimurium* with P22) are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check known prophage-carrying species\n",
    "known_species = [\n",
    "    's__Escherichia_coli',      # lambda phage\n",
    "    's__Salmonella_enterica',   # P22 phage\n",
    "    's__Staphylococcus_aureus', # phi11, phiSa3\n",
    "    's__Pseudomonas_aeruginosa', # multiple prophages\n",
    "    's__Mycobacterium_tuberculosis', # phiRv1, phiRv2\n",
    "    's__Bacillus_subtilis',     # SPBeta, PBSX\n",
    "    's__Vibrio_cholerae',       # CTXphi\n",
    "    's__Streptococcus_pyogenes', # multiple prophages encoding virulence\n",
    "]\n",
    "\n",
    "for species_name in known_species:\n",
    "    matches = species_mod_df[\n",
    "        species_mod_df['gtdb_species_clade_id'].str.startswith(species_name)\n",
    "    ]\n",
    "    if len(matches) > 0:\n",
    "        row = matches.iloc[0]\n",
    "        modules_present = [m for m in MODULES.keys() if row[f'has_{m}']]\n",
    "        print(f'{species_name}: {row[\"n_prophage_clusters\"]} clusters, '\n",
    "              f'{row[\"n_modules_present\"]}/7 modules: {modules_present}')\n",
    "    else:\n",
    "        print(f'{species_name}: NOT FOUND in prophage results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Panel 1: Gene clusters per module\n",
    "module_names = [MODULES[m]['full_name'] for m in sorted(MODULES.keys())]\n",
    "module_counts = [module_counter.get(m, 0) for m in sorted(MODULES.keys())]\n",
    "axes[0].barh(module_names, module_counts, color='steelblue')\n",
    "axes[0].set_xlabel('Gene Clusters')\n",
    "axes[0].set_title('Prophage Gene Clusters by Module')\n",
    "for i, (v, n) in enumerate(zip(module_counts, module_names)):\n",
    "    axes[0].text(v + max(module_counts)*0.01, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "# Panel 2: Species per module\n",
    "species_counts = [species_mod_df[f'has_{m}'].sum() for m in sorted(MODULES.keys())]\n",
    "axes[1].barh(module_names, species_counts, color='darkorange')\n",
    "axes[1].set_xlabel('Species')\n",
    "axes[1].set_title('Species with Module Present')\n",
    "for i, v in enumerate(species_counts):\n",
    "    axes[1].text(v + max(species_counts)*0.01, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "# Panel 3: Distribution of modules per species\n",
    "mod_dist = species_mod_df['n_modules_present'].value_counts().sort_index()\n",
    "axes[2].bar(mod_dist.index, mod_dist.values, color='seagreen')\n",
    "axes[2].set_xlabel('Number of Modules Present')\n",
    "axes[2].set_ylabel('Number of Species')\n",
    "axes[2].set_title('Prophage Module Richness per Species')\n",
    "axes[2].set_xticks(range(0, 8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/prophage_module_discovery.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/prophage_module_discovery.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservation status by module (stacked bar)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "conservation_data = []\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    mask = prophage_df[f'has_{module_id}']\n",
    "    if mask.sum() > 0:\n",
    "        vc = prophage_df.loc[mask, 'conservation'].value_counts(normalize=True)\n",
    "        conservation_data.append({\n",
    "            'module': MODULES[module_id]['full_name'],\n",
    "            'core': vc.get('core', 0),\n",
    "            'accessory': vc.get('accessory', 0),\n",
    "            'singleton': vc.get('singleton', 0),\n",
    "        })\n",
    "\n",
    "cons_df = pd.DataFrame(conservation_data)\n",
    "cons_df.plot.barh(\n",
    "    x='module', stacked=True, ax=ax,\n",
    "    color=['#2ca02c', '#ff7f0e', '#d62728'],\n",
    ")\n",
    "ax.set_xlabel('Fraction')\n",
    "ax.set_title('Core/Accessory/Singleton Status of Prophage Gene Clusters by Module')\n",
    "ax.legend(title='Conservation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/prophage_conservation_by_module.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved figures/prophage_conservation_by_module.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('='*60)\n",
    "print('NB01 SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Total prophage gene clusters: {len(prophage_df):,}')\n",
    "print(f'Species with prophage annotations: {species_mod_df.shape[0]:,} / {len(pangenome_stats):,} ({species_mod_df.shape[0]/len(pangenome_stats)*100:.1f}%)')\n",
    "print(f'TerL clusters (for lineage clustering): {n_terL:,}')\n",
    "print(f'TerL clusters with sequences: {n_with_seq:,}')\n",
    "print(f'\\nModule prevalence (species with >= 1 cluster):')\n",
    "for module_id in sorted(MODULES.keys()):\n",
    "    n = species_mod_df[f'has_{module_id}'].sum()\n",
    "    print(f'  {module_id}: {n:,} species')\n",
    "print(f'\\nFiles saved:')\n",
    "print(f'  data/prophage_gene_clusters.tsv ({len(prophage_out):,} rows)')\n",
    "print(f'  data/species_module_summary.tsv ({len(species_mod_df):,} rows)')\n",
    "print(f'  data/terL_sequences.fasta ({n_with_seq:,} sequences)')\n",
    "print(f'  figures/prophage_module_discovery.png')\n",
    "print(f'  figures/prophage_conservation_by_module.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
