{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NB01: Data Extraction for Co-fitness Co-inheritance Analysis\n",
    "\n",
    "Extract genome × gene cluster presence matrices, co-fitness pairs, gene coordinates,\n",
    "and phylogenetic distances for 11 target organisms.\n",
    "\n",
    "**Requires BERDL JupyterHub** — `get_spark_session()` must be available.\n",
    "\n",
    "This notebook is the interactive equivalent of `src/extract_data.py`.\n",
    "For batch extraction, run the script directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:12:06.135342Z",
     "iopub.status.busy": "2026-02-15T07:12:06.135096Z",
     "iopub.status.idle": "2026-02-15T07:12:06.940770Z",
     "shell.execute_reply": "2026-02-15T07:12:06.939645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link table: 173,582 rows, 43 organisms\n",
      "Target organisms: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import Spark session — works on JupyterHub and locally\n",
    "try:\n",
    "    get_spark_session\n",
    "except NameError:\n",
    "    from berdl_notebook_utils.setup_spark_session import get_spark_session\n",
    "\n",
    "spark = get_spark_session()\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "CONS_DIR = Path('../../conservation_vs_fitness/data')\n",
    "\n",
    "for subdir in ['genome_cluster_matrices', 'cofit', 'gene_coords', 'phylo_distances']:\n",
    "    (DATA_DIR / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Target organisms and their species clades\n",
    "TARGET_ORGANISMS = {\n",
    "    'Koxy': 's__Klebsiella_michiganensis--RS_GCF_002925905.1',\n",
    "    'Btheta': 's__Bacteroides_thetaiotaomicron--RS_GCF_000011065.1',\n",
    "    'Smeli': 's__Sinorhizobium_meliloti--RS_GCF_017876815.1',\n",
    "    'RalstoniaUW163': 's__Ralstonia_solanacearum--RS_GCF_002251695.1',\n",
    "    'Putida': 's__Pseudomonas_E_alloputida--RS_GCF_021282585.1',\n",
    "    'SyringaeB728a': 's__Pseudomonas_E_syringae_M--RS_GCF_009176725.1',\n",
    "    'Korea': 's__Sphingomonas_koreensis--RS_GCF_002797435.1',\n",
    "    'RalstoniaGMI1000': 's__Ralstonia_pseudosolanacearum--RS_GCF_024925465.1',\n",
    "    'Phaeo': 's__Phaeobacter_inhibens--RS_GCF_000473105.1',\n",
    "    'Ddia6719': 's__Dickeya_dianthicola--RS_GCF_000365305.1',\n",
    "    'pseudo3_N2E3': 's__Pseudomonas_E_fluorescens_E--RS_GCF_001307155.1',\n",
    "}\n",
    "\n",
    "# Load shared data\n",
    "link = pd.read_csv(CONS_DIR / 'fb_pangenome_link.tsv', sep='\\t')\n",
    "link = link[link['orgId'] != 'Dyella79']\n",
    "org_mapping = pd.read_csv(CONS_DIR / 'organism_mapping.tsv', sep='\\t')\n",
    "\n",
    "print(f\"Link table: {len(link):,} rows, {link['orgId'].nunique()} organisms\")\n",
    "print(f\"Target organisms: {len(TARGET_ORGANISMS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-pangenome-stats",
   "metadata": {},
   "source": [
    "## Step 0: Verify Target Species Pangenome Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pangenome-stats",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:12:06.943539Z",
     "iopub.status.busy": "2026-02-15T07:12:06.943398Z",
     "iopub.status.idle": "2026-02-15T07:12:08.720482Z",
     "shell.execute_reply": "2026-02-15T07:12:08.719659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           orgId                    GTDB_species  no_genomes  mean_intra_species_ANI  no_gene_clusters  n_fb_genes  n_aux_fb\n",
      "            Koxy     s__Klebsiella_michiganensis         399                   98.57             61735        4965       822\n",
      "          Btheta s__Bacteroides_thetaiotaomicron         287                   98.44             65634        4727      1632\n",
      "           Smeli       s__Sinorhizobium_meliloti         241                   98.93             58199        6123      1365\n",
      "  RalstoniaUW163       s__Ralstonia_solanacearum         141                   96.27             23007        4303       867\n",
      "          Putida     s__Pseudomonas_E_alloputida         128                   97.49             42747        5470      1372\n",
      "   SyringaeB728a     s__Pseudomonas_E_syringae_M         126                   98.70             29917        5031       723\n",
      "           Korea       s__Sphingomonas_koreensis          72                   98.13              7633        4116       637\n",
      "RalstoniaGMI1000 s__Ralstonia_pseudosolanacearum          70                   95.97             21463        4812       932\n",
      "        Ddia6719          s__Dickeya_dianthicola          66                   99.47              9248        4030       767\n",
      "           Phaeo         s__Phaeobacter_inhibens          43                   97.75             10948        3823       508\n",
      "    pseudo3_N2E3  s__Pseudomonas_E_fluorescens_E          40                   99.66             10861        5535       140\n"
     ]
    }
   ],
   "source": [
    "clade_ids = list(TARGET_ORGANISMS.values())\n",
    "clade_str = \"','\".join(clade_ids)\n",
    "\n",
    "stats = spark.sql(f\"\"\"\n",
    "    SELECT p.gtdb_species_clade_id,\n",
    "           s.GTDB_species,\n",
    "           p.no_genomes,\n",
    "           p.no_core,\n",
    "           p.no_aux_genome,\n",
    "           p.no_singleton_gene_clusters,\n",
    "           p.no_gene_clusters,\n",
    "           s.mean_intra_species_ANI\n",
    "    FROM kbase_ke_pangenome.pangenome p\n",
    "    JOIN kbase_ke_pangenome.gtdb_species_clade s\n",
    "        ON p.gtdb_species_clade_id = s.gtdb_species_clade_id\n",
    "    WHERE p.gtdb_species_clade_id IN ('{clade_str}')\n",
    "    ORDER BY p.no_genomes DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Add orgId column\n",
    "clade_to_org = {v: k for k, v in TARGET_ORGANISMS.items()}\n",
    "stats['orgId'] = stats['gtdb_species_clade_id'].map(clade_to_org)\n",
    "\n",
    "# Count FB genes per organism\n",
    "fb_counts = link.groupby('orgId').agg(\n",
    "    n_fb_genes=('locusId', 'nunique'),\n",
    "    n_aux_fb=('is_auxiliary', lambda x: (x == True).sum())\n",
    ").reset_index()\n",
    "stats = stats.merge(fb_counts, on='orgId', how='left')\n",
    "\n",
    "print(stats[['orgId', 'GTDB_species', 'no_genomes', 'mean_intra_species_ANI',\n",
    "             'no_gene_clusters', 'n_fb_genes', 'n_aux_fb']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-matrices",
   "metadata": {},
   "source": [
    "## Step 1: Extract Genome × Gene Cluster Presence Matrices\n",
    "\n",
    "For each species, build a binary matrix: rows = genomes, columns = gene clusters.\n",
    "Only include clusters that FB genes map to (from `fb_pangenome_link.tsv`).\n",
    "\n",
    "**Performance note**: Each organism requires joining `gene_genecluster_junction` (~1B rows)\n",
    "with `gene` (~1B rows). BROADCAST hints on the small filter tables reduce join cost.\n",
    "Expect ~3-5 min per organism, ~45 min total. Already-cached matrices are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extract-matrices",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:12:08.723274Z",
     "iopub.status.busy": "2026-02-15T07:12:08.723153Z",
     "iopub.status.idle": "2026-02-15T07:33:26.943123Z",
     "shell.execute_reply": "2026-02-15T07:33:26.942526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Koxy] Cached: 399 genomes x 4942 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Btheta] Cached: 287 genomes x 4649 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Smeli] Cached: 241 genomes x 6004 clusters\n",
      "  [RalstoniaUW163] Cached: 141 genomes x 4413 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Putida] Cached: 128 genomes x 5409 clusters\n",
      "  [SyringaeB728a] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 558,868 (218s)\n",
      "    Matrix: 126 genomes x 4999 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Korea] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 254,177 (211s)\n",
      "    Matrix: 72 genomes x 4075 clusters\n",
      "  [RalstoniaGMI1000] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 4723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 285,319 (220s)\n",
      "    Matrix: 70 genomes x 4723 clusters\n",
      "  [Phaeo] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 145,722 (209s)\n",
      "    Matrix: 43 genomes x 3790 clusters\n",
      "  [Ddia6719] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 4694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 256,026 (209s)\n",
      "    Matrix: 66 genomes x 4694 clusters\n",
      "  [pseudo3_N2E3] Extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target clusters: 5513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw presence rows: 214,589 (211s)\n",
      "    Matrix: 40 genomes x 5513 clusters\n",
      "\n",
      "=== MATRIX SUMMARY ===\n",
      "           orgId  genomes  clusters    status\n",
      "            Koxy      399      4942    cached\n",
      "          Btheta      287      4649    cached\n",
      "           Smeli      241      6004    cached\n",
      "  RalstoniaUW163      141      4413    cached\n",
      "          Putida      128      5409    cached\n",
      "   SyringaeB728a      126      4999 extracted\n",
      "           Korea       72      4075 extracted\n",
      "RalstoniaGMI1000       70      4723 extracted\n",
      "           Phaeo       43      3790 extracted\n",
      "        Ddia6719       66      4694 extracted\n",
      "    pseudo3_N2E3       40      5513 extracted\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "matrix_summary = []\n",
    "\n",
    "for orgId, clade_id in TARGET_ORGANISMS.items():\n",
    "    outpath = DATA_DIR / 'genome_cluster_matrices' / f'{orgId}_presence.tsv'\n",
    "    if outpath.exists() and outpath.stat().st_size > 0:\n",
    "        cached = pd.read_csv(outpath, sep='\\t', index_col=0)\n",
    "        matrix_summary.append({'orgId': orgId, 'genomes': cached.shape[0],\n",
    "                               'clusters': cached.shape[1], 'status': 'cached'})\n",
    "        print(f\"  [{orgId}] Cached: {cached.shape[0]} genomes x {cached.shape[1]} clusters\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  [{orgId}] Extracting...\", flush=True)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Get target cluster IDs\n",
    "    org_clusters = link[link['gtdb_species_clade_id'] == clade_id]['gene_cluster_id'].unique()\n",
    "    if len(org_clusters) == 0:\n",
    "        org_clusters = link[link['orgId'] == orgId]['gene_cluster_id'].unique()\n",
    "    print(f\"    Target clusters: {len(org_clusters)}\")\n",
    "\n",
    "    if len(org_clusters) == 0:\n",
    "        print(f\"    WARNING: No clusters for {orgId}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Register small filter tables for BROADCAST joins\n",
    "    cluster_df = spark.createDataFrame([(c,) for c in org_clusters], ['gene_cluster_id'])\n",
    "    cluster_df.createOrReplaceTempView('target_clusters')\n",
    "\n",
    "    genome_ids = spark.sql(f\"\"\"\n",
    "        SELECT genome_id FROM kbase_ke_pangenome.genome\n",
    "        WHERE gtdb_species_clade_id = '{clade_id}'\n",
    "    \"\"\").toPandas()['genome_id'].tolist()\n",
    "    genome_df = spark.createDataFrame([(g,) for g in genome_ids], ['genome_id'])\n",
    "    genome_df.createOrReplaceTempView('target_genomes')\n",
    "\n",
    "    # Use BROADCAST hints on small tables to avoid shuffle joins\n",
    "    presence = spark.sql(\"\"\"\n",
    "        SELECT /*+ BROADCAST(tc), BROADCAST(tg) */\n",
    "            DISTINCT g.genome_id, j.gene_cluster_id\n",
    "        FROM kbase_ke_pangenome.gene_genecluster_junction j\n",
    "        JOIN target_clusters tc ON j.gene_cluster_id = tc.gene_cluster_id\n",
    "        JOIN kbase_ke_pangenome.gene g ON j.gene_id = g.gene_id\n",
    "        JOIN target_genomes tg ON g.genome_id = tg.genome_id\n",
    "    \"\"\").toPandas()\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"    Raw presence rows: {len(presence):,} ({elapsed:.0f}s)\")\n",
    "\n",
    "    if len(presence) == 0:\n",
    "        print(f\"    WARNING: No data for {orgId}\")\n",
    "        continue\n",
    "\n",
    "    presence['present'] = 1\n",
    "    matrix = presence.pivot_table(\n",
    "        index='genome_id', columns='gene_cluster_id',\n",
    "        values='present', fill_value=0, aggfunc='max'\n",
    "    )\n",
    "\n",
    "    matrix_summary.append({'orgId': orgId, 'genomes': matrix.shape[0],\n",
    "                           'clusters': matrix.shape[1], 'status': 'extracted'})\n",
    "    print(f\"    Matrix: {matrix.shape[0]} genomes x {matrix.shape[1]} clusters\")\n",
    "    matrix.to_csv(outpath, sep='\\t')\n",
    "\n",
    "print(\"\\n=== MATRIX SUMMARY ===\")\n",
    "print(pd.DataFrame(matrix_summary).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-cofit",
   "metadata": {},
   "source": [
    "## Step 2: Extract Co-fitness Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extract-cofit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:33:26.946315Z",
     "iopub.status.busy": "2026-02-15T07:33:26.946189Z",
     "iopub.status.idle": "2026-02-15T07:34:05.467485Z",
     "shell.execute_reply": "2026-02-15T07:34:05.466658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Koxy] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 423,936 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Btheta] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 328,455 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Smeli] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 528,699 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [RalstoniaUW163] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 pairs\n",
      "  [Putida] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 458,688 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [SyringaeB728a] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 371,004 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Korea] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 230,724 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [RalstoniaGMI1000] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 pairs\n",
      "  [Phaeo] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 192,138 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Ddia6719] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 250,488 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [pseudo3_N2E3] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 507,828 pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COFIT SUMMARY ===\n",
      "           orgId  pairs    status\n",
      "            Koxy 423936 extracted\n",
      "          Btheta 328455 extracted\n",
      "           Smeli 528699 extracted\n",
      "  RalstoniaUW163      0 extracted\n",
      "          Putida 458688 extracted\n",
      "   SyringaeB728a 371004 extracted\n",
      "           Korea 230724 extracted\n",
      "RalstoniaGMI1000      0 extracted\n",
      "           Phaeo 192138 extracted\n",
      "        Ddia6719 250488 extracted\n",
      "    pseudo3_N2E3 507828 extracted\n"
     ]
    }
   ],
   "source": [
    "cofit_summary = []\n",
    "\n",
    "for orgId in TARGET_ORGANISMS:\n",
    "    outpath = DATA_DIR / 'cofit' / f'{orgId}_cofit.tsv'\n",
    "    if outpath.exists() and outpath.stat().st_size > 0:\n",
    "        cached = pd.read_csv(outpath, sep='\\t')\n",
    "        cofit_summary.append({'orgId': orgId, 'pairs': len(cached), 'status': 'cached'})\n",
    "        print(f\"  [{orgId}] Cached: {len(cached):,} pairs\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  [{orgId}] Extracting...\", end='', flush=True)\n",
    "    cofit = spark.sql(f\"\"\"\n",
    "        SELECT orgId, locusId, hitId,\n",
    "               CAST(rank AS INT) as rank,\n",
    "               CAST(cofit AS FLOAT) as cofit\n",
    "        FROM kescience_fitnessbrowser.cofit\n",
    "        WHERE orgId = '{orgId}'\n",
    "        ORDER BY locusId, CAST(rank AS INT)\n",
    "    \"\"\").toPandas()\n",
    "    print(f\" {len(cofit):,} pairs\")\n",
    "\n",
    "    cofit.to_csv(outpath, sep='\\t', index=False)\n",
    "    cofit_summary.append({'orgId': orgId, 'pairs': len(cofit), 'status': 'extracted'})\n",
    "\n",
    "print(\"\\n=== COFIT SUMMARY ===\")\n",
    "print(pd.DataFrame(cofit_summary).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-coords",
   "metadata": {},
   "source": [
    "## Step 3: Extract Gene Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extract-coords",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:34:05.470443Z",
     "iopub.status.busy": "2026-02-15T07:34:05.470322Z",
     "iopub.status.idle": "2026-02-15T07:34:19.397354Z",
     "shell.execute_reply": "2026-02-15T07:34:19.395975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Koxy] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,586 genes\n",
      "  [Btheta] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4,902 genes\n",
      "  [Smeli] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6,281 genes\n",
      "  [RalstoniaUW163] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,006 genes\n",
      "  [Putida] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,661 genes\n",
      "  [SyringaeB728a] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,216 genes\n",
      "  [Korea] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4,245 genes\n",
      "  [RalstoniaGMI1000] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,204 genes\n",
      "  [Phaeo] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3,944 genes\n",
      "  [Ddia6719] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4,338 genes\n",
      "  [pseudo3_N2E3] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,854 genes\n"
     ]
    }
   ],
   "source": [
    "for orgId in TARGET_ORGANISMS:\n",
    "    outpath = DATA_DIR / 'gene_coords' / f'{orgId}_coords.tsv'\n",
    "    if outpath.exists() and outpath.stat().st_size > 0:\n",
    "        print(f\"  [{orgId}] Cached\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  [{orgId}] Extracting...\", end='', flush=True)\n",
    "    coords = spark.sql(f\"\"\"\n",
    "        SELECT orgId, locusId, scaffoldId,\n",
    "               CAST(begin AS INT) as begin,\n",
    "               CAST(end AS INT) as end,\n",
    "               strand\n",
    "        FROM kescience_fitnessbrowser.gene\n",
    "        WHERE orgId = '{orgId}'\n",
    "        ORDER BY scaffoldId, CAST(begin AS INT)\n",
    "    \"\"\").toPandas()\n",
    "    print(f\" {len(coords):,} genes\")\n",
    "    coords.to_csv(outpath, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-phylo",
   "metadata": {},
   "source": [
    "## Step 4: Extract Phylogenetic Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extract-phylo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:34:19.400206Z",
     "iopub.status.busy": "2026-02-15T07:34:19.399886Z",
     "iopub.status.idle": "2026-02-15T07:34:40.297798Z",
     "shell.execute_reply": "2026-02-15T07:34:40.296437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species with phylogenetic trees: 9/11\n",
      "  [Koxy] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79,401 pairs\n",
      "  [Btheta] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41,041 pairs\n",
      "  [Smeli] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28,920 pairs\n",
      "  [RalstoniaGMI1000] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2,415 pairs\n",
      "  [RalstoniaUW163] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9,870 pairs\n",
      "  [Putida] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8,128 pairs\n",
      "  [SyringaeB728a] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7,875 pairs\n",
      "  [Ddia6719] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2,145 pairs\n",
      "  [Korea] Extracting..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2,556 pairs\n",
      "\n",
      "Reference genomes saved: 95 rows\n"
     ]
    }
   ],
   "source": [
    "clade_str = \"','\".join(TARGET_ORGANISMS.values())\n",
    "\n",
    "tree_mapping = spark.sql(f\"\"\"\n",
    "    SELECT gtdb_species_clade_id, phylogenetic_tree_id\n",
    "    FROM kbase_ke_pangenome.phylogenetic_tree\n",
    "    WHERE gtdb_species_clade_id IN ('{clade_str}')\n",
    "\"\"\").toPandas()\n",
    "\n",
    "clade_to_org = {v: k for k, v in TARGET_ORGANISMS.items()}\n",
    "print(f\"Species with phylogenetic trees: {len(tree_mapping)}/{len(TARGET_ORGANISMS)}\")\n",
    "\n",
    "for _, row in tree_mapping.iterrows():\n",
    "    clade_id = row['gtdb_species_clade_id']\n",
    "    tree_id = row['phylogenetic_tree_id']\n",
    "    orgId = clade_to_org.get(clade_id)\n",
    "    if orgId is None:\n",
    "        continue\n",
    "\n",
    "    outpath = DATA_DIR / 'phylo_distances' / f'{orgId}_phylo_distances.tsv'\n",
    "    if outpath.exists() and outpath.stat().st_size > 0:\n",
    "        print(f\"  [{orgId}] Cached\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  [{orgId}] Extracting...\", end='', flush=True)\n",
    "    distances = spark.sql(f\"\"\"\n",
    "        SELECT genome1_id, genome2_id, branch_distance\n",
    "        FROM kbase_ke_pangenome.phylogenetic_tree_distance_pairs\n",
    "        WHERE phylogenetic_tree_id = '{tree_id}'\n",
    "    \"\"\").toPandas()\n",
    "    print(f\" {len(distances):,} pairs\")\n",
    "    distances.to_csv(outpath, sep='\\t', index=False)\n",
    "\n",
    "# Save reference genome mapping\n",
    "ref_genomes = org_mapping[\n",
    "    org_mapping['orgId'].isin(TARGET_ORGANISMS.keys())\n",
    "][['orgId', 'gtdb_species_clade_id', 'pg_genome_id']].drop_duplicates()\n",
    "ref_genomes.to_csv(DATA_DIR / 'phylo_distances' / 'reference_genomes.tsv',\n",
    "                   sep='\\t', index=False)\n",
    "print(f\"\\nReference genomes saved: {len(ref_genomes)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T07:34:40.300561Z",
     "iopub.status.busy": "2026-02-15T07:34:40.300295Z",
     "iopub.status.idle": "2026-02-15T07:34:40.306627Z",
     "shell.execute_reply": "2026-02-15T07:34:40.305743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NB01 SUMMARY: Data Extraction\n",
      "============================================================\n",
      "Target organisms: 11\n",
      "Species with phylogenetic trees: 9\n",
      "\n",
      "Output directories:\n",
      "  genome_cluster_matrices/: 11 files\n",
      "  cofit/: 11 files\n",
      "  gene_coords/: 11 files\n",
      "  phylo_distances/: 10 files\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('=' * 60)\n",
    "print('NB01 SUMMARY: Data Extraction')\n",
    "print('=' * 60)\n",
    "print(f'Target organisms: {len(TARGET_ORGANISMS)}')\n",
    "print(f'Species with phylogenetic trees: {len(tree_mapping)}')\n",
    "print(f'\\nOutput directories:')\n",
    "for subdir in ['genome_cluster_matrices', 'cofit', 'gene_coords', 'phylo_distances']:\n",
    "    files = list((DATA_DIR / subdir).glob('*.tsv'))\n",
    "    print(f'  {subdir}/: {len(files)} files')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
