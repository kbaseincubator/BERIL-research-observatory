{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Data Exploration & Lifestyle Classification\n",
    "\n",
    "**Project**: Lifestyle-Based COG Stratification\n",
    "\n",
    "**Goal**: Assess `ncbi_env` coverage, build a genome-level lifestyle classifier, and identify target species for COG analysis.\n",
    "\n",
    "**Data Sources**:\n",
    "- `kbase_ke_pangenome.ncbi_env` — NCBI environment metadata (4.1M rows, EAV format)\n",
    "- `kbase_ke_pangenome.genome` — Genome metadata (293K rows)\n",
    "- `kbase_ke_pangenome.pangenome` — Per-species pangenome stats (27K rows)\n",
    "- `kbase_ke_pangenome.gtdb_species_clade` — Taxonomy (27K rows)\n",
    "\n",
    "**Output**: `../data/species_lifestyle_classification.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Table Row Counts\n",
    "\n",
    "Verify expected table sizes before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['ncbi_env', 'genome', 'sample', 'pangenome', 'gtdb_species_clade']\n",
    "for t in tables:\n",
    "    cnt = spark.sql(f\"SELECT COUNT(*) as cnt FROM kbase_ke_pangenome.{t}\").collect()[0]['cnt']\n",
    "    print(f\"{t}: {cnt:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore ncbi_env Structure\n",
    "\n",
    "The `ncbi_env` table is EAV format: each row is one (BioSample, attribute_name, content) triple.\n",
    "We need to find which `harmonized_name` values are most populated and useful for lifestyle classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What harmonized_name values exist and how many biosamples have them?\n",
    "attr_counts = spark.sql(\"\"\"\n",
    "    SELECT harmonized_name, COUNT(DISTINCT accession) as n_biosamples\n",
    "    FROM kbase_ke_pangenome.ncbi_env\n",
    "    GROUP BY harmonized_name\n",
    "    ORDER BY n_biosamples DESC\n",
    "    LIMIT 30\n",
    "\"\"\")\n",
    "attr_counts.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample rows to understand the data format\n",
    "spark.sql(\"\"\"\n",
    "    SELECT accession, harmonized_name, content\n",
    "    FROM kbase_ke_pangenome.ncbi_env\n",
    "    WHERE harmonized_name IN ('host', 'isolation_source', 'env_broad_scale', 'env_local_scale', 'env_medium')\n",
    "    LIMIT 20\n",
    "\"\"\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assess Genome-to-ncbi_env Join Coverage\n",
    "\n",
    "How many of the 293K genomes have `ncbi_biosample_id` values that match `ncbi_env.accession`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many genomes have non-null biosample IDs\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total_genomes,\n",
    "        SUM(CASE WHEN ncbi_biosample_id IS NOT NULL AND ncbi_biosample_id != '' THEN 1 ELSE 0 END) as has_biosample,\n",
    "        SUM(CASE WHEN ncbi_biosample_id IS NOT NULL AND ncbi_biosample_id != '' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as pct_with_biosample\n",
    "    FROM kbase_ke_pangenome.genome\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many genomes actually join to ncbi_env\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(DISTINCT g.genome_id) as genomes_with_env\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.ncbi_env ne\n",
    "        ON g.ncbi_biosample_id = ne.accession\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many genomes have lifestyle-relevant attributes specifically?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        ne.harmonized_name,\n",
    "        COUNT(DISTINCT g.genome_id) as n_genomes\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.ncbi_env ne\n",
    "        ON g.ncbi_biosample_id = ne.accession\n",
    "    WHERE ne.harmonized_name IN ('host', 'isolation_source', 'env_broad_scale', 'env_local_scale', 'env_medium')\n",
    "    GROUP BY ne.harmonized_name\n",
    "    ORDER BY n_genomes DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine Content Values for Lifestyle Classification\n",
    "\n",
    "For each lifestyle-relevant attribute, examine the most common content values.\n",
    "This will help us build classification rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 'host' values\n",
    "spark.sql(\"\"\"\n",
    "    SELECT content, COUNT(*) as cnt\n",
    "    FROM kbase_ke_pangenome.ncbi_env\n",
    "    WHERE harmonized_name = 'host'\n",
    "        AND content IS NOT NULL\n",
    "        AND content != ''\n",
    "        AND LOWER(content) NOT IN ('not applicable', 'not collected', 'missing', 'na', 'n/a', 'none', 'unknown')\n",
    "    GROUP BY content\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 30\n",
    "\"\"\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 'isolation_source' values\n",
    "spark.sql(\"\"\"\n",
    "    SELECT content, COUNT(*) as cnt\n",
    "    FROM kbase_ke_pangenome.ncbi_env\n",
    "    WHERE harmonized_name = 'isolation_source'\n",
    "        AND content IS NOT NULL\n",
    "        AND content != ''\n",
    "        AND LOWER(content) NOT IN ('not applicable', 'not collected', 'missing', 'na', 'n/a', 'none', 'unknown')\n",
    "    GROUP BY content\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 30\n",
    "\"\"\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 'env_broad_scale' values\n",
    "spark.sql(\"\"\"\n",
    "    SELECT content, COUNT(*) as cnt\n",
    "    FROM kbase_ke_pangenome.ncbi_env\n",
    "    WHERE harmonized_name = 'env_broad_scale'\n",
    "        AND content IS NOT NULL\n",
    "        AND content != ''\n",
    "        AND LOWER(content) NOT IN ('not applicable', 'not collected', 'missing', 'na', 'n/a', 'none', 'unknown')\n",
    "    GROUP BY content\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 30\n",
    "\"\"\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Lifestyle Classifier\n",
    "\n",
    "Classification rules (refine after inspecting content values above):\n",
    "\n",
    "**Host-associated**: Genome has a valid `host` attribute (not 'not applicable', etc.) OR `isolation_source` contains host-related keywords (blood, sputum, wound, stool, urine, clinical, patient, etc.)\n",
    "\n",
    "**Free-living**: Genome has NO valid `host` attribute AND `isolation_source` or `env_broad_scale` contains environmental keywords (soil, water, marine, freshwater, sediment, rhizosphere, etc.)\n",
    "\n",
    "**Ambiguous/Unknown**: Everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all lifestyle-relevant metadata per genome\n",
    "# Pivot the EAV table into a wide format with one row per genome\n",
    "genome_env = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        g.genome_id,\n",
    "        g.gtdb_species_clade_id,\n",
    "        MAX(CASE WHEN ne.harmonized_name = 'host' THEN ne.content END) as host,\n",
    "        MAX(CASE WHEN ne.harmonized_name = 'isolation_source' THEN ne.content END) as isolation_source,\n",
    "        MAX(CASE WHEN ne.harmonized_name = 'env_broad_scale' THEN ne.content END) as env_broad_scale,\n",
    "        MAX(CASE WHEN ne.harmonized_name = 'env_local_scale' THEN ne.content END) as env_local_scale,\n",
    "        MAX(CASE WHEN ne.harmonized_name = 'env_medium' THEN ne.content END) as env_medium\n",
    "    FROM kbase_ke_pangenome.genome g\n",
    "    JOIN kbase_ke_pangenome.ncbi_env ne\n",
    "        ON g.ncbi_biosample_id = ne.accession\n",
    "    WHERE ne.harmonized_name IN ('host', 'isolation_source', 'env_broad_scale', 'env_local_scale', 'env_medium')\n",
    "    GROUP BY g.genome_id, g.gtdb_species_clade_id\n",
    "\"\"\")\n",
    "\n",
    "genome_env.cache()\n",
    "print(f\"Genomes with any lifestyle metadata: {genome_env.count():,}\")\n",
    "genome_env.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Define classification rules\n",
    "# NOTE: Refine these keyword lists after inspecting the content values above!\n",
    "\n",
    "# Sentinel values to exclude\n",
    "na_values = ['not applicable', 'not collected', 'missing', 'na', 'n/a', 'none', 'unknown', '']\n",
    "\n",
    "# Host-related isolation source keywords (clinical/host samples)\n",
    "host_keywords = ['blood', 'sputum', 'wound', 'stool', 'urine', 'clinical',\n",
    "                 'patient', 'feces', 'abscess', 'throat', 'nasal', 'skin',\n",
    "                 'lung', 'cerebrospinal', 'bile', 'tissue', 'biopsy',\n",
    "                 'human', 'cattle', 'chicken', 'pig', 'mouse', 'bovine',\n",
    "                 'swine', 'poultry', 'gut', 'intestin', 'fecal', 'rectal']\n",
    "\n",
    "# Environmental isolation source keywords\n",
    "env_keywords = ['soil', 'water', 'marine', 'freshwater', 'sediment', 'river',\n",
    "                'lake', 'ocean', 'sea', 'rhizosphere', 'root', 'leaf',\n",
    "                'air', 'hot spring', 'hydrothermal', 'mine', 'compost',\n",
    "                'wastewater', 'activated sludge', 'biofilm', 'rock', 'sand']\n",
    "\n",
    "\n",
    "def has_valid_host(host_col):\n",
    "    \"\"\"Returns True if host column has a meaningful value.\"\"\"\n",
    "    return (\n",
    "        host_col.isNotNull()\n",
    "        & (~F.lower(host_col).isin(na_values))\n",
    "    )\n",
    "\n",
    "\n",
    "def matches_keywords(col, keywords):\n",
    "    \"\"\"Returns True if column contains any of the keywords (case-insensitive).\"\"\"\n",
    "    conditions = [F.lower(col).contains(kw) for kw in keywords]\n",
    "    return F.when(col.isNull(), F.lit(False)).otherwise(\n",
    "        conditions[0] if len(conditions) == 1\n",
    "        else F.greatest(*[c.cast('int') for c in conditions]).cast('boolean')\n",
    "    )\n",
    "\n",
    "\n",
    "# Classify each genome\n",
    "classified = genome_env.withColumn(\n",
    "    'lifestyle',\n",
    "    F.when(\n",
    "        has_valid_host(F.col('host')) | matches_keywords(F.col('isolation_source'), host_keywords),\n",
    "        F.lit('host_associated')\n",
    "    ).when(\n",
    "        matches_keywords(F.col('isolation_source'), env_keywords)\n",
    "        | matches_keywords(F.col('env_broad_scale'), env_keywords),\n",
    "        F.lit('free_living')\n",
    "    ).otherwise(F.lit('ambiguous'))\n",
    ")\n",
    "\n",
    "# Summary\n",
    "classified.groupBy('lifestyle').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-check: sample genomes from each category\n",
    "for cat in ['host_associated', 'free_living', 'ambiguous']:\n",
    "    print(f\"\\n=== {cat} (sample 5) ===\")\n",
    "    classified.filter(F.col('lifestyle') == cat).select(\n",
    "        'genome_id', 'host', 'isolation_source', 'env_broad_scale'\n",
    "    ).show(5, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregate to Species Level\n",
    "\n",
    "Assign each species a lifestyle based on majority vote of its constituent genomes.\n",
    "Filter to species with:\n",
    "- >= 10 genomes total (for meaningful pangenome)\n",
    "- >= 70% of classified genomes agreeing on lifestyle (clear assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count lifestyle categories per species\n",
    "species_lifestyle = classified.filter(\n",
    "    F.col('lifestyle') != 'ambiguous'\n",
    ").groupBy('gtdb_species_clade_id', 'lifestyle').count()\n",
    "\n",
    "# Get total classified genomes per species\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window.partitionBy('gtdb_species_clade_id')\n",
    "species_lifestyle = species_lifestyle.withColumn(\n",
    "    'total_classified', F.sum('count').over(w)\n",
    ").withColumn(\n",
    "    'fraction', F.col('count') / F.col('total_classified')\n",
    ")\n",
    "\n",
    "species_lifestyle.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign species lifestyle: majority vote with >= 70% threshold\n",
    "# Keep only the dominant lifestyle per species\n",
    "w_rank = Window.partitionBy('gtdb_species_clade_id').orderBy(F.desc('count'))\n",
    "\n",
    "species_assignment = species_lifestyle.withColumn(\n",
    "    'rank', F.row_number().over(w_rank)\n",
    ").filter(\n",
    "    (F.col('rank') == 1) & (F.col('fraction') >= 0.7)\n",
    ").select(\n",
    "    'gtdb_species_clade_id',\n",
    "    F.col('lifestyle').alias('species_lifestyle'),\n",
    "    F.col('count').alias('n_classified_dominant'),\n",
    "    'total_classified',\n",
    "    F.col('fraction').alias('lifestyle_fraction')\n",
    ")\n",
    "\n",
    "print(f\"Species with clear lifestyle assignment: {species_assignment.count():,}\")\n",
    "species_assignment.groupBy('species_lifestyle').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with pangenome stats to filter by genome count and add taxonomy\n",
    "target_species = species_assignment.join(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT p.gtdb_species_clade_id, p.no_genomes, p.no_gene_clusters, p.no_core,\n",
    "               p.no_aux_genome, p.no_singleton_gene_clusters,\n",
    "               sc.GTDB_taxonomy, sc.GTDB_species\n",
    "        FROM kbase_ke_pangenome.pangenome p\n",
    "        JOIN kbase_ke_pangenome.gtdb_species_clade sc\n",
    "            ON p.gtdb_species_clade_id = sc.gtdb_species_clade_id\n",
    "    \"\"\"),\n",
    "    on='gtdb_species_clade_id',\n",
    "    how='inner'\n",
    ").filter(\n",
    "    F.col('no_genomes') >= 10\n",
    ")\n",
    "\n",
    "# Add phylum for phylogenetic stratification\n",
    "target_species = target_species.withColumn(\n",
    "    'phylum', F.split(F.col('GTDB_taxonomy'), ';').getItem(1)\n",
    ")\n",
    "\n",
    "print(f\"Target species (>= 10 genomes, clear lifestyle): {target_species.count():,}\")\n",
    "target_species.groupBy('species_lifestyle').count().show()\n",
    "target_species.groupBy('species_lifestyle', 'phylum').count().orderBy(\n",
    "    'species_lifestyle', F.desc('count')\n",
    ").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save species lifestyle classification\n",
    "target_pdf = target_species.toPandas()\n",
    "target_pdf.to_csv('../data/species_lifestyle_classification.csv', index=False)\n",
    "print(f\"Saved {len(target_pdf)} species to ../data/species_lifestyle_classification.csv\")\n",
    "target_pdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "Record observations here after running:\n",
    "\n",
    "- How many genomes had usable lifestyle metadata? ___\n",
    "- How many species classified as host-associated? ___\n",
    "- How many species classified as free-living? ___\n",
    "- Which phyla are represented in each category? ___\n",
    "- Any concerns about classification quality? ___\n",
    "- Are the keyword lists adequate or do they need refinement? ___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
