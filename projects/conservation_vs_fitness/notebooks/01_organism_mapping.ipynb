{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {},
   "source": [
    "# NB01: Map Fitness Browser Organisms to Pangenome Clades\n",
    "\n",
    "Map each of the 48 FB organisms to one or more pangenome species clades using three\n",
    "complementary strategies:\n",
    "\n",
    "1. **NCBI taxid** — match FB `taxonomyId` against `gtdb_metadata.ncbi_taxid` / `ncbi_species_taxid`\n",
    "2. **NCBI organism name** — match genus+species against `gtdb_metadata.ncbi_organism_name` (catches GTDB-renamed organisms)\n",
    "3. **Scaffold accession** — match FB scaffold IDs against pangenome `gene.gene_id` prefixes\n",
    "\n",
    "**Requires BERDL JupyterHub** — `get_spark_session()` must be available.\n",
    "\n",
    "**Output**: `data/organism_mapping.tsv`\n",
    "\n",
    "### Key notes\n",
    "- GTDB renames many organisms (e.g. *P. putida* → *Pseudomonas_E alloputida*), so we must match on NCBI names/taxids\n",
    "- FB organism may map to multiple clades (GTDB splits finer than NCBI) — resolved later by DIAMOND hit count\n",
    "- *E. coli* (`Keio`) is expected to be absent — the main `s__Escherichia_coli` clade was too large for the pangenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark_session()\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-orgs",
   "metadata": {},
   "source": [
    "## 1. Load Fitness Browser Organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-orgs",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_orgs = spark.sql(\"\"\"\n",
    "    SELECT orgId, genus, species, strain, taxonomyId\n",
    "    FROM kescience_fitnessbrowser.organism\n",
    "    ORDER BY genus, species\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Total FB organisms: {len(fb_orgs)}\")\n",
    "fb_orgs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scaffolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaffold IDs per organism for Strategy 3\n",
    "fb_scaffolds = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT orgId, scaffoldId\n",
    "    FROM kescience_fitnessbrowser.gene\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Total scaffold entries: {len(fb_scaffolds)}\")\n",
    "print(f\"Organisms with scaffolds: {fb_scaffolds['orgId'].nunique()}\")\n",
    "\n",
    "# Show sample scaffold IDs to understand format\n",
    "print(\"\\nSample scaffold IDs:\")\n",
    "for org in fb_scaffolds['orgId'].unique()[:5]:\n",
    "    scaffs = fb_scaffolds[fb_scaffolds['orgId'] == org]['scaffoldId'].tolist()\n",
    "    print(f\"  {org}: {scaffs[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-s1",
   "metadata": {},
   "source": [
    "## 2. Strategy 1: NCBI Taxid Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-taxid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all unique FB taxonomy IDs\n",
    "tax_ids = fb_orgs['taxonomyId'].dropna().unique().tolist()\n",
    "tax_id_str = ','.join([str(int(t)) for t in tax_ids])\n",
    "\n",
    "taxid_matches = spark.sql(f\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        m.ncbi_taxid,\n",
    "        m.ncbi_species_taxid,\n",
    "        m.accession,\n",
    "        g.gtdb_species_clade_id\n",
    "    FROM kbase_ke_pangenome.gtdb_metadata m\n",
    "    JOIN kbase_ke_pangenome.genome g ON m.accession = g.genome_id\n",
    "    WHERE CAST(m.ncbi_species_taxid AS INT) IN ({tax_id_str})\n",
    "       OR CAST(m.ncbi_taxid AS INT) IN ({tax_id_str})\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(f\"Taxid matches: {len(taxid_matches)} genome-clade pairs\")\n",
    "print(f\"Unique clades: {taxid_matches['gtdb_species_clade_id'].nunique()}\")\n",
    "\n",
    "# Map back to FB orgIds\n",
    "taxid_mapping = []\n",
    "for _, org in fb_orgs.iterrows():\n",
    "    tid = org['taxonomyId']\n",
    "    if pd.isna(tid):\n",
    "        continue\n",
    "    tid = int(tid)\n",
    "    hits = taxid_matches[\n",
    "        (taxid_matches['ncbi_species_taxid'].astype(str).str.strip() == str(tid)) |\n",
    "        (taxid_matches['ncbi_taxid'].astype(str).str.strip() == str(tid))\n",
    "    ]\n",
    "    for clade in hits['gtdb_species_clade_id'].unique():\n",
    "        pg_genomes = hits[hits['gtdb_species_clade_id'] == clade]['accession'].tolist()\n",
    "        taxid_mapping.append({\n",
    "            'orgId': org['orgId'],\n",
    "            'genus': org['genus'],\n",
    "            'species': org['species'],\n",
    "            'strain': org['strain'],\n",
    "            'taxonomyId': tid,\n",
    "            'gtdb_species_clade_id': clade,\n",
    "            'pg_genome_id': pg_genomes[0],  # representative genome\n",
    "            'match_method': 'taxid'\n",
    "        })\n",
    "\n",
    "taxid_df = pd.DataFrame(taxid_mapping)\n",
    "taxid_orgs = taxid_df['orgId'].nunique() if len(taxid_df) > 0 else 0\n",
    "print(f\"\\nFB organisms matched by taxid: {taxid_orgs}/48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-s2",
   "metadata": {},
   "source": [
    "## 3. Strategy 2: NCBI Organism Name Matching\n",
    "\n",
    "The `ncbi_organism_name` field in `gtdb_metadata` preserves pre-GTDB nomenclature,\n",
    "so searching by genus+species here catches organisms that GTDB has renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-name-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = []\n",
    "\n",
    "for _, org in fb_orgs.iterrows():\n",
    "    orgId = org['orgId']\n",
    "    genus = org['genus']\n",
    "    species = org['species']\n",
    "    strain = org['strain']\n",
    "    \n",
    "    if pd.isna(genus) or pd.isna(species):\n",
    "        continue\n",
    "    \n",
    "    # Try genus + species match\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT m.accession, g.gtdb_species_clade_id, m.ncbi_organism_name\n",
    "        FROM kbase_ke_pangenome.gtdb_metadata m\n",
    "        JOIN kbase_ke_pangenome.genome g ON m.accession = g.genome_id\n",
    "        WHERE m.ncbi_organism_name LIKE '%{genus}%{species}%'\n",
    "    \"\"\"\n",
    "    hits = spark.sql(query).toPandas()\n",
    "    \n",
    "    # If strain is available, also try with strain for more specific match\n",
    "    if not pd.isna(strain) and str(strain).strip() and len(hits) > 0:\n",
    "        strain_query = f\"\"\"\n",
    "            SELECT DISTINCT m.accession, g.gtdb_species_clade_id, m.ncbi_organism_name\n",
    "            FROM kbase_ke_pangenome.gtdb_metadata m\n",
    "            JOIN kbase_ke_pangenome.genome g ON m.accession = g.genome_id\n",
    "            WHERE m.ncbi_organism_name LIKE '%{genus}%{species}%{strain}%'\n",
    "        \"\"\"\n",
    "        strain_hits = spark.sql(strain_query).toPandas()\n",
    "        if len(strain_hits) > 0:\n",
    "            hits = strain_hits  # prefer strain-specific match\n",
    "    \n",
    "    for clade in hits['gtdb_species_clade_id'].unique():\n",
    "        clade_hits = hits[hits['gtdb_species_clade_id'] == clade]\n",
    "        name_mapping.append({\n",
    "            'orgId': orgId,\n",
    "            'genus': genus,\n",
    "            'species': species,\n",
    "            'strain': strain,\n",
    "            'taxonomyId': org['taxonomyId'],\n",
    "            'gtdb_species_clade_id': clade,\n",
    "            'pg_genome_id': clade_hits['accession'].iloc[0],\n",
    "            'match_method': 'ncbi_name'\n",
    "        })\n",
    "\n",
    "name_df = pd.DataFrame(name_mapping)\n",
    "name_orgs = name_df['orgId'].nunique() if len(name_df) > 0 else 0\n",
    "print(f\"FB organisms matched by NCBI name: {name_orgs}/48\")\n",
    "\n",
    "# Show which new organisms this strategy found beyond taxid\n",
    "if len(taxid_df) > 0 and len(name_df) > 0:\n",
    "    new_by_name = set(name_df['orgId']) - set(taxid_df['orgId'])\n",
    "    print(f\"New organisms found only by NCBI name (not taxid): {len(new_by_name)}\")\n",
    "    if new_by_name:\n",
    "        for oid in sorted(new_by_name):\n",
    "            row = name_df[name_df['orgId'] == oid].iloc[0]\n",
    "            print(f\"  {oid}: {row['genus']} {row['species']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-s3",
   "metadata": {},
   "source": [
    "## 4. Strategy 3: Scaffold Accession Matching\n",
    "\n",
    "For FB organisms with RefSeq-style scaffold IDs (NC_, NZ_, CP, AE prefixes),\n",
    "search for pangenome genes whose `gene_id` starts with the same accession.\n",
    "This works because pangenome gene IDs embed the scaffold accession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scaffold-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_mapping = []\n",
    "\n",
    "# Only try scaffolds with RefSeq-style prefixes\n",
    "refseq_prefixes = ('NC_', 'NZ_', 'CP', 'AE', 'AP', 'BA', 'BX', 'CR', 'FN', 'FP', 'HE', 'AL', 'AM')\n",
    "\n",
    "for _, org in fb_orgs.iterrows():\n",
    "    orgId = org['orgId']\n",
    "    org_scaffolds = fb_scaffolds[fb_scaffolds['orgId'] == orgId]['scaffoldId'].tolist()\n",
    "    \n",
    "    # Filter to RefSeq-style scaffolds\n",
    "    refseq_scaffolds = [s for s in org_scaffolds if any(s.startswith(p) for p in refseq_prefixes)]\n",
    "    \n",
    "    if not refseq_scaffolds:\n",
    "        continue\n",
    "    \n",
    "    # Try the first scaffold (usually the main chromosome)\n",
    "    scaffold = refseq_scaffolds[0]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT g.genome_id, g.gtdb_species_clade_id\n",
    "        FROM kbase_ke_pangenome.gene gene_t\n",
    "        JOIN kbase_ke_pangenome.genome g ON gene_t.genome_id = g.genome_id\n",
    "        WHERE gene_t.gene_id LIKE '{scaffold}%'\n",
    "    \"\"\"\n",
    "    hits = spark.sql(query).toPandas()\n",
    "    \n",
    "    for clade in hits['gtdb_species_clade_id'].unique():\n",
    "        clade_hits = hits[hits['gtdb_species_clade_id'] == clade]\n",
    "        scaffold_mapping.append({\n",
    "            'orgId': orgId,\n",
    "            'genus': org['genus'],\n",
    "            'species': org['species'],\n",
    "            'strain': org['strain'],\n",
    "            'taxonomyId': org['taxonomyId'],\n",
    "            'gtdb_species_clade_id': clade,\n",
    "            'pg_genome_id': clade_hits['genome_id'].iloc[0],\n",
    "            'match_method': 'scaffold'\n",
    "        })\n",
    "\n",
    "scaffold_df = pd.DataFrame(scaffold_mapping)\n",
    "scaffold_orgs = scaffold_df['orgId'].nunique() if len(scaffold_df) > 0 else 0\n",
    "print(f\"FB organisms matched by scaffold accession: {scaffold_orgs}/48\")\n",
    "\n",
    "# Show which new organisms this strategy found\n",
    "already_matched = set()\n",
    "if len(taxid_df) > 0:\n",
    "    already_matched |= set(taxid_df['orgId'])\n",
    "if len(name_df) > 0:\n",
    "    already_matched |= set(name_df['orgId'])\n",
    "if len(scaffold_df) > 0:\n",
    "    new_by_scaffold = set(scaffold_df['orgId']) - already_matched\n",
    "    print(f\"New organisms found only by scaffold (not taxid/name): {len(new_by_scaffold)}\")\n",
    "    if new_by_scaffold:\n",
    "        for oid in sorted(new_by_scaffold):\n",
    "            row = scaffold_df[scaffold_df['orgId'] == oid].iloc[0]\n",
    "            print(f\"  {oid}: {row['genus']} {row['species']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-combine",
   "metadata": {},
   "source": [
    "## 5. Combine All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all mappings, keeping match_method to show provenance\n",
    "all_mappings = pd.concat([taxid_df, name_df, scaffold_df], ignore_index=True)\n",
    "\n",
    "# Deduplicate: same orgId + clade should only appear once, prefer taxid > scaffold > ncbi_name\n",
    "method_priority = {'taxid': 0, 'scaffold': 1, 'ncbi_name': 2}\n",
    "all_mappings['priority'] = all_mappings['match_method'].map(method_priority)\n",
    "all_mappings = all_mappings.sort_values('priority').drop_duplicates(\n",
    "    subset=['orgId', 'gtdb_species_clade_id'], keep='first'\n",
    ").drop(columns='priority').sort_values(['orgId', 'gtdb_species_clade_id'])\n",
    "\n",
    "print(f\"Combined mapping: {len(all_mappings)} orgId x clade pairs\")\n",
    "print(f\"Unique FB organisms matched: {all_mappings['orgId'].nunique()}/48\")\n",
    "print(f\"Unique pangenome clades: {all_mappings['gtdb_species_clade_id'].nunique()}\")\n",
    "print(f\"\\nMatch method breakdown:\")\n",
    "print(all_mappings['match_method'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-qc",
   "metadata": {},
   "source": [
    "## 6. Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-qc-unmatched",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmatched organisms\n",
    "matched_orgs = set(all_mappings['orgId'])\n",
    "unmatched = fb_orgs[~fb_orgs['orgId'].isin(matched_orgs)]\n",
    "\n",
    "print(f\"=== UNMATCHED ORGANISMS ({len(unmatched)}/48) ===\")\n",
    "if len(unmatched) > 0:\n",
    "    for _, row in unmatched.iterrows():\n",
    "        print(f\"  {row['orgId']:25s} {row['genus']} {row['species']} \"\n",
    "              f\"(strain={row['strain']}, taxid={row['taxonomyId']})\")\n",
    "else:\n",
    "    print(\"  All organisms matched!\")\n",
    "\n",
    "# Note E. coli absence\n",
    "ecoli_orgs = fb_orgs[fb_orgs['species'].str.contains('coli', case=False, na=False)]\n",
    "if len(ecoli_orgs) > 0:\n",
    "    for _, row in ecoli_orgs.iterrows():\n",
    "        status = 'MATCHED' if row['orgId'] in matched_orgs else 'UNMATCHED'\n",
    "        print(f\"\\nE. coli check: {row['orgId']} ({row['genus']} {row['species']} \"\n",
    "              f\"{row['strain']}) — {status}\")\n",
    "        if status == 'UNMATCHED':\n",
    "            print(\"  Expected: main s__Escherichia_coli clade absent from pangenome (too large)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-qc-multi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-clade organisms\n",
    "clades_per_org = all_mappings.groupby('orgId')['gtdb_species_clade_id'].nunique().reset_index()\n",
    "clades_per_org.columns = ['orgId', 'n_clades']\n",
    "multi_clade = clades_per_org[clades_per_org['n_clades'] > 1]\n",
    "\n",
    "print(f\"=== MULTI-CLADE ORGANISMS ({len(multi_clade)}) ===\")\n",
    "for _, row in multi_clade.iterrows():\n",
    "    orgId = row['orgId']\n",
    "    org_info = fb_orgs[fb_orgs['orgId'] == orgId].iloc[0]\n",
    "    clades = all_mappings[all_mappings['orgId'] == orgId]['gtdb_species_clade_id'].tolist()\n",
    "    print(f\"  {orgId} ({org_info['genus']} {org_info['species']}): {row['n_clades']} clades\")\n",
    "    for c in clades:\n",
    "        method = all_mappings[(all_mappings['orgId'] == orgId) & \n",
    "                              (all_mappings['gtdb_species_clade_id'] == c)]['match_method'].iloc[0]\n",
    "        print(f\"    - {c} (via {method})\")\n",
    "\n",
    "print(f\"\\nSingle-clade organisms: {len(clades_per_org) - len(multi_clade)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-qc-crosscheck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-check: show GTDB species names for all matched clades\n",
    "# to verify they are taxonomically reasonable\n",
    "unique_clades = all_mappings['gtdb_species_clade_id'].unique().tolist()\n",
    "clade_str = \"','\".join(unique_clades)\n",
    "\n",
    "clade_info = spark.sql(f\"\"\"\n",
    "    SELECT gtdb_species_clade_id, GTDB_species,\n",
    "           COUNT(*) as n_genomes\n",
    "    FROM kbase_ke_pangenome.gtdb_species_clade\n",
    "    WHERE gtdb_species_clade_id IN ('{clade_str}')\n",
    "    GROUP BY gtdb_species_clade_id, GTDB_species\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"=== CLADE CROSS-CHECK ===\")\n",
    "summary = all_mappings[['orgId', 'genus', 'species', 'gtdb_species_clade_id']].drop_duplicates()\n",
    "summary = summary.merge(clade_info, on='gtdb_species_clade_id', how='left')\n",
    "print(summary[['orgId', 'genus', 'species', 'gtdb_species_clade_id', \n",
    "               'GTDB_species', 'n_genomes']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-save",
   "metadata": {},
   "source": [
    "## 7. Save Organism Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = DATA_DIR / 'organism_mapping.tsv'\n",
    "all_mappings.to_csv(output_path, sep='\\t', index=False)\n",
    "print(f\"Saved: {output_path}\")\n",
    "print(f\"  {len(all_mappings)} rows (orgId x clade pairs)\")\n",
    "print(f\"  {all_mappings['orgId'].nunique()} unique FB organisms\")\n",
    "print(f\"  {all_mappings['gtdb_species_clade_id'].nunique()} unique pangenome clades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NB01 SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"FB organisms: {len(fb_orgs)}\")\n",
    "print(f\"Matched: {all_mappings['orgId'].nunique()}\")\n",
    "print(f\"Unmatched: {len(unmatched)}\")\n",
    "print(f\"Multi-clade: {len(multi_clade)}\")\n",
    "print(f\"Unique clades: {all_mappings['gtdb_species_clade_id'].nunique()}\")\n",
    "print(f\"Match methods: {dict(all_mappings['match_method'].value_counts())}\")\n",
    "print(f\"\\nOutput: {output_path}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}